{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Intelligence Nanodegree\n",
    "\n",
    "## Convolutional Neural Networks\n",
    "\n",
    "## Project: Write an Algorithm for a Dog Identification App \n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, some template code has already been provided for you, and you will need to implement additional functionality to successfully complete this project. You will not need to modify the included code beyond what is requested. Sections that begin with **'(IMPLEMENTATION)'** in the header indicate that the following block of code will require additional functionality which you must provide. Instructions will be provided for each section, and the specifics of the implementation are marked in the code block with a 'TODO' statement. Please be sure to read the instructions carefully! \n",
    "\n",
    "> **Note**: Once you have completed all of the code implementations, you need to finalize your work by exporting the iPython Notebook as an HTML document. Before exporting the notebook to html, all of the code cells need to have been run so that reviewers can see the final implementation and output. You can then export the notebook by using the menu above and navigating to  \\n\",\n",
    "    \"**File -> Download as -> HTML (.html)**. Include the finished document along with this notebook as your submission.\n",
    "\n",
    "In addition to implementing code, there will be questions that you must answer which relate to the project and your implementation. Each section where you will answer a question is preceded by a **'Question X'** header. Carefully read each question and provide thorough answers in the following text boxes that begin with **'Answer:'**. Your project submission will be evaluated based on your answers to each of the questions and the implementation you provide.\n",
    "\n",
    ">**Note:** Code and Markdown cells can be executed using the **Shift + Enter** keyboard shortcut.  Markdown cells can be edited by double-clicking the cell to enter edit mode.\n",
    "\n",
    "The rubric contains _optional_ \"Stand Out Suggestions\" for enhancing the project beyond the minimum requirements. If you decide to pursue the \"Stand Out Suggestions\", you should include the code in this IPython notebook.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "### Why We're Here \n",
    "\n",
    "In this notebook, you will make the first steps towards developing an algorithm that could be used as part of a mobile or web app.  At the end of this project, your code will accept any user-supplied image as input.  If a dog is detected in the image, it will provide an estimate of the dog's breed.  If a human is detected, it will provide an estimate of the dog breed that is most resembling.  The image below displays potential sample output of your finished project (... but we expect that each student's algorithm will behave differently!). \n",
    "\n",
    "![Sample Dog Output](images/sample_dog_output.png)\n",
    "\n",
    "In this real-world setting, you will need to piece together a series of models to perform different tasks; for instance, the algorithm that detects humans in an image will be different from the CNN that infers dog breed.  There are many points of possible failure, and no perfect algorithm exists.  Your imperfect solution will nonetheless create a fun user experience!\n",
    "\n",
    "### The Road Ahead\n",
    "\n",
    "We break the notebook into separate steps.  Feel free to use the links below to navigate the notebook.\n",
    "\n",
    "* [Step 0](#step0): Import Datasets\n",
    "* [Step 1](#step1): Detect Humans\n",
    "* [Step 2](#step2): Detect Dogs\n",
    "* [Step 3](#step3): Create a CNN to Classify Dog Breeds (from Scratch)\n",
    "* [Step 4](#step4): Use a CNN to Classify Dog Breeds (using Transfer Learning)\n",
    "* [Step 5](#step5): Create a CNN to Classify Dog Breeds (using Transfer Learning)\n",
    "* [Step 6](#step6): Write your Algorithm\n",
    "* [Step 7](#step7): Test Your Algorithm\n",
    "\n",
    "---\n",
    "<a id='step0'></a>\n",
    "## Step 0: Import Datasets\n",
    "\n",
    "### Import Dog Dataset\n",
    "\n",
    "In the code cell below, we import a dataset of dog images.  We populate a few variables through the use of the `load_files` function from the scikit-learn library:\n",
    "- `train_files`, `valid_files`, `test_files` - numpy arrays containing file paths to images\n",
    "- `train_targets`, `valid_targets`, `test_targets` - numpy arrays containing onehot-encoded classification labels \n",
    "- `dog_names` - list of string-valued dog breed names for translating labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 133 total dog categories.\n",
      "There are 8351 total dog images.\n",
      "\n",
      "There are 6680 training dog images.\n",
      "There are 835 validation dog images.\n",
      "There are 836 test dog images.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "# define function to load train, test, and validation datasets\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    dog_files = np.array(data['filenames'])\n",
    "    dog_targets = np_utils.to_categorical(np.array(data['target']), 133)\n",
    "    return dog_files, dog_targets\n",
    "\n",
    "# load train, test, and validation datasets\n",
    "train_files, train_targets = load_dataset('Dataset/dogImages/train')\n",
    "valid_files, valid_targets = load_dataset('Dataset/dogImages/valid')\n",
    "test_files, test_targets = load_dataset('Dataset/dogImages/test')\n",
    "\n",
    "# load list of dog names\n",
    "dog_names = [item[20:-1] for item in sorted(glob(\"Dataset/dogImages/train/*/\"))]\n",
    "\n",
    "# print statistics about the dataset\n",
    "print('There are %d total dog categories.' % len(dog_names))\n",
    "print('There are %s total dog images.\\n' % len(np.hstack([train_files, valid_files, test_files])))\n",
    "print('There are %d training dog images.' % len(train_files))\n",
    "print('There are %d validation dog images.' % len(valid_files))\n",
    "print('There are %d test dog images.'% len(test_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Human Dataset\n",
    "\n",
    "In the code cell below, we import a dataset of human images, where the file paths are stored in the numpy array `human_files`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/Developement/Udacity_Project/dog-project-master/Dataset/lfw/lfw\\Yoko_Ono\\Yoko_Ono_0001.jpg\n",
      "There are 13233 total human images.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(8675309)\n",
    "\n",
    "# load filenames in shuffled human dataset\n",
    "human_files = np.array(glob(\"D:/Developement/Udacity_Project/dog-project-master/Dataset/lfw/lfw/*/*\"))\n",
    "random.shuffle(human_files)\n",
    "print (human_files[1])\n",
    "# print statistics about the dataset\n",
    "print('There are %d total human images.' % len(human_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step1'></a>\n",
    "## Step 1: Detect Humans\n",
    "\n",
    "We use OpenCV's implementation of [Haar feature-based cascade classifiers](http://docs.opencv.org/trunk/d7/d8b/tutorial_py_face_detection.html) to detect human faces in images.  OpenCV provides many pre-trained face detectors, stored as XML files on [github](https://github.com/opencv/opencv/tree/master/data/haarcascades).  We have downloaded one of these detectors and stored it in the `haarcascades` directory.\n",
    "\n",
    "In the next code cell, we demonstrate how to use this detector to find human faces in a sample image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/Developement/Udacity_Project/dog-project-master/Dataset/lfw/lfw\\Laurence_Fishburne\\Laurence_Fishburne_0001.jpg\n",
      "Number of faces detected: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19b183bef60>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2                \n",
    "import matplotlib.pyplot as plt                        \n",
    "%matplotlib inline                               \n",
    "\n",
    "# extract pre-trained face detector\n",
    "face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_alt.xml')\n",
    "print(human_files[3])\n",
    "# load color (BGR) image\n",
    "img = cv2.imread(human_files[3])\n",
    "\n",
    "# convert BGR image to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# find faces in image\n",
    "faces = face_cascade.detectMultiScale(gray)\n",
    "\n",
    "# print number of faces detected in the image\n",
    "print('Number of faces detected:', len(faces))\n",
    "\n",
    "# get bounding box for each detected face\n",
    "for (x,y,w,h) in faces:\n",
    "    # add bounding box to color image\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    \n",
    "# convert BGR image to RGB for plotting\n",
    "cv_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# display the image, along with bounding box\n",
    "plt.imshow(cv_rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before using any of the face detectors, it is standard procedure to convert the images to grayscale.  The `detectMultiScale` function executes the classifier stored in `face_cascade` and takes the grayscale image as a parameter.  \n",
    "\n",
    "In the above code, `faces` is a numpy array of detected faces, where each row corresponds to a detected face.  Each detected face is a 1D array with four entries that specifies the bounding box of the detected face.  The first two entries in the array (extracted in the above code as `x` and `y`) specify the horizontal and vertical positions of the top left corner of the bounding box.  The last two entries in the array (extracted here as `w` and `h`) specify the width and height of the box.\n",
    "\n",
    "### Write a Human Face Detector\n",
    "\n",
    "We can use this procedure to write a function that returns `True` if a human face is detected in an image and `False` otherwise.  This function, aptly named `face_detector`, takes a string-valued file path to an image as input and appears in the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# returns \"True\" if face is detected in image stored at img_path\n",
    "\n",
    "def face_detector(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray)\n",
    "    return len(faces) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Assess the Human Face Detector\n",
    "\n",
    "__Question 1:__ Use the code cell below to test the performance of the `face_detector` function.  \n",
    "- What percentage of the first 100 images in `human_files` have a detected human face?  \n",
    "- What percentage of the first 100 images in `dog_files` have a detected human face? \n",
    "\n",
    "Ideally, we would like 100% of human images with a detected face and 0% of dog images with a detected face.  You will see that our algorithm falls short of this goal, but still gives acceptable performance.  We extract the file paths for the first 100 images from each of the datasets and store them in the numpy arrays `human_files_short` and `dog_files_short`.\n",
    "\n",
    "__Answer:__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human Accuracy: 99%\n",
      "Dog Accuracy: 89%\n"
     ]
    }
   ],
   "source": [
    "human_files_short = human_files[:100]\n",
    "dog_files_short = train_files[:100]\n",
    "# Do NOT modify the code above this line.\n",
    "## TODO: Test the performance of the face_detector algorithm\n",
    "## on the images in human_files_short and dog_files_short.\n",
    "human_counter = 0\n",
    "dog_counter = 0\n",
    "for h_filename, d_filename in zip(human_files_short, dog_files_short):\n",
    "    if face_detector(h_filename):\n",
    "        human_counter += 1    \n",
    "    if not face_detector(d_filename):\n",
    "        dog_counter+= 1\n",
    "print ('Human Accuracy: %d%%'%human_counter)\n",
    "print ('Dog Accuracy: %d%%'%dog_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 2:__ This algorithmic choice necessitates that we communicate to the user that we accept human images only when they provide a clear view of a face (otherwise, we risk having unneccessarily frustrated users!). In your opinion, is this a reasonable expectation to pose on the user? If not, can you think of a way to detect humans in images that does not necessitate an image with a clearly presented face?\n",
    "\n",
    "__Answer:__\n",
    "\n",
    "We suggest the face detector from OpenCV as a potential way to detect human images in your algorithm, but you are free to explore other approaches, especially approaches that make use of deep learning :).  Please use the code cell below to design and test your own face detection algorithm.  If you decide to pursue this _optional_ task, report performance on each of the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (Optional) TODO: Report the performance of another  \n",
    "## face detection algorithm on the LFW dataset\n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step2'></a>\n",
    "## Step 2: Detect Dogs\n",
    "\n",
    "In this section, we use a pre-trained [ResNet-50](http://ethereon.github.io/netscope/#/gist/db945b393d40bfa26006) model to detect dogs in images.  Our first line of code downloads the ResNet-50 model, along with weights that have been trained on [ImageNet](http://www.image-net.org/), a very large, very popular dataset used for image classification and other vision tasks.  ImageNet contains over 10 million URLs, each linking to an image containing an object from one of [1000 categories](https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a).  Given an image, this pre-trained ResNet-50 model returns a prediction (derived from the available categories in ImageNet) for the object that is contained in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "# define ResNet50 model\n",
    "ResNet50_model = ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-23-5993a01b333e>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-23-5993a01b333e>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    When using TensorFlow as backend, Keras CNNs require a 4D array (which we'll also refer to as a 4D tensor) as input, with shape\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "### Pre-process the Data\n",
    "\n",
    "When using TensorFlow as backend, Keras CNNs require a 4D array (which we'll also refer to as a 4D tensor) as input, with shape\n",
    "\n",
    "$$\n",
    "(\\text{nb_samples}, \\text{rows}, \\text{columns}, \\text{channels}),\n",
    "$$\n",
    "\n",
    "where `nb_samples` corresponds to the total number of images (or samples), and `rows`, `columns`, and `channels` correspond to the number of rows, columns, and channels for each image, respectively.  \n",
    "\n",
    "The `path_to_tensor` function below takes a string-valued file path to a color image as input and returns a 4D tensor suitable for supplying to a Keras CNN.  The function first loads the image and resizes it to a square image that is $224 \\times 224$ pixels.  Next, the image is converted to an array, which is then resized to a 4D tensor.  In this case, since we are working with color images, each image has three channels.  Likewise, since we are processing a single image (or sample), the returned tensor will always have shape\n",
    "\n",
    "$$\n",
    "(1, 224, 224, 3).\n",
    "$$\n",
    "\n",
    "The `paths_to_tensor` function takes a numpy array of string-valued image paths as input and returns a 4D tensor with shape \n",
    "\n",
    "$$\n",
    "(\\text{nb_samples}, 224, 224, 3).\n",
    "$$\n",
    "\n",
    "Here, `nb_samples` is the number of samples, or number of images, in the supplied array of image paths.  It is best to think of `nb_samples` as the number of 3D tensors (where each 3D tensor corresponds to a different image) in your dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions with ResNet-50\n",
    "\n",
    "Getting the 4D tensor ready for ResNet-50, and for any other pre-trained model in Keras, requires some additional processing.  First, the RGB image is converted to BGR by reordering the channels.  All pre-trained models have the additional normalization step that the mean pixel (expressed in RGB as $[103.939, 116.779, 123.68]$ and calculated from all pixels in all images in ImageNet) must be subtracted from every pixel in each image.  This is implemented in the imported function `preprocess_input`.  If you're curious, you can check the code for `preprocess_input` [here](https://github.com/fchollet/keras/blob/master/keras/applications/imagenet_utils.py).\n",
    "\n",
    "Now that we have a way to format our image for supplying to ResNet-50, we are now ready to use the model to extract the predictions.  This is accomplished with the `predict` method, which returns an array whose $i$-th entry is the model's predicted probability that the image belongs to the $i$-th ImageNet category.  This is implemented in the `ResNet50_predict_labels` function below.\n",
    "\n",
    "By taking the argmax of the predicted probability vector, we obtain an integer corresponding to the model's predicted object class, which we can identify with an object category through the use of this [dictionary](https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "def ResNet50_predict_labels(img_path):\n",
    "    # returns prediction vector for image located at img_path\n",
    "    img = preprocess_input(path_to_tensor(img_path))\n",
    "    return np.argmax(ResNet50_model.predict(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a Dog Detector\n",
    "\n",
    "While looking at the [dictionary](https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a), you will notice that the categories corresponding to dogs appear in an uninterrupted sequence and correspond to dictionary keys 151-268, inclusive, to include all categories from `'Chihuahua'` to `'Mexican hairless'`.  Thus, in order to check to see if an image is predicted to contain a dog by the pre-trained ResNet-50 model, we need only check if the `ResNet50_predict_labels` function above returns a value between 151 and 268 (inclusive).\n",
    "\n",
    "We use these ideas to complete the `dog_detector` function below, which returns `True` if a dog is detected in an image (and `False` if not)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "### returns \"True\" if a dog is detected in the image stored at img_path\n",
    "def dog_detector(img_path):\n",
    "    prediction = ResNet50_predict_labels(img_path)\n",
    "    return ((prediction <= 268) & (prediction >= 151)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Assess the Dog Detector\n",
    "\n",
    "__Question 3:__ Use the code cell below to test the performance of your `dog_detector` function.  \n",
    "- What percentage of the images in `human_files_short` have a detected dog?  \n",
    "- What percentage of the images in `dog_files_short` have a detected dog?\n",
    "\n",
    "__Answer:__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Human dataset:-99 %\n",
      "Dogs detected in Dogs dataset:-100 %\n"
     ]
    }
   ],
   "source": [
    "### TODO: Test the performance of the dog_detector function\n",
    "### on the images in human_files_short and dog_files_short.\n",
    "dog_counter1 = 0\n",
    "dog_counter2 = 0\n",
    "for h_filename, d_filename in zip(human_files_short, dog_files_short):\n",
    "    if not dog_detector(h_filename):\n",
    "        dog_counter1 += 1    \n",
    "    if dog_detector(d_filename):\n",
    "        dog_counter2+= 1\n",
    "print(\"Accuracy on Human dataset:-%d %%\" %(dog_counter1/100 *100))\n",
    "print(\"Dogs detected in Dogs dataset:-%d %%\" %(dog_counter2/100 *100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step3'></a>\n",
    "## Step 3: Create a CNN to Classify Dog Breeds (from Scratch)\n",
    "\n",
    "Now that we have functions for detecting humans and dogs in images, we need a way to predict breed from images.  In this step, you will create a CNN that classifies dog breeds.  You must create your CNN _from scratch_ (so, you can't use transfer learning _yet_!), and you must attain a test accuracy of at least 1%.  In Step 5 of this notebook, you will have the opportunity to use transfer learning to create a CNN that attains greatly improved accuracy.\n",
    "\n",
    "Be careful with adding too many trainable layers!  More parameters means longer training, which means you are more likely to need a GPU to accelerate the training process.  Thankfully, Keras provides a handy estimate of the time that each epoch is likely to take; you can extrapolate this estimate to figure out how long it will take for your algorithm to train. \n",
    "\n",
    "We mention that the task of assigning breed to dogs from images is considered exceptionally challenging.  To see why, consider that *even a human* would have great difficulty in distinguishing between a Brittany and a Welsh Springer Spaniel.  \n",
    "\n",
    "Brittany | Welsh Springer Spaniel\n",
    "- | - \n",
    "<img src=\"images/Brittany_02625.jpg\" width=\"100\"> | <img src=\"images/Welsh_springer_spaniel_08203.jpg\" width=\"200\">\n",
    "\n",
    "It is not difficult to find other dog breed pairs with minimal inter-class variation (for instance, Curly-Coated Retrievers and American Water Spaniels).  \n",
    "\n",
    "Curly-Coated Retriever | American Water Spaniel\n",
    "- | -\n",
    "<img src=\"images/Curly-coated_retriever_03896.jpg\" width=\"200\"> | <img src=\"images/American_water_spaniel_00648.jpg\" width=\"200\">\n",
    "\n",
    "\n",
    "Likewise, recall that labradors come in yellow, chocolate, and black.  Your vision-based algorithm will have to conquer this high intra-class variation to determine how to classify all of these different shades as the same breed.  \n",
    "\n",
    "Yellow Labrador | Chocolate Labrador | Black Labrador\n",
    "- | -\n",
    "<img src=\"images/Labrador_retriever_06457.jpg\" width=\"150\"> | <img src=\"images/Labrador_retriever_06455.jpg\" width=\"240\"> | <img src=\"images/Labrador_retriever_06449.jpg\" width=\"220\">\n",
    "\n",
    "We also mention that random chance presents an exceptionally low bar: setting aside the fact that the classes are slightly imabalanced, a random guess will provide a correct answer roughly 1 in 133 times, which corresponds to an accuracy of less than 1%.  \n",
    "\n",
    "Remember that the practice is far ahead of the theory in deep learning.  Experiment with many different architectures, and trust your intuition.  And, of course, have fun! \n",
    "\n",
    "### Pre-process the Data\n",
    "\n",
    "We rescale the images by dividing every pixel in every image by 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True                 \n",
    "\n",
    "# pre-process the data for Keras\n",
    "train_tensors = paths_to_tensor(train_files).astype('float32')/255\n",
    "valid_tensors = paths_to_tensor(valid_files).astype('float32')/255\n",
    "test_tensors = paths_to_tensor(test_files).astype('float32')/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Model Architecture\n",
    "\n",
    "Create a CNN to classify dog breed.  At the end of your code cell block, summarize the layers of your model by executing the line:\n",
    "    \n",
    "        model.summary()\n",
    "\n",
    "We have imported some Python modules to get you started, but feel free to import as many modules as you need.  If you end up getting stuck, here's a hint that specifies a model that trains relatively fast on CPU and attains >1% test accuracy in 5 epochs:\n",
    "\n",
    "![Sample CNN](images/sample_cnn.png)\n",
    "           \n",
    "__Question 4:__ Outline the steps you took to get to your final CNN architecture and your reasoning at each step.  If you chose to use the hinted architecture above, describe why you think that CNN architecture should work well for the image classification task.\n",
    "\n",
    "__Answer:__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "row,col,ch = train_tensors.shape[1:]\n",
    "output_classes = len(train_targets[0][:])\n",
    "model = Sequential()\n",
    "\n",
    "### TODO: Define your architecture.\n",
    "# layer-1 convolution 2d \n",
    "model.add(Conv2D(16, 5, strides=2,input_shape=(row,col,ch) ,padding=\"same\", activation=\"relu\",\n",
    "                 kernel_initializer='glorot_uniform',bias_initializer='zeros',name ='conv1'))\n",
    "# First Maxpool layer kernel size =2 , strides = 1\n",
    "model.add(MaxPooling2D(pool_size=2))#(2, 2), strides=(1,1), padding='same', data_format=None,name ='Maxpool1'))\n",
    "  \n",
    "# layer-2 convolution 2d \n",
    "model.add(Conv2D(32,5,strides=2,padding=\"same\",name='conv2',activation=\"relu\"))\n",
    "# 2nd Maxpool layer kernel size =2 , strides = 1\n",
    "model.add(MaxPooling2D(pool_size=2))#(2, 2), strides=(1,1), padding='same', data_format=None,name ='Maxpool2'))\n",
    "          \n",
    "# # layer-3 convolution 2d \n",
    "# model.add(Conv2D(32, 5,strides=2,padding=\"same\", activation=\"relu\", \n",
    "#                  kernel_initializer='glorot_uniform',bias_initializer='zeros',name ='conv3'))\n",
    "# # 3rd Maxpool layer kernel size =2 , strides = 1\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2), strides=(1,1), padding='valid', data_format=None,name ='Maxpool3'))\n",
    "  \n",
    "# layer-4 convolution 2d \n",
    "model.add(Conv2D(64,5,strides=2,padding=\"same\", activation=\"relu\", \n",
    "                 kernel_initializer='glorot_uniform',bias_initializer='zeros',name ='conv4'))\n",
    "# 4th Maxpool layer kernel size =2 , strides = 1\n",
    "model.add(MaxPooling2D(pool_size=2))#, 2), strides=(1,1), padding='same', data_format=None,name ='Maxpool4'))\n",
    "          \n",
    "# layer-5 convolution 2d \n",
    "model.add(Conv2D(128,3,strides=2,padding=\"same\", activation=\"relu\", \n",
    "                 kernel_initializer='glorot_uniform',bias_initializer='zeros',name ='conv5'))\n",
    "# 5th Maxpool layer kernel size =2 , strides = 1\n",
    "model.add(MaxPooling2D(pool_size=2))#, strides=(1,1), padding='same', data_format=None,name ='Maxpool5'))\n",
    "\n",
    "# Flatten layer\n",
    "model.add(Flatten())\n",
    "# model.add(Dropout(0.7))\n",
    "          \n",
    "# Dense layer with 128 neurons and Relu activation\n",
    "# model.add(Dense(500, name='dense1', activation= 'relu'))\n",
    "# model.add(Dropout(0.7))\n",
    "          \n",
    "# Ouput layer with softmax activation\n",
    "model.add(Dense(output_classes, activation='softmax', name = 'output'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Train the Model\n",
    "\n",
    "Train your model in the code cell below.  Use model checkpointing to save the model that attains the best validation loss.\n",
    "\n",
    "You are welcome to [augment the training data](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html), but this is not a requirement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "### TODO: specify the number of epochs that you would like to use to train the model.\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "### Do NOT modify the code below this line.\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.from_scratch.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit(train_tensors, train_targets, \n",
    "          validation_data=(valid_tensors, valid_targets),\n",
    "          epochs=epochs, batch_size=20, callbacks=[checkpointer], verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Model with the Best Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('saved_models/weights.best.from_scratch.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Model\n",
    "\n",
    "Try out your model on the test dataset of dog images.  Ensure that your test accuracy is greater than 1%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get index of predicted dog breed for each image in test set\n",
    "dog_breed_predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(dog_breed_predictions)==np.argmax(test_targets, axis=1))/len(dog_breed_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step4'></a>\n",
    "## Step 4: Use a CNN to Classify Dog Breeds\n",
    "\n",
    "To reduce training time without sacrificing accuracy, we show you how to train a CNN using transfer learning.  In the following step, you will get a chance to use transfer learning to train your own CNN.\n",
    "\n",
    "### Obtain Bottleneck Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleneck_features = np.load('bottleneck_features/DogVGG16Data.npz')\n",
    "train_VGG16 = bottleneck_features['train']\n",
    "valid_VGG16 = bottleneck_features['valid']\n",
    "test_VGG16 = bottleneck_features['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture\n",
    "\n",
    "The model uses the the pre-trained VGG-16 model as a fixed feature extractor, where the last convolutional output of VGG-16 is fed as input to our model.  We only add a global average pooling layer and a fully connected layer, where the latter contains one node for each dog category and is equipped with a softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG16_model = Sequential()\n",
    "VGG16_model.add(GlobalAveragePooling2D(input_shape=train_VGG16.shape[1:]))\n",
    "VGG16_model.add(Dense(133, activation='softmax'))\n",
    "\n",
    "VGG16_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG16_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.VGG16.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "VGG16_model.fit(train_VGG16, train_targets, \n",
    "          validation_data=(valid_VGG16, valid_targets),\n",
    "          epochs=20, batch_size=20, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Model with the Best Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG16_model.load_weights('saved_models/weights.best.VGG16.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Model\n",
    "\n",
    "Now, we can use the CNN to test how well it identifies breed within our test dataset of dog images.  We print the test accuracy below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get index of predicted dog breed for each image in test set\n",
    "VGG16_predictions = [np.argmax(VGG16_model.predict(np.expand_dims(feature, axis=0))) for feature in test_VGG16]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(VGG16_predictions)==np.argmax(test_targets, axis=1))/len(VGG16_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Dog Breed with the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extract_bottleneck_features import *\n",
    "\n",
    "def VGG16_predict_breed(img_path):\n",
    "    # extract bottleneck features\n",
    "    bottleneck_feature = extract_VGG16(path_to_tensor(img_path))\n",
    "    # obtain predicted vector\n",
    "    predicted_vector = VGG16_model.predict(bottleneck_feature)\n",
    "    # return dog breed that is predicted by the model\n",
    "    return dog_names[np.argmax(predicted_vector)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step5'></a>\n",
    "## Step 5: Create a CNN to Classify Dog Breeds (using Transfer Learning)\n",
    "\n",
    "You will now use transfer learning to create a CNN that can identify dog breed from images.  Your CNN must attain at least 60% accuracy on the test set.\n",
    "\n",
    "In Step 4, we used transfer learning to create a CNN using VGG-16 bottleneck features.  In this section, you must use the bottleneck features from a different pre-trained model.  To make things easier for you, we have pre-computed the features for all of the networks that are currently available in Keras:\n",
    "- [VGG-19](https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/DogVGG19Data.npz) bottleneck features\n",
    "- [ResNet-50](https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/DogResnet50Data.npz) bottleneck features\n",
    "- [Inception](https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/DogInceptionV3Data.npz) bottleneck features\n",
    "- [Xception](https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/DogXceptionData.npz) bottleneck features\n",
    "\n",
    "The files are encoded as such:\n",
    "\n",
    "    Dog{network}Data.npz\n",
    "    \n",
    "where `{network}`, in the above filename, can be one of `VGG19`, `Resnet50`, `InceptionV3`, or `Xception`.  Pick one of the above architectures, download the corresponding bottleneck features, and store the downloaded file in the `bottleneck_features/` folder in the repository.\n",
    "\n",
    "### (IMPLEMENTATION) Obtain Bottleneck Features\n",
    "\n",
    "In the code block below, extract the bottleneck features corresponding to the train, test, and validation sets by running the following:\n",
    "\n",
    "    bottleneck_features = np.load('bottleneck_features/Dog{network}Data.npz')\n",
    "    train_{network} = bottleneck_features['train']\n",
    "    valid_{network} = bottleneck_features['valid']\n",
    "    test_{network} = bottleneck_features['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Obtain bottleneck features from another pre-trained CNN.\n",
    "bottleneck_features = np.load('bottleneck_features/DogVGG19Data.npz')\n",
    "train_VGG19 = bottleneck_features['train']\n",
    "valid_VGG19 = bottleneck_features['valid']\n",
    "test_VGG19 = bottleneck_features['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Model Architecture\n",
    "\n",
    "Create a CNN to classify dog breed.  At the end of your code cell block, summarize the layers of your model by executing the line:\n",
    "    \n",
    "        <your model's name>.summary()\n",
    "   \n",
    "__Question 5:__ Outline the steps you took to get to your final CNN architecture and your reasoning at each step.  Describe why you think the architecture is suitable for the current problem.\n",
    "\n",
    "__Answer:__ \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "global_average_pooling2d_3 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 133)               68229     \n",
      "=================================================================\n",
      "Total params: 68,229.0\n",
      "Trainable params: 68,229.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### TODO: Define your architecture.\n",
    "from keras import regularizers\n",
    "VGG19_model = Sequential()\n",
    "VGG19_model.add(GlobalAveragePooling2D(input_shape=train_VGG19.shape[1:]))\n",
    "VGG19_model.add(Dense(133, activation='softmax',kernel_regularizer=regularizers.l2(0.01)))\n",
    "\n",
    "VGG19_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Compile the model.\n",
    "import keras\n",
    "from keras import optimizers\n",
    "adam_optimiser = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999,decay=0.001)\n",
    "nadam_optimizer = optimizers.Nadam(lr=0.001, beta_1=0.9, beta_2=0.999,schedule_decay=0.004)\n",
    "VGG19_model.compile(loss='categorical_crossentropy', optimizer=adam_optimiser, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Train the Model\n",
    "\n",
    "Train your model in the code cell below.  Use model checkpointing to save the model that attains the best validation loss.  \n",
    "\n",
    "You are welcome to [augment the training data](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html), but this is not a requirement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6680 samples, validate on 835 samples\n",
      "Epoch 1/30\n",
      "6624/6680 [============================>.] - ETA: 738s - loss: 16.2432 - acc: 0.06 - ETA: 150s - loss: 16.4598 - acc: 0.01 - ETA: 69s - loss: 16.2565 - acc: 0.0057 - ETA: 52s - loss: 16.1275 - acc: 0.004 - ETA: 37s - loss: 15.5754 - acc: 0.020 - ETA: 29s - loss: 15.3622 - acc: 0.027 - ETA: 25s - loss: 15.3557 - acc: 0.027 - ETA: 22s - loss: 15.1538 - acc: 0.030 - ETA: 19s - loss: 14.9389 - acc: 0.033 - ETA: 17s - loss: 14.6683 - acc: 0.036 - ETA: 15s - loss: 14.3934 - acc: 0.040 - ETA: 14s - loss: 14.0819 - acc: 0.044 - ETA: 13s - loss: 13.8974 - acc: 0.044 - ETA: 12s - loss: 13.6145 - acc: 0.049 - ETA: 11s - loss: 13.3889 - acc: 0.049 - ETA: 10s - loss: 13.1447 - acc: 0.057 - ETA: 9s - loss: 12.8689 - acc: 0.066 - ETA: 9s - loss: 12.6035 - acc: 0.07 - ETA: 8s - loss: 12.4048 - acc: 0.07 - ETA: 8s - loss: 12.1683 - acc: 0.08 - ETA: 7s - loss: 11.9641 - acc: 0.08 - ETA: 7s - loss: 11.8240 - acc: 0.09 - ETA: 7s - loss: 11.6214 - acc: 0.09 - ETA: 6s - loss: 11.3906 - acc: 0.10 - ETA: 6s - loss: 11.1972 - acc: 0.10 - ETA: 6s - loss: 11.0493 - acc: 0.11 - ETA: 6s - loss: 10.8528 - acc: 0.11 - ETA: 5s - loss: 10.6797 - acc: 0.12 - ETA: 5s - loss: 10.5153 - acc: 0.12 - ETA: 5s - loss: 10.3602 - acc: 0.13 - ETA: 5s - loss: 10.1916 - acc: 0.13 - ETA: 4s - loss: 10.0601 - acc: 0.14 - ETA: 4s - loss: 9.9371 - acc: 0.1508 - ETA: 4s - loss: 9.8337 - acc: 0.156 - ETA: 4s - loss: 9.6700 - acc: 0.162 - ETA: 4s - loss: 9.5293 - acc: 0.166 - ETA: 4s - loss: 9.3927 - acc: 0.173 - ETA: 3s - loss: 9.2301 - acc: 0.184 - ETA: 3s - loss: 9.1114 - acc: 0.191 - ETA: 3s - loss: 9.0083 - acc: 0.195 - ETA: 3s - loss: 8.9053 - acc: 0.201 - ETA: 3s - loss: 8.7798 - acc: 0.209 - ETA: 3s - loss: 8.7004 - acc: 0.212 - ETA: 3s - loss: 8.5836 - acc: 0.219 - ETA: 2s - loss: 8.4707 - acc: 0.226 - ETA: 2s - loss: 8.3788 - acc: 0.231 - ETA: 2s - loss: 8.2831 - acc: 0.236 - ETA: 2s - loss: 8.2091 - acc: 0.242 - ETA: 2s - loss: 8.1118 - acc: 0.247 - ETA: 2s - loss: 8.0343 - acc: 0.251 - ETA: 2s - loss: 7.9518 - acc: 0.255 - ETA: 2s - loss: 7.8779 - acc: 0.259 - ETA: 2s - loss: 7.7954 - acc: 0.264 - ETA: 1s - loss: 7.7119 - acc: 0.269 - ETA: 1s - loss: 7.6295 - acc: 0.272 - ETA: 1s - loss: 7.5717 - acc: 0.275 - ETA: 1s - loss: 7.5064 - acc: 0.279 - ETA: 1s - loss: 7.4377 - acc: 0.284 - ETA: 1s - loss: 7.3883 - acc: 0.286 - ETA: 1s - loss: 7.3380 - acc: 0.290 - ETA: 1s - loss: 7.2989 - acc: 0.292 - ETA: 1s - loss: 7.2590 - acc: 0.294 - ETA: 1s - loss: 7.2266 - acc: 0.296 - ETA: 1s - loss: 7.1814 - acc: 0.299 - ETA: 1s - loss: 7.1285 - acc: 0.302 - ETA: 1s - loss: 7.0711 - acc: 0.306 - ETA: 0s - loss: 7.0155 - acc: 0.310 - ETA: 0s - loss: 6.9657 - acc: 0.313 - ETA: 0s - loss: 6.9183 - acc: 0.315 - ETA: 0s - loss: 6.8706 - acc: 0.317 - ETA: 0s - loss: 6.8177 - acc: 0.320 - ETA: 0s - loss: 6.7745 - acc: 0.323 - ETA: 0s - loss: 6.7258 - acc: 0.326 - ETA: 0s - loss: 6.6660 - acc: 0.330 - ETA: 0s - loss: 6.6138 - acc: 0.332 - ETA: 0s - loss: 6.5727 - acc: 0.336 - ETA: 0s - loss: 6.5283 - acc: 0.338 - ETA: 0s - loss: 6.4938 - acc: 0.3403Epoch 00000: val_loss improved from inf to 3.10041, saving model to saved_models/weights.best.VGG19.hdf5\n",
      "6680/6680 [==============================] - 7s - loss: 6.4663 - acc: 0.3422 - val_loss: 3.1004 - val_acc: 0.5629\n",
      "Epoch 2/30\n",
      "6656/6680 [============================>.] - ETA: 4s - loss: 3.2571 - acc: 0.500 - ETA: 4s - loss: 2.3616 - acc: 0.697 - ETA: 4s - loss: 2.3631 - acc: 0.687 - ETA: 4s - loss: 2.4525 - acc: 0.695 - ETA: 4s - loss: 2.5048 - acc: 0.676 - ETA: 4s - loss: 2.4271 - acc: 0.694 - ETA: 4s - loss: 2.4290 - acc: 0.699 - ETA: 4s - loss: 2.3691 - acc: 0.699 - ETA: 4s - loss: 2.3552 - acc: 0.700 - ETA: 3s - loss: 2.3171 - acc: 0.704 - ETA: 3s - loss: 2.3048 - acc: 0.704 - ETA: 3s - loss: 2.3344 - acc: 0.703 - ETA: 3s - loss: 2.3731 - acc: 0.701 - ETA: 3s - loss: 2.3597 - acc: 0.702 - ETA: 3s - loss: 2.3441 - acc: 0.706 - ETA: 3s - loss: 2.3125 - acc: 0.710 - ETA: 3s - loss: 2.2888 - acc: 0.710 - ETA: 3s - loss: 2.2674 - acc: 0.712 - ETA: 3s - loss: 2.2388 - acc: 0.713 - ETA: 3s - loss: 2.2498 - acc: 0.714 - ETA: 3s - loss: 2.2459 - acc: 0.714 - ETA: 3s - loss: 2.2220 - acc: 0.719 - ETA: 3s - loss: 2.2003 - acc: 0.721 - ETA: 3s - loss: 2.1766 - acc: 0.725 - ETA: 2s - loss: 2.1657 - acc: 0.727 - ETA: 2s - loss: 2.1506 - acc: 0.727 - ETA: 2s - loss: 2.1500 - acc: 0.726 - ETA: 2s - loss: 2.1390 - acc: 0.728 - ETA: 2s - loss: 2.1253 - acc: 0.728 - ETA: 2s - loss: 2.1269 - acc: 0.727 - ETA: 2s - loss: 2.1136 - acc: 0.729 - ETA: 2s - loss: 2.1189 - acc: 0.726 - ETA: 2s - loss: 2.1065 - acc: 0.727 - ETA: 2s - loss: 2.1046 - acc: 0.727 - ETA: 2s - loss: 2.0881 - acc: 0.730 - ETA: 2s - loss: 2.0865 - acc: 0.730 - ETA: 2s - loss: 2.0906 - acc: 0.730 - ETA: 2s - loss: 2.0894 - acc: 0.730 - ETA: 2s - loss: 2.0821 - acc: 0.730 - ETA: 2s - loss: 2.0883 - acc: 0.728 - ETA: 2s - loss: 2.0848 - acc: 0.730 - ETA: 2s - loss: 2.0741 - acc: 0.730 - ETA: 2s - loss: 2.0689 - acc: 0.730 - ETA: 2s - loss: 2.0670 - acc: 0.730 - ETA: 1s - loss: 2.0524 - acc: 0.733 - ETA: 1s - loss: 2.0473 - acc: 0.734 - ETA: 1s - loss: 2.0416 - acc: 0.734 - ETA: 1s - loss: 2.0428 - acc: 0.734 - ETA: 1s - loss: 2.0297 - acc: 0.736 - ETA: 1s - loss: 2.0299 - acc: 0.735 - ETA: 1s - loss: 2.0265 - acc: 0.736 - ETA: 1s - loss: 2.0245 - acc: 0.736 - ETA: 1s - loss: 2.0306 - acc: 0.735 - ETA: 1s - loss: 2.0339 - acc: 0.734 - ETA: 1s - loss: 2.0402 - acc: 0.734 - ETA: 1s - loss: 2.0331 - acc: 0.735 - ETA: 1s - loss: 2.0353 - acc: 0.735 - ETA: 1s - loss: 2.0277 - acc: 0.735 - ETA: 1s - loss: 2.0254 - acc: 0.735 - ETA: 1s - loss: 2.0275 - acc: 0.734 - ETA: 1s - loss: 2.0355 - acc: 0.733 - ETA: 1s - loss: 2.0314 - acc: 0.734 - ETA: 0s - loss: 2.0401 - acc: 0.733 - ETA: 0s - loss: 2.0375 - acc: 0.733 - ETA: 0s - loss: 2.0338 - acc: 0.734 - ETA: 0s - loss: 2.0331 - acc: 0.735 - ETA: 0s - loss: 2.0369 - acc: 0.734 - ETA: 0s - loss: 2.0346 - acc: 0.734 - ETA: 0s - loss: 2.0379 - acc: 0.733 - ETA: 0s - loss: 2.0361 - acc: 0.734 - ETA: 0s - loss: 2.0343 - acc: 0.734 - ETA: 0s - loss: 2.0280 - acc: 0.736 - ETA: 0s - loss: 2.0273 - acc: 0.735 - ETA: 0s - loss: 2.0262 - acc: 0.736 - ETA: 0s - loss: 2.0228 - acc: 0.735 - ETA: 0s - loss: 2.0190 - acc: 0.735 - ETA: 0s - loss: 2.0178 - acc: 0.735 - ETA: 0s - loss: 2.0127 - acc: 0.736 - ETA: 0s - loss: 2.0115 - acc: 0.736 - ETA: 0s - loss: 2.0101 - acc: 0.7366Epoch 00001: val_loss improved from 3.10041 to 2.36402, saving model to saved_models/weights.best.VGG19.hdf5\n",
      "6680/6680 [==============================] - 4s - loss: 2.0094 - acc: 0.7365 - val_loss: 2.3640 - val_acc: 0.6683\n",
      "Epoch 3/30\n",
      "6672/6680 [============================>.] - ETA: 4s - loss: 1.9040 - acc: 0.625 - ETA: 4s - loss: 1.4974 - acc: 0.812 - ETA: 4s - loss: 1.3565 - acc: 0.818 - ETA: 4s - loss: 1.3607 - acc: 0.849 - ETA: 4s - loss: 1.3094 - acc: 0.864 - ETA: 3s - loss: 1.3052 - acc: 0.855 - ETA: 3s - loss: 1.3156 - acc: 0.852 - ETA: 4s - loss: 1.3179 - acc: 0.853 - ETA: 4s - loss: 1.3605 - acc: 0.851 - ETA: 4s - loss: 1.3445 - acc: 0.857 - ETA: 4s - loss: 1.3842 - acc: 0.852 - ETA: 4s - loss: 1.4177 - acc: 0.851 - ETA: 4s - loss: 1.4263 - acc: 0.855 - ETA: 4s - loss: 1.3978 - acc: 0.859 - ETA: 4s - loss: 1.3864 - acc: 0.859 - ETA: 4s - loss: 1.4214 - acc: 0.859 - ETA: 4s - loss: 1.3966 - acc: 0.866 - ETA: 4s - loss: 1.3998 - acc: 0.867 - ETA: 4s - loss: 1.3925 - acc: 0.863 - ETA: 4s - loss: 1.3834 - acc: 0.863 - ETA: 4s - loss: 1.3735 - acc: 0.865 - ETA: 3s - loss: 1.3772 - acc: 0.863 - ETA: 3s - loss: 1.3828 - acc: 0.859 - ETA: 3s - loss: 1.3711 - acc: 0.862 - ETA: 3s - loss: 1.3671 - acc: 0.861 - ETA: 3s - loss: 1.3762 - acc: 0.862 - ETA: 3s - loss: 1.3737 - acc: 0.859 - ETA: 3s - loss: 1.3682 - acc: 0.861 - ETA: 3s - loss: 1.3659 - acc: 0.861 - ETA: 3s - loss: 1.3746 - acc: 0.861 - ETA: 3s - loss: 1.3777 - acc: 0.862 - ETA: 3s - loss: 1.3740 - acc: 0.860 - ETA: 3s - loss: 1.3702 - acc: 0.860 - ETA: 3s - loss: 1.3643 - acc: 0.860 - ETA: 3s - loss: 1.3669 - acc: 0.860 - ETA: 3s - loss: 1.3710 - acc: 0.858 - ETA: 3s - loss: 1.3645 - acc: 0.859 - ETA: 3s - loss: 1.3588 - acc: 0.859 - ETA: 3s - loss: 1.3616 - acc: 0.858 - ETA: 2s - loss: 1.3591 - acc: 0.857 - ETA: 2s - loss: 1.3537 - acc: 0.859 - ETA: 2s - loss: 1.3487 - acc: 0.860 - ETA: 2s - loss: 1.3573 - acc: 0.859 - ETA: 2s - loss: 1.3559 - acc: 0.859 - ETA: 2s - loss: 1.3542 - acc: 0.859 - ETA: 2s - loss: 1.3509 - acc: 0.859 - ETA: 2s - loss: 1.3561 - acc: 0.858 - ETA: 2s - loss: 1.3627 - acc: 0.858 - ETA: 2s - loss: 1.3569 - acc: 0.859 - ETA: 2s - loss: 1.3502 - acc: 0.859 - ETA: 2s - loss: 1.3422 - acc: 0.860 - ETA: 2s - loss: 1.3375 - acc: 0.860 - ETA: 1s - loss: 1.3338 - acc: 0.860 - ETA: 1s - loss: 1.3327 - acc: 0.861 - ETA: 1s - loss: 1.3289 - acc: 0.862 - ETA: 1s - loss: 1.3244 - acc: 0.862 - ETA: 1s - loss: 1.3251 - acc: 0.861 - ETA: 1s - loss: 1.3234 - acc: 0.861 - ETA: 1s - loss: 1.3255 - acc: 0.862 - ETA: 1s - loss: 1.3321 - acc: 0.861 - ETA: 1s - loss: 1.3306 - acc: 0.861 - ETA: 1s - loss: 1.3303 - acc: 0.861 - ETA: 1s - loss: 1.3289 - acc: 0.860 - ETA: 1s - loss: 1.3259 - acc: 0.860 - ETA: 1s - loss: 1.3311 - acc: 0.860 - ETA: 1s - loss: 1.3377 - acc: 0.860 - ETA: 1s - loss: 1.3455 - acc: 0.860 - ETA: 1s - loss: 1.3402 - acc: 0.861 - ETA: 1s - loss: 1.3360 - acc: 0.862 - ETA: 1s - loss: 1.3367 - acc: 0.862 - ETA: 0s - loss: 1.3416 - acc: 0.860 - ETA: 0s - loss: 1.3403 - acc: 0.860 - ETA: 0s - loss: 1.3410 - acc: 0.860 - ETA: 0s - loss: 1.3422 - acc: 0.860 - ETA: 0s - loss: 1.3448 - acc: 0.859 - ETA: 0s - loss: 1.3511 - acc: 0.858 - ETA: 0s - loss: 1.3505 - acc: 0.859 - ETA: 0s - loss: 1.3449 - acc: 0.860 - ETA: 0s - loss: 1.3424 - acc: 0.860 - ETA: 0s - loss: 1.3451 - acc: 0.860 - ETA: 0s - loss: 1.3418 - acc: 0.860 - ETA: 0s - loss: 1.3443 - acc: 0.860 - ETA: 0s - loss: 1.3437 - acc: 0.860 - ETA: 0s - loss: 1.3428 - acc: 0.860 - ETA: 0s - loss: 1.3385 - acc: 0.861 - ETA: 0s - loss: 1.3405 - acc: 0.861 - ETA: 0s - loss: 1.3395 - acc: 0.8611Epoch 00002: val_loss improved from 2.36402 to 2.04265, saving model to saved_models/weights.best.VGG19.hdf5\n",
      "6680/6680 [==============================] - 5s - loss: 1.3399 - acc: 0.8611 - val_loss: 2.0426 - val_acc: 0.6922\n",
      "Epoch 4/30\n",
      "6640/6680 [============================>.] - ETA: 4s - loss: 0.7678 - acc: 1.000 - ETA: 4s - loss: 1.0324 - acc: 0.947 - ETA: 4s - loss: 1.0069 - acc: 0.943 - ETA: 4s - loss: 1.0684 - acc: 0.937 - ETA: 5s - loss: 1.0422 - acc: 0.940 - ETA: 4s - loss: 1.0568 - acc: 0.940 - ETA: 4s - loss: 1.0778 - acc: 0.937 - ETA: 4s - loss: 1.0932 - acc: 0.928 - ETA: 4s - loss: 1.0778 - acc: 0.924 - ETA: 4s - loss: 1.0522 - acc: 0.930 - ETA: 4s - loss: 1.0554 - acc: 0.931 - ETA: 4s - loss: 1.0414 - acc: 0.934 - ETA: 3s - loss: 1.0368 - acc: 0.930 - ETA: 3s - loss: 1.0231 - acc: 0.932 - ETA: 3s - loss: 1.0207 - acc: 0.933 - ETA: 3s - loss: 1.0190 - acc: 0.934 - ETA: 3s - loss: 1.0064 - acc: 0.938 - ETA: 3s - loss: 0.9978 - acc: 0.940 - ETA: 3s - loss: 1.0031 - acc: 0.938 - ETA: 3s - loss: 0.9945 - acc: 0.940 - ETA: 3s - loss: 0.9925 - acc: 0.939 - ETA: 3s - loss: 0.9915 - acc: 0.938 - ETA: 3s - loss: 0.9929 - acc: 0.938 - ETA: 3s - loss: 0.9888 - acc: 0.939 - ETA: 3s - loss: 0.9869 - acc: 0.938 - ETA: 3s - loss: 0.9846 - acc: 0.937 - ETA: 3s - loss: 0.9825 - acc: 0.937 - ETA: 3s - loss: 0.9781 - acc: 0.939 - ETA: 3s - loss: 0.9744 - acc: 0.939 - ETA: 3s - loss: 0.9735 - acc: 0.939 - ETA: 3s - loss: 0.9739 - acc: 0.939 - ETA: 2s - loss: 0.9719 - acc: 0.940 - ETA: 2s - loss: 0.9694 - acc: 0.939 - ETA: 2s - loss: 0.9655 - acc: 0.940 - ETA: 2s - loss: 0.9631 - acc: 0.939 - ETA: 2s - loss: 0.9615 - acc: 0.939 - ETA: 2s - loss: 0.9622 - acc: 0.939 - ETA: 2s - loss: 0.9620 - acc: 0.937 - ETA: 2s - loss: 0.9603 - acc: 0.937 - ETA: 2s - loss: 0.9608 - acc: 0.936 - ETA: 2s - loss: 0.9625 - acc: 0.935 - ETA: 2s - loss: 0.9624 - acc: 0.935 - ETA: 2s - loss: 0.9615 - acc: 0.935 - ETA: 2s - loss: 0.9613 - acc: 0.935 - ETA: 2s - loss: 0.9609 - acc: 0.934 - ETA: 2s - loss: 0.9609 - acc: 0.934 - ETA: 2s - loss: 0.9634 - acc: 0.933 - ETA: 2s - loss: 0.9625 - acc: 0.933 - ETA: 2s - loss: 0.9614 - acc: 0.932 - ETA: 2s - loss: 0.9650 - acc: 0.932 - ETA: 1s - loss: 0.9637 - acc: 0.932 - ETA: 1s - loss: 0.9628 - acc: 0.932 - ETA: 1s - loss: 0.9643 - acc: 0.931 - ETA: 1s - loss: 0.9634 - acc: 0.930 - ETA: 1s - loss: 0.9626 - acc: 0.931 - ETA: 1s - loss: 0.9623 - acc: 0.931 - ETA: 1s - loss: 0.9647 - acc: 0.930 - ETA: 1s - loss: 0.9654 - acc: 0.929 - ETA: 1s - loss: 0.9669 - acc: 0.929 - ETA: 1s - loss: 0.9676 - acc: 0.928 - ETA: 1s - loss: 0.9697 - acc: 0.927 - ETA: 1s - loss: 0.9686 - acc: 0.928 - ETA: 1s - loss: 0.9723 - acc: 0.927 - ETA: 1s - loss: 0.9696 - acc: 0.927 - ETA: 1s - loss: 0.9694 - acc: 0.927 - ETA: 1s - loss: 0.9762 - acc: 0.925 - ETA: 0s - loss: 0.9797 - acc: 0.924 - ETA: 0s - loss: 0.9795 - acc: 0.924 - ETA: 0s - loss: 0.9799 - acc: 0.923 - ETA: 0s - loss: 0.9780 - acc: 0.923 - ETA: 0s - loss: 0.9766 - acc: 0.923 - ETA: 0s - loss: 0.9773 - acc: 0.924 - ETA: 0s - loss: 0.9774 - acc: 0.923 - ETA: 0s - loss: 0.9764 - acc: 0.923 - ETA: 0s - loss: 0.9770 - acc: 0.922 - ETA: 0s - loss: 0.9753 - acc: 0.923 - ETA: 0s - loss: 0.9728 - acc: 0.923 - ETA: 0s - loss: 0.9718 - acc: 0.924 - ETA: 0s - loss: 0.9701 - acc: 0.923 - ETA: 0s - loss: 0.9709 - acc: 0.923 - ETA: 0s - loss: 0.9696 - acc: 0.924 - ETA: 0s - loss: 0.9682 - acc: 0.924 - ETA: 0s - loss: 0.9692 - acc: 0.9236Epoch 00003: val_loss improved from 2.04265 to 1.78487, saving model to saved_models/weights.best.VGG19.hdf5\n",
      "6680/6680 [==============================] - 4s - loss: 0.9682 - acc: 0.9240 - val_loss: 1.7849 - val_acc: 0.7150\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6592/6680 [============================>.] - ETA: 4s - loss: 0.7146 - acc: 1.000 - ETA: 4s - loss: 0.8018 - acc: 0.968 - ETA: 4s - loss: 0.8172 - acc: 0.954 - ETA: 4s - loss: 0.8109 - acc: 0.960 - ETA: 4s - loss: 0.8278 - acc: 0.958 - ETA: 4s - loss: 0.8299 - acc: 0.962 - ETA: 4s - loss: 0.8274 - acc: 0.961 - ETA: 4s - loss: 0.8289 - acc: 0.958 - ETA: 4s - loss: 0.8188 - acc: 0.962 - ETA: 4s - loss: 0.8141 - acc: 0.960 - ETA: 4s - loss: 0.8168 - acc: 0.960 - ETA: 4s - loss: 0.8071 - acc: 0.963 - ETA: 4s - loss: 0.8066 - acc: 0.964 - ETA: 4s - loss: 0.8101 - acc: 0.962 - ETA: 4s - loss: 0.8074 - acc: 0.961 - ETA: 3s - loss: 0.8108 - acc: 0.959 - ETA: 3s - loss: 0.8091 - acc: 0.959 - ETA: 3s - loss: 0.8043 - acc: 0.961 - ETA: 3s - loss: 0.8020 - acc: 0.962 - ETA: 3s - loss: 0.7999 - acc: 0.962 - ETA: 3s - loss: 0.8023 - acc: 0.961 - ETA: 3s - loss: 0.7982 - acc: 0.963 - ETA: 3s - loss: 0.7989 - acc: 0.961 - ETA: 3s - loss: 0.7975 - acc: 0.961 - ETA: 3s - loss: 0.7950 - acc: 0.961 - ETA: 3s - loss: 0.7951 - acc: 0.962 - ETA: 3s - loss: 0.7937 - acc: 0.962 - ETA: 3s - loss: 0.7919 - acc: 0.962 - ETA: 2s - loss: 0.7910 - acc: 0.962 - ETA: 2s - loss: 0.7907 - acc: 0.962 - ETA: 2s - loss: 0.7901 - acc: 0.962 - ETA: 2s - loss: 0.7962 - acc: 0.961 - ETA: 2s - loss: 0.7939 - acc: 0.961 - ETA: 2s - loss: 0.7918 - acc: 0.963 - ETA: 2s - loss: 0.7910 - acc: 0.963 - ETA: 2s - loss: 0.7986 - acc: 0.961 - ETA: 2s - loss: 0.7955 - acc: 0.962 - ETA: 2s - loss: 0.7947 - acc: 0.962 - ETA: 2s - loss: 0.7970 - acc: 0.961 - ETA: 2s - loss: 0.7953 - acc: 0.961 - ETA: 2s - loss: 0.7942 - acc: 0.961 - ETA: 2s - loss: 0.7930 - acc: 0.962 - ETA: 2s - loss: 0.7915 - acc: 0.961 - ETA: 1s - loss: 0.7934 - acc: 0.961 - ETA: 1s - loss: 0.7911 - acc: 0.961 - ETA: 1s - loss: 0.7893 - acc: 0.962 - ETA: 1s - loss: 0.7891 - acc: 0.962 - ETA: 1s - loss: 0.7884 - acc: 0.962 - ETA: 1s - loss: 0.7906 - acc: 0.961 - ETA: 1s - loss: 0.7901 - acc: 0.960 - ETA: 1s - loss: 0.7897 - acc: 0.960 - ETA: 1s - loss: 0.7902 - acc: 0.960 - ETA: 1s - loss: 0.7930 - acc: 0.959 - ETA: 1s - loss: 0.7938 - acc: 0.959 - ETA: 1s - loss: 0.7928 - acc: 0.959 - ETA: 1s - loss: 0.7918 - acc: 0.960 - ETA: 1s - loss: 0.7919 - acc: 0.960 - ETA: 1s - loss: 0.7952 - acc: 0.960 - ETA: 1s - loss: 0.7960 - acc: 0.960 - ETA: 1s - loss: 0.7949 - acc: 0.960 - ETA: 0s - loss: 0.7935 - acc: 0.960 - ETA: 0s - loss: 0.7925 - acc: 0.960 - ETA: 0s - loss: 0.7920 - acc: 0.960 - ETA: 0s - loss: 0.7916 - acc: 0.960 - ETA: 0s - loss: 0.7923 - acc: 0.960 - ETA: 0s - loss: 0.7906 - acc: 0.960 - ETA: 0s - loss: 0.7892 - acc: 0.961 - ETA: 0s - loss: 0.7904 - acc: 0.960 - ETA: 0s - loss: 0.7903 - acc: 0.960 - ETA: 0s - loss: 0.7905 - acc: 0.960 - ETA: 0s - loss: 0.7906 - acc: 0.960 - ETA: 0s - loss: 0.7899 - acc: 0.960 - ETA: 0s - loss: 0.7895 - acc: 0.960 - ETA: 0s - loss: 0.7894 - acc: 0.960 - ETA: 0s - loss: 0.7887 - acc: 0.960 - ETA: 0s - loss: 0.7882 - acc: 0.9607Epoch 00004: val_loss improved from 1.78487 to 1.63720, saving model to saved_models/weights.best.VGG19.hdf5\n",
      "6680/6680 [==============================] - 4s - loss: 0.7882 - acc: 0.9602 - val_loss: 1.6372 - val_acc: 0.7293\n",
      "Epoch 6/30\n",
      "6592/6680 [============================>.] - ETA: 5s - loss: 0.7585 - acc: 0.937 - ETA: 4s - loss: 0.7020 - acc: 0.979 - ETA: 4s - loss: 0.7038 - acc: 0.979 - ETA: 4s - loss: 0.7087 - acc: 0.975 - ETA: 3s - loss: 0.6993 - acc: 0.976 - ETA: 3s - loss: 0.6989 - acc: 0.975 - ETA: 3s - loss: 0.7218 - acc: 0.975 - ETA: 3s - loss: 0.7180 - acc: 0.977 - ETA: 3s - loss: 0.7147 - acc: 0.976 - ETA: 3s - loss: 0.7101 - acc: 0.977 - ETA: 3s - loss: 0.7039 - acc: 0.979 - ETA: 3s - loss: 0.7023 - acc: 0.978 - ETA: 3s - loss: 0.7025 - acc: 0.976 - ETA: 3s - loss: 0.7011 - acc: 0.975 - ETA: 3s - loss: 0.6990 - acc: 0.976 - ETA: 3s - loss: 0.6995 - acc: 0.977 - ETA: 3s - loss: 0.6980 - acc: 0.977 - ETA: 3s - loss: 0.7068 - acc: 0.977 - ETA: 3s - loss: 0.7056 - acc: 0.977 - ETA: 3s - loss: 0.7028 - acc: 0.978 - ETA: 2s - loss: 0.7037 - acc: 0.977 - ETA: 2s - loss: 0.7011 - acc: 0.977 - ETA: 2s - loss: 0.7000 - acc: 0.977 - ETA: 2s - loss: 0.6981 - acc: 0.978 - ETA: 2s - loss: 0.6963 - acc: 0.978 - ETA: 2s - loss: 0.6936 - acc: 0.978 - ETA: 2s - loss: 0.6942 - acc: 0.977 - ETA: 2s - loss: 0.6935 - acc: 0.976 - ETA: 2s - loss: 0.6937 - acc: 0.976 - ETA: 2s - loss: 0.6938 - acc: 0.975 - ETA: 2s - loss: 0.6926 - acc: 0.975 - ETA: 2s - loss: 0.6909 - acc: 0.976 - ETA: 2s - loss: 0.6934 - acc: 0.975 - ETA: 2s - loss: 0.6939 - acc: 0.975 - ETA: 2s - loss: 0.6943 - acc: 0.975 - ETA: 2s - loss: 0.6927 - acc: 0.975 - ETA: 2s - loss: 0.6919 - acc: 0.975 - ETA: 2s - loss: 0.6913 - acc: 0.976 - ETA: 1s - loss: 0.6913 - acc: 0.976 - ETA: 1s - loss: 0.6908 - acc: 0.976 - ETA: 1s - loss: 0.6898 - acc: 0.976 - ETA: 1s - loss: 0.6885 - acc: 0.976 - ETA: 1s - loss: 0.6880 - acc: 0.977 - ETA: 1s - loss: 0.6876 - acc: 0.977 - ETA: 1s - loss: 0.6861 - acc: 0.977 - ETA: 1s - loss: 0.6854 - acc: 0.978 - ETA: 1s - loss: 0.6860 - acc: 0.978 - ETA: 1s - loss: 0.6856 - acc: 0.978 - ETA: 1s - loss: 0.6850 - acc: 0.978 - ETA: 1s - loss: 0.6839 - acc: 0.978 - ETA: 1s - loss: 0.6836 - acc: 0.978 - ETA: 1s - loss: 0.6837 - acc: 0.978 - ETA: 1s - loss: 0.6834 - acc: 0.978 - ETA: 1s - loss: 0.6835 - acc: 0.978 - ETA: 1s - loss: 0.6827 - acc: 0.978 - ETA: 1s - loss: 0.6828 - acc: 0.978 - ETA: 1s - loss: 0.6819 - acc: 0.978 - ETA: 1s - loss: 0.6815 - acc: 0.978 - ETA: 1s - loss: 0.6814 - acc: 0.978 - ETA: 1s - loss: 0.6805 - acc: 0.978 - ETA: 0s - loss: 0.6801 - acc: 0.978 - ETA: 0s - loss: 0.6809 - acc: 0.978 - ETA: 0s - loss: 0.6824 - acc: 0.977 - ETA: 0s - loss: 0.6825 - acc: 0.977 - ETA: 0s - loss: 0.6819 - acc: 0.977 - ETA: 0s - loss: 0.6819 - acc: 0.977 - ETA: 0s - loss: 0.6814 - acc: 0.977 - ETA: 0s - loss: 0.6817 - acc: 0.977 - ETA: 0s - loss: 0.6812 - acc: 0.977 - ETA: 0s - loss: 0.6808 - acc: 0.977 - ETA: 0s - loss: 0.6804 - acc: 0.977 - ETA: 0s - loss: 0.6806 - acc: 0.977 - ETA: 0s - loss: 0.6802 - acc: 0.977 - ETA: 0s - loss: 0.6798 - acc: 0.977 - ETA: 0s - loss: 0.6793 - acc: 0.977 - ETA: 0s - loss: 0.6790 - acc: 0.977 - ETA: 0s - loss: 0.6786 - acc: 0.978 - ETA: 0s - loss: 0.6798 - acc: 0.977 - ETA: 0s - loss: 0.6792 - acc: 0.9772Epoch 00005: val_loss improved from 1.63720 to 1.52550, saving model to saved_models/weights.best.VGG19.hdf5\n",
      "6680/6680 [==============================] - 4s - loss: 0.6796 - acc: 0.9768 - val_loss: 1.5255 - val_acc: 0.7557\n",
      "Epoch 7/30\n",
      "6608/6680 [============================>.] - ETA: 4s - loss: 0.6620 - acc: 0.937 - ETA: 4s - loss: 0.6331 - acc: 0.979 - ETA: 3s - loss: 0.6149 - acc: 0.984 - ETA: 4s - loss: 0.6274 - acc: 0.981 - ETA: 3s - loss: 0.6567 - acc: 0.978 - ETA: 3s - loss: 0.6501 - acc: 0.979 - ETA: 3s - loss: 0.6411 - acc: 0.983 - ETA: 3s - loss: 0.6382 - acc: 0.984 - ETA: 3s - loss: 0.6364 - acc: 0.984 - ETA: 3s - loss: 0.6358 - acc: 0.982 - ETA: 3s - loss: 0.6346 - acc: 0.981 - ETA: 3s - loss: 0.6322 - acc: 0.981 - ETA: 3s - loss: 0.6287 - acc: 0.983 - ETA: 3s - loss: 0.6259 - acc: 0.984 - ETA: 3s - loss: 0.6232 - acc: 0.985 - ETA: 3s - loss: 0.6232 - acc: 0.984 - ETA: 3s - loss: 0.6222 - acc: 0.983 - ETA: 3s - loss: 0.6207 - acc: 0.983 - ETA: 3s - loss: 0.6198 - acc: 0.984 - ETA: 3s - loss: 0.6200 - acc: 0.983 - ETA: 2s - loss: 0.6179 - acc: 0.984 - ETA: 2s - loss: 0.6167 - acc: 0.985 - ETA: 2s - loss: 0.6157 - acc: 0.985 - ETA: 2s - loss: 0.6149 - acc: 0.986 - ETA: 2s - loss: 0.6137 - acc: 0.986 - ETA: 2s - loss: 0.6149 - acc: 0.986 - ETA: 2s - loss: 0.6148 - acc: 0.985 - ETA: 2s - loss: 0.6140 - acc: 0.986 - ETA: 2s - loss: 0.6131 - acc: 0.986 - ETA: 2s - loss: 0.6129 - acc: 0.986 - ETA: 2s - loss: 0.6117 - acc: 0.987 - ETA: 2s - loss: 0.6114 - acc: 0.987 - ETA: 2s - loss: 0.6115 - acc: 0.987 - ETA: 2s - loss: 0.6101 - acc: 0.987 - ETA: 2s - loss: 0.6105 - acc: 0.987 - ETA: 2s - loss: 0.6092 - acc: 0.987 - ETA: 2s - loss: 0.6086 - acc: 0.987 - ETA: 2s - loss: 0.6078 - acc: 0.987 - ETA: 2s - loss: 0.6071 - acc: 0.987 - ETA: 2s - loss: 0.6066 - acc: 0.988 - ETA: 1s - loss: 0.6067 - acc: 0.988 - ETA: 1s - loss: 0.6063 - acc: 0.988 - ETA: 1s - loss: 0.6058 - acc: 0.988 - ETA: 1s - loss: 0.6055 - acc: 0.988 - ETA: 1s - loss: 0.6051 - acc: 0.988 - ETA: 1s - loss: 0.6058 - acc: 0.988 - ETA: 1s - loss: 0.6054 - acc: 0.988 - ETA: 1s - loss: 0.6064 - acc: 0.988 - ETA: 1s - loss: 0.6056 - acc: 0.988 - ETA: 1s - loss: 0.6070 - acc: 0.987 - ETA: 1s - loss: 0.6062 - acc: 0.987 - ETA: 1s - loss: 0.6068 - acc: 0.987 - ETA: 1s - loss: 0.6076 - acc: 0.986 - ETA: 1s - loss: 0.6071 - acc: 0.986 - ETA: 1s - loss: 0.6067 - acc: 0.986 - ETA: 1s - loss: 0.6069 - acc: 0.986 - ETA: 1s - loss: 0.6060 - acc: 0.986 - ETA: 1s - loss: 0.6070 - acc: 0.986 - ETA: 1s - loss: 0.6076 - acc: 0.985 - ETA: 0s - loss: 0.6071 - acc: 0.985 - ETA: 0s - loss: 0.6065 - acc: 0.986 - ETA: 0s - loss: 0.6072 - acc: 0.986 - ETA: 0s - loss: 0.6067 - acc: 0.986 - ETA: 0s - loss: 0.6065 - acc: 0.986 - ETA: 0s - loss: 0.6089 - acc: 0.986 - ETA: 0s - loss: 0.6085 - acc: 0.986 - ETA: 0s - loss: 0.6084 - acc: 0.986 - ETA: 0s - loss: 0.6084 - acc: 0.985 - ETA: 0s - loss: 0.6075 - acc: 0.986 - ETA: 0s - loss: 0.6069 - acc: 0.986 - ETA: 0s - loss: 0.6066 - acc: 0.985 - ETA: 0s - loss: 0.6059 - acc: 0.986 - ETA: 0s - loss: 0.6054 - acc: 0.986 - ETA: 0s - loss: 0.6051 - acc: 0.986 - ETA: 0s - loss: 0.6050 - acc: 0.986 - ETA: 0s - loss: 0.6051 - acc: 0.986 - ETA: 0s - loss: 0.6049 - acc: 0.986 - ETA: 0s - loss: 0.6046 - acc: 0.986 - ETA: 0s - loss: 0.6047 - acc: 0.9862Epoch 00006: val_loss improved from 1.52550 to 1.42743, saving model to saved_models/weights.best.VGG19.hdf5\n",
      "6680/6680 [==============================] - 4s - loss: 0.6040 - acc: 0.9864 - val_loss: 1.4274 - val_acc: 0.7437\n",
      "Epoch 8/30\n",
      "6608/6680 [============================>.] - ETA: 7s - loss: 0.5195 - acc: 1.000 - ETA: 5s - loss: 0.5415 - acc: 0.989 - ETA: 5s - loss: 0.5418 - acc: 0.993 - ETA: 5s - loss: 0.5445 - acc: 0.995 - ETA: 4s - loss: 0.5503 - acc: 0.990 - ETA: 4s - loss: 0.5497 - acc: 0.990 - ETA: 4s - loss: 0.5541 - acc: 0.987 - ETA: 4s - loss: 0.5557 - acc: 0.987 - ETA: 4s - loss: 0.5566 - acc: 0.987 - ETA: 4s - loss: 0.5522 - acc: 0.989 - ETA: 3s - loss: 0.5488 - acc: 0.990 - ETA: 3s - loss: 0.5497 - acc: 0.990 - ETA: 3s - loss: 0.5492 - acc: 0.990 - ETA: 3s - loss: 0.5516 - acc: 0.989 - ETA: 3s - loss: 0.5507 - acc: 0.989 - ETA: 3s - loss: 0.5523 - acc: 0.989 - ETA: 3s - loss: 0.5531 - acc: 0.988 - ETA: 3s - loss: 0.5516 - acc: 0.989 - ETA: 3s - loss: 0.5492 - acc: 0.989 - ETA: 3s - loss: 0.5495 - acc: 0.990 - ETA: 3s - loss: 0.5481 - acc: 0.990 - ETA: 3s - loss: 0.5469 - acc: 0.990 - ETA: 3s - loss: 0.5471 - acc: 0.990 - ETA: 3s - loss: 0.5463 - acc: 0.991 - ETA: 3s - loss: 0.5449 - acc: 0.991 - ETA: 3s - loss: 0.5443 - acc: 0.992 - ETA: 2s - loss: 0.5429 - acc: 0.992 - ETA: 2s - loss: 0.5422 - acc: 0.992 - ETA: 2s - loss: 0.5411 - acc: 0.992 - ETA: 2s - loss: 0.5411 - acc: 0.991 - ETA: 2s - loss: 0.5400 - acc: 0.992 - ETA: 2s - loss: 0.5440 - acc: 0.991 - ETA: 2s - loss: 0.5437 - acc: 0.991 - ETA: 2s - loss: 0.5435 - acc: 0.991 - ETA: 2s - loss: 0.5433 - acc: 0.991 - ETA: 2s - loss: 0.5426 - acc: 0.991 - ETA: 2s - loss: 0.5423 - acc: 0.991 - ETA: 2s - loss: 0.5419 - acc: 0.991 - ETA: 2s - loss: 0.5416 - acc: 0.991 - ETA: 2s - loss: 0.5406 - acc: 0.991 - ETA: 2s - loss: 0.5411 - acc: 0.991 - ETA: 2s - loss: 0.5411 - acc: 0.991 - ETA: 1s - loss: 0.5409 - acc: 0.991 - ETA: 1s - loss: 0.5406 - acc: 0.992 - ETA: 1s - loss: 0.5405 - acc: 0.991 - ETA: 1s - loss: 0.5403 - acc: 0.992 - ETA: 1s - loss: 0.5403 - acc: 0.992 - ETA: 1s - loss: 0.5398 - acc: 0.992 - ETA: 1s - loss: 0.5400 - acc: 0.992 - ETA: 1s - loss: 0.5397 - acc: 0.992 - ETA: 1s - loss: 0.5387 - acc: 0.992 - ETA: 1s - loss: 0.5387 - acc: 0.992 - ETA: 1s - loss: 0.5379 - acc: 0.992 - ETA: 1s - loss: 0.5385 - acc: 0.992 - ETA: 1s - loss: 0.5389 - acc: 0.992 - ETA: 1s - loss: 0.5383 - acc: 0.992 - ETA: 1s - loss: 0.5381 - acc: 0.992 - ETA: 1s - loss: 0.5378 - acc: 0.992 - ETA: 0s - loss: 0.5372 - acc: 0.992 - ETA: 0s - loss: 0.5371 - acc: 0.992 - ETA: 0s - loss: 0.5379 - acc: 0.992 - ETA: 0s - loss: 0.5380 - acc: 0.992 - ETA: 0s - loss: 0.5379 - acc: 0.992 - ETA: 0s - loss: 0.5377 - acc: 0.992 - ETA: 0s - loss: 0.5378 - acc: 0.992 - ETA: 0s - loss: 0.5378 - acc: 0.992 - ETA: 0s - loss: 0.5375 - acc: 0.992 - ETA: 0s - loss: 0.5376 - acc: 0.992 - ETA: 0s - loss: 0.5401 - acc: 0.992 - ETA: 0s - loss: 0.5398 - acc: 0.992 - ETA: 0s - loss: 0.5399 - acc: 0.992 - ETA: 0s - loss: 0.5398 - acc: 0.992 - ETA: 0s - loss: 0.5394 - acc: 0.992 - ETA: 0s - loss: 0.5395 - acc: 0.992 - ETA: 0s - loss: 0.5391 - acc: 0.992 - ETA: 0s - loss: 0.5390 - acc: 0.992 - ETA: 0s - loss: 0.5386 - acc: 0.992 - ETA: 0s - loss: 0.5387 - acc: 0.992 - ETA: 0s - loss: 0.5382 - acc: 0.992 - ETA: 0s - loss: 0.5380 - acc: 0.991 - ETA: 0s - loss: 0.5384 - acc: 0.9914Epoch 00007: val_loss improved from 1.42743 to 1.34536, saving model to saved_models/weights.best.VGG19.hdf5\n",
      "6680/6680 [==============================] - 4s - loss: 0.5383 - acc: 0.9915 - val_loss: 1.3454 - val_acc: 0.7569\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6656/6680 [============================>.] - ETA: 4s - loss: 0.5938 - acc: 0.937 - ETA: 4s - loss: 0.5083 - acc: 0.989 - ETA: 4s - loss: 0.5103 - acc: 0.988 - ETA: 4s - loss: 0.5020 - acc: 0.992 - ETA: 4s - loss: 0.5078 - acc: 0.991 - ETA: 3s - loss: 0.5073 - acc: 0.991 - ETA: 3s - loss: 0.5023 - acc: 0.992 - ETA: 3s - loss: 0.5014 - acc: 0.993 - ETA: 3s - loss: 0.5003 - acc: 0.994 - ETA: 3s - loss: 0.4977 - acc: 0.994 - ETA: 3s - loss: 0.4949 - acc: 0.995 - ETA: 3s - loss: 0.4949 - acc: 0.995 - ETA: 3s - loss: 0.4946 - acc: 0.996 - ETA: 3s - loss: 0.4932 - acc: 0.996 - ETA: 3s - loss: 0.4938 - acc: 0.996 - ETA: 3s - loss: 0.4930 - acc: 0.996 - ETA: 3s - loss: 0.4912 - acc: 0.996 - ETA: 3s - loss: 0.4910 - acc: 0.997 - ETA: 3s - loss: 0.4905 - acc: 0.997 - ETA: 3s - loss: 0.4900 - acc: 0.997 - ETA: 3s - loss: 0.4894 - acc: 0.997 - ETA: 3s - loss: 0.4894 - acc: 0.997 - ETA: 3s - loss: 0.4990 - acc: 0.996 - ETA: 3s - loss: 0.4982 - acc: 0.996 - ETA: 3s - loss: 0.4982 - acc: 0.995 - ETA: 3s - loss: 0.4967 - acc: 0.996 - ETA: 3s - loss: 0.4963 - acc: 0.995 - ETA: 2s - loss: 0.4974 - acc: 0.995 - ETA: 2s - loss: 0.4969 - acc: 0.995 - ETA: 2s - loss: 0.4964 - acc: 0.995 - ETA: 2s - loss: 0.4968 - acc: 0.995 - ETA: 2s - loss: 0.4962 - acc: 0.995 - ETA: 2s - loss: 0.4953 - acc: 0.995 - ETA: 2s - loss: 0.4951 - acc: 0.995 - ETA: 2s - loss: 0.4950 - acc: 0.995 - ETA: 2s - loss: 0.4949 - acc: 0.995 - ETA: 2s - loss: 0.4948 - acc: 0.995 - ETA: 2s - loss: 0.4948 - acc: 0.994 - ETA: 2s - loss: 0.4943 - acc: 0.994 - ETA: 2s - loss: 0.4935 - acc: 0.995 - ETA: 2s - loss: 0.4929 - acc: 0.995 - ETA: 2s - loss: 0.4930 - acc: 0.995 - ETA: 2s - loss: 0.4924 - acc: 0.995 - ETA: 2s - loss: 0.4930 - acc: 0.994 - ETA: 2s - loss: 0.4926 - acc: 0.994 - ETA: 2s - loss: 0.4917 - acc: 0.994 - ETA: 2s - loss: 0.4915 - acc: 0.994 - ETA: 1s - loss: 0.4915 - acc: 0.995 - ETA: 1s - loss: 0.4910 - acc: 0.995 - ETA: 1s - loss: 0.4909 - acc: 0.995 - ETA: 1s - loss: 0.4903 - acc: 0.995 - ETA: 1s - loss: 0.4899 - acc: 0.995 - ETA: 1s - loss: 0.4896 - acc: 0.995 - ETA: 1s - loss: 0.4893 - acc: 0.995 - ETA: 1s - loss: 0.4888 - acc: 0.995 - ETA: 1s - loss: 0.4890 - acc: 0.995 - ETA: 1s - loss: 0.4890 - acc: 0.995 - ETA: 1s - loss: 0.4894 - acc: 0.995 - ETA: 1s - loss: 0.4892 - acc: 0.995 - ETA: 1s - loss: 0.4891 - acc: 0.995 - ETA: 1s - loss: 0.4893 - acc: 0.995 - ETA: 1s - loss: 0.4891 - acc: 0.995 - ETA: 1s - loss: 0.4891 - acc: 0.995 - ETA: 1s - loss: 0.4893 - acc: 0.995 - ETA: 0s - loss: 0.4896 - acc: 0.995 - ETA: 0s - loss: 0.4893 - acc: 0.995 - ETA: 0s - loss: 0.4894 - acc: 0.995 - ETA: 0s - loss: 0.4888 - acc: 0.995 - ETA: 0s - loss: 0.4885 - acc: 0.995 - ETA: 0s - loss: 0.4881 - acc: 0.995 - ETA: 0s - loss: 0.4883 - acc: 0.995 - ETA: 0s - loss: 0.4878 - acc: 0.995 - ETA: 0s - loss: 0.4879 - acc: 0.995 - ETA: 0s - loss: 0.4879 - acc: 0.994 - ETA: 0s - loss: 0.4876 - acc: 0.994 - ETA: 0s - loss: 0.4871 - acc: 0.994 - ETA: 0s - loss: 0.4876 - acc: 0.994 - ETA: 0s - loss: 0.4875 - acc: 0.994 - ETA: 0s - loss: 0.4870 - acc: 0.994 - ETA: 0s - loss: 0.4868 - acc: 0.994 - ETA: 0s - loss: 0.4876 - acc: 0.9941Epoch 00008: val_loss improved from 1.34536 to 1.27269, saving model to saved_models/weights.best.VGG19.hdf5\n",
      "6680/6680 [==============================] - 4s - loss: 0.4875 - acc: 0.9942 - val_loss: 1.2727 - val_acc: 0.7569\n",
      "Epoch 10/30\n",
      "6672/6680 [============================>.] - ETA: 6s - loss: 0.4332 - acc: 1.000 - ETA: 6s - loss: 0.4755 - acc: 1.000 - ETA: 6s - loss: 0.4640 - acc: 1.000 - ETA: 5s - loss: 0.4547 - acc: 1.000 - ETA: 5s - loss: 0.4496 - acc: 1.000 - ETA: 5s - loss: 0.4522 - acc: 1.000 - ETA: 4s - loss: 0.4519 - acc: 0.997 - ETA: 4s - loss: 0.4516 - acc: 0.998 - ETA: 4s - loss: 0.4525 - acc: 0.998 - ETA: 4s - loss: 0.4514 - acc: 0.998 - ETA: 4s - loss: 0.4507 - acc: 0.998 - ETA: 4s - loss: 0.4503 - acc: 0.997 - ETA: 3s - loss: 0.4568 - acc: 0.996 - ETA: 3s - loss: 0.4567 - acc: 0.996 - ETA: 3s - loss: 0.4572 - acc: 0.996 - ETA: 3s - loss: 0.4548 - acc: 0.996 - ETA: 3s - loss: 0.4548 - acc: 0.996 - ETA: 3s - loss: 0.4542 - acc: 0.996 - ETA: 3s - loss: 0.4547 - acc: 0.996 - ETA: 3s - loss: 0.4546 - acc: 0.995 - ETA: 3s - loss: 0.4537 - acc: 0.995 - ETA: 3s - loss: 0.4533 - acc: 0.995 - ETA: 3s - loss: 0.4539 - acc: 0.995 - ETA: 3s - loss: 0.4531 - acc: 0.995 - ETA: 3s - loss: 0.4534 - acc: 0.994 - ETA: 3s - loss: 0.4528 - acc: 0.994 - ETA: 3s - loss: 0.4527 - acc: 0.994 - ETA: 3s - loss: 0.4520 - acc: 0.994 - ETA: 3s - loss: 0.4518 - acc: 0.994 - ETA: 3s - loss: 0.4515 - acc: 0.994 - ETA: 3s - loss: 0.4514 - acc: 0.994 - ETA: 2s - loss: 0.4520 - acc: 0.994 - ETA: 2s - loss: 0.4514 - acc: 0.994 - ETA: 2s - loss: 0.4512 - acc: 0.994 - ETA: 2s - loss: 0.4508 - acc: 0.994 - ETA: 2s - loss: 0.4499 - acc: 0.994 - ETA: 2s - loss: 0.4496 - acc: 0.994 - ETA: 2s - loss: 0.4492 - acc: 0.994 - ETA: 2s - loss: 0.4487 - acc: 0.994 - ETA: 2s - loss: 0.4487 - acc: 0.994 - ETA: 2s - loss: 0.4482 - acc: 0.994 - ETA: 2s - loss: 0.4474 - acc: 0.994 - ETA: 2s - loss: 0.4473 - acc: 0.994 - ETA: 2s - loss: 0.4472 - acc: 0.994 - ETA: 2s - loss: 0.4469 - acc: 0.995 - ETA: 2s - loss: 0.4470 - acc: 0.995 - ETA: 2s - loss: 0.4464 - acc: 0.995 - ETA: 1s - loss: 0.4459 - acc: 0.995 - ETA: 1s - loss: 0.4454 - acc: 0.995 - ETA: 1s - loss: 0.4456 - acc: 0.994 - ETA: 1s - loss: 0.4453 - acc: 0.995 - ETA: 1s - loss: 0.4452 - acc: 0.994 - ETA: 1s - loss: 0.4451 - acc: 0.994 - ETA: 1s - loss: 0.4454 - acc: 0.994 - ETA: 1s - loss: 0.4452 - acc: 0.994 - ETA: 1s - loss: 0.4449 - acc: 0.994 - ETA: 1s - loss: 0.4446 - acc: 0.994 - ETA: 1s - loss: 0.4443 - acc: 0.995 - ETA: 1s - loss: 0.4441 - acc: 0.995 - ETA: 1s - loss: 0.4441 - acc: 0.994 - ETA: 1s - loss: 0.4443 - acc: 0.994 - ETA: 1s - loss: 0.4441 - acc: 0.994 - ETA: 1s - loss: 0.4438 - acc: 0.994 - ETA: 1s - loss: 0.4442 - acc: 0.994 - ETA: 1s - loss: 0.4443 - acc: 0.994 - ETA: 0s - loss: 0.4443 - acc: 0.994 - ETA: 0s - loss: 0.4440 - acc: 0.994 - ETA: 0s - loss: 0.4440 - acc: 0.994 - ETA: 0s - loss: 0.4439 - acc: 0.994 - ETA: 0s - loss: 0.4439 - acc: 0.994 - ETA: 0s - loss: 0.4437 - acc: 0.994 - ETA: 0s - loss: 0.4438 - acc: 0.994 - ETA: 0s - loss: 0.4440 - acc: 0.994 - ETA: 0s - loss: 0.4437 - acc: 0.994 - ETA: 0s - loss: 0.4436 - acc: 0.994 - ETA: 0s - loss: 0.4435 - acc: 0.994 - ETA: 0s - loss: 0.4435 - acc: 0.994 - ETA: 0s - loss: 0.4434 - acc: 0.994 - ETA: 0s - loss: 0.4436 - acc: 0.994 - ETA: 0s - loss: 0.4432 - acc: 0.994 - ETA: 0s - loss: 0.4462 - acc: 0.994 - ETA: 0s - loss: 0.4466 - acc: 0.994 - ETA: 0s - loss: 0.4463 - acc: 0.994 - ETA: 0s - loss: 0.4463 - acc: 0.9945Epoch 00009: val_loss improved from 1.27269 to 1.21715, saving model to saved_models/weights.best.VGG19.hdf5\n",
      "6680/6680 [==============================] - 4s - loss: 0.4467 - acc: 0.9943 - val_loss: 1.2172 - val_acc: 0.7737\n",
      "Epoch 11/30\n",
      "6640/6680 [============================>.] - ETA: 3s - loss: 0.3823 - acc: 1.000 - ETA: 5s - loss: 0.4115 - acc: 1.000 - ETA: 5s - loss: 0.4288 - acc: 0.987 - ETA: 5s - loss: 0.4231 - acc: 0.991 - ETA: 4s - loss: 0.4289 - acc: 0.993 - ETA: 4s - loss: 0.4312 - acc: 0.994 - ETA: 4s - loss: 0.4253 - acc: 0.995 - ETA: 4s - loss: 0.4218 - acc: 0.996 - ETA: 4s - loss: 0.4216 - acc: 0.996 - ETA: 4s - loss: 0.4202 - acc: 0.997 - ETA: 4s - loss: 0.4187 - acc: 0.997 - ETA: 4s - loss: 0.4171 - acc: 0.997 - ETA: 4s - loss: 0.4154 - acc: 0.997 - ETA: 4s - loss: 0.4154 - acc: 0.998 - ETA: 3s - loss: 0.4147 - acc: 0.997 - ETA: 3s - loss: 0.4135 - acc: 0.997 - ETA: 3s - loss: 0.4127 - acc: 0.997 - ETA: 3s - loss: 0.4118 - acc: 0.997 - ETA: 3s - loss: 0.4123 - acc: 0.997 - ETA: 3s - loss: 0.4114 - acc: 0.997 - ETA: 3s - loss: 0.4114 - acc: 0.997 - ETA: 3s - loss: 0.4109 - acc: 0.997 - ETA: 3s - loss: 0.4101 - acc: 0.997 - ETA: 3s - loss: 0.4096 - acc: 0.996 - ETA: 3s - loss: 0.4098 - acc: 0.996 - ETA: 3s - loss: 0.4099 - acc: 0.997 - ETA: 3s - loss: 0.4098 - acc: 0.996 - ETA: 3s - loss: 0.4105 - acc: 0.996 - ETA: 3s - loss: 0.4101 - acc: 0.996 - ETA: 2s - loss: 0.4100 - acc: 0.997 - ETA: 2s - loss: 0.4100 - acc: 0.996 - ETA: 2s - loss: 0.4097 - acc: 0.996 - ETA: 2s - loss: 0.4092 - acc: 0.996 - ETA: 2s - loss: 0.4092 - acc: 0.996 - ETA: 2s - loss: 0.4092 - acc: 0.996 - ETA: 2s - loss: 0.4098 - acc: 0.995 - ETA: 2s - loss: 0.4107 - acc: 0.995 - ETA: 2s - loss: 0.4103 - acc: 0.995 - ETA: 2s - loss: 0.4101 - acc: 0.995 - ETA: 2s - loss: 0.4098 - acc: 0.995 - ETA: 2s - loss: 0.4096 - acc: 0.995 - ETA: 2s - loss: 0.4094 - acc: 0.995 - ETA: 2s - loss: 0.4096 - acc: 0.995 - ETA: 2s - loss: 0.4095 - acc: 0.995 - ETA: 2s - loss: 0.4092 - acc: 0.996 - ETA: 2s - loss: 0.4094 - acc: 0.995 - ETA: 2s - loss: 0.4088 - acc: 0.995 - ETA: 1s - loss: 0.4091 - acc: 0.995 - ETA: 1s - loss: 0.4088 - acc: 0.995 - ETA: 1s - loss: 0.4086 - acc: 0.995 - ETA: 1s - loss: 0.4083 - acc: 0.995 - ETA: 1s - loss: 0.4079 - acc: 0.995 - ETA: 1s - loss: 0.4086 - acc: 0.995 - ETA: 1s - loss: 0.4089 - acc: 0.995 - ETA: 1s - loss: 0.4085 - acc: 0.995 - ETA: 1s - loss: 0.4093 - acc: 0.995 - ETA: 1s - loss: 0.4094 - acc: 0.995 - ETA: 1s - loss: 0.4095 - acc: 0.995 - ETA: 1s - loss: 0.4093 - acc: 0.995 - ETA: 1s - loss: 0.4091 - acc: 0.995 - ETA: 1s - loss: 0.4092 - acc: 0.994 - ETA: 1s - loss: 0.4095 - acc: 0.994 - ETA: 1s - loss: 0.4099 - acc: 0.994 - ETA: 1s - loss: 0.4099 - acc: 0.994 - ETA: 1s - loss: 0.4098 - acc: 0.995 - ETA: 0s - loss: 0.4107 - acc: 0.994 - ETA: 0s - loss: 0.4109 - acc: 0.994 - ETA: 0s - loss: 0.4109 - acc: 0.994 - ETA: 0s - loss: 0.4114 - acc: 0.994 - ETA: 0s - loss: 0.4111 - acc: 0.995 - ETA: 0s - loss: 0.4123 - acc: 0.994 - ETA: 0s - loss: 0.4120 - acc: 0.994 - ETA: 0s - loss: 0.4117 - acc: 0.994 - ETA: 0s - loss: 0.4120 - acc: 0.994 - ETA: 0s - loss: 0.4117 - acc: 0.994 - ETA: 0s - loss: 0.4114 - acc: 0.994 - ETA: 0s - loss: 0.4110 - acc: 0.994 - ETA: 0s - loss: 0.4143 - acc: 0.994 - ETA: 0s - loss: 0.4140 - acc: 0.994 - ETA: 0s - loss: 0.4143 - acc: 0.993 - ETA: 0s - loss: 0.4145 - acc: 0.993 - ETA: 0s - loss: 0.4143 - acc: 0.993 - ETA: 0s - loss: 0.4144 - acc: 0.993 - ETA: 0s - loss: 0.4144 - acc: 0.9932Epoch 00010: val_loss improved from 1.21715 to 1.16309, saving model to saved_models/weights.best.VGG19.hdf5\n",
      "6680/6680 [==============================] - 4s - loss: 0.4145 - acc: 0.9933 - val_loss: 1.1631 - val_acc: 0.7569\n",
      "Epoch 12/30\n",
      "6672/6680 [============================>.] - ETA: 4s - loss: 0.3659 - acc: 1.000 - ETA: 4s - loss: 0.3830 - acc: 1.000 - ETA: 4s - loss: 0.3831 - acc: 1.000 - ETA: 4s - loss: 0.3872 - acc: 1.000 - ETA: 4s - loss: 0.3843 - acc: 1.000 - ETA: 4s - loss: 0.3810 - acc: 1.000 - ETA: 4s - loss: 0.3797 - acc: 0.998 - ETA: 4s - loss: 0.3788 - acc: 0.998 - ETA: 3s - loss: 0.3793 - acc: 0.998 - ETA: 3s - loss: 0.3774 - acc: 0.998 - ETA: 3s - loss: 0.3784 - acc: 0.998 - ETA: 3s - loss: 0.3788 - acc: 0.999 - ETA: 3s - loss: 0.3794 - acc: 0.999 - ETA: 3s - loss: 0.3787 - acc: 0.999 - ETA: 3s - loss: 0.3776 - acc: 0.999 - ETA: 3s - loss: 0.3780 - acc: 0.999 - ETA: 3s - loss: 0.3777 - acc: 0.999 - ETA: 3s - loss: 0.3779 - acc: 0.999 - ETA: 3s - loss: 0.3774 - acc: 0.999 - ETA: 3s - loss: 0.3766 - acc: 0.999 - ETA: 3s - loss: 0.3759 - acc: 0.999 - ETA: 3s - loss: 0.3757 - acc: 0.999 - ETA: 3s - loss: 0.3770 - acc: 0.998 - ETA: 3s - loss: 0.3768 - acc: 0.998 - ETA: 3s - loss: 0.3774 - acc: 0.998 - ETA: 3s - loss: 0.3777 - acc: 0.998 - ETA: 3s - loss: 0.3775 - acc: 0.998 - ETA: 3s - loss: 0.3782 - acc: 0.997 - ETA: 2s - loss: 0.3785 - acc: 0.997 - ETA: 2s - loss: 0.3783 - acc: 0.997 - ETA: 2s - loss: 0.3786 - acc: 0.997 - ETA: 2s - loss: 0.3797 - acc: 0.996 - ETA: 2s - loss: 0.3792 - acc: 0.997 - ETA: 2s - loss: 0.3792 - acc: 0.997 - ETA: 2s - loss: 0.3796 - acc: 0.997 - ETA: 2s - loss: 0.3789 - acc: 0.997 - ETA: 2s - loss: 0.3786 - acc: 0.997 - ETA: 2s - loss: 0.3783 - acc: 0.997 - ETA: 2s - loss: 0.3782 - acc: 0.997 - ETA: 2s - loss: 0.3780 - acc: 0.997 - ETA: 2s - loss: 0.3782 - acc: 0.997 - ETA: 2s - loss: 0.3779 - acc: 0.997 - ETA: 2s - loss: 0.3779 - acc: 0.997 - ETA: 2s - loss: 0.3824 - acc: 0.996 - ETA: 2s - loss: 0.3821 - acc: 0.996 - ETA: 2s - loss: 0.3819 - acc: 0.996 - ETA: 2s - loss: 0.3819 - acc: 0.996 - ETA: 1s - loss: 0.3817 - acc: 0.996 - ETA: 1s - loss: 0.3816 - acc: 0.996 - ETA: 1s - loss: 0.3814 - acc: 0.996 - ETA: 1s - loss: 0.3813 - acc: 0.996 - ETA: 1s - loss: 0.3817 - acc: 0.996 - ETA: 1s - loss: 0.3820 - acc: 0.996 - ETA: 1s - loss: 0.3819 - acc: 0.996 - ETA: 1s - loss: 0.3821 - acc: 0.996 - ETA: 1s - loss: 0.3819 - acc: 0.996 - ETA: 1s - loss: 0.3815 - acc: 0.996 - ETA: 1s - loss: 0.3811 - acc: 0.996 - ETA: 1s - loss: 0.3818 - acc: 0.996 - ETA: 1s - loss: 0.3819 - acc: 0.996 - ETA: 1s - loss: 0.3819 - acc: 0.996 - ETA: 1s - loss: 0.3821 - acc: 0.996 - ETA: 1s - loss: 0.3821 - acc: 0.996 - ETA: 1s - loss: 0.3826 - acc: 0.996 - ETA: 0s - loss: 0.3827 - acc: 0.996 - ETA: 0s - loss: 0.3824 - acc: 0.996 - ETA: 0s - loss: 0.3822 - acc: 0.996 - ETA: 0s - loss: 0.3819 - acc: 0.996 - ETA: 0s - loss: 0.3816 - acc: 0.996 - ETA: 0s - loss: 0.3817 - acc: 0.996 - ETA: 0s - loss: 0.3817 - acc: 0.996 - ETA: 0s - loss: 0.3813 - acc: 0.996 - ETA: 0s - loss: 0.3814 - acc: 0.996 - ETA: 0s - loss: 0.3815 - acc: 0.996 - ETA: 0s - loss: 0.3811 - acc: 0.996 - ETA: 0s - loss: 0.3809 - acc: 0.996 - ETA: 0s - loss: 0.3812 - acc: 0.996 - ETA: 0s - loss: 0.3813 - acc: 0.996 - ETA: 0s - loss: 0.3810 - acc: 0.996 - ETA: 0s - loss: 0.3815 - acc: 0.9961Epoch 00011: val_loss improved from 1.16309 to 1.13651, saving model to saved_models/weights.best.VGG19.hdf5\n",
      "6680/6680 [==============================] - 4s - loss: 0.3815 - acc: 0.9961 - val_loss: 1.1365 - val_acc: 0.7521\n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6656/6680 [============================>.] - ETA: 4s - loss: 0.3679 - acc: 1.000 - ETA: 4s - loss: 0.3604 - acc: 1.000 - ETA: 4s - loss: 0.3573 - acc: 1.000 - ETA: 4s - loss: 0.3517 - acc: 1.000 - ETA: 4s - loss: 0.3561 - acc: 1.000 - ETA: 4s - loss: 0.3579 - acc: 1.000 - ETA: 4s - loss: 0.3561 - acc: 1.000 - ETA: 3s - loss: 0.3534 - acc: 1.000 - ETA: 3s - loss: 0.3509 - acc: 1.000 - ETA: 3s - loss: 0.3488 - acc: 1.000 - ETA: 3s - loss: 0.3484 - acc: 1.000 - ETA: 3s - loss: 0.3479 - acc: 1.000 - ETA: 3s - loss: 0.3475 - acc: 1.000 - ETA: 3s - loss: 0.3470 - acc: 1.000 - ETA: 3s - loss: 0.3461 - acc: 1.000 - ETA: 3s - loss: 0.3459 - acc: 1.000 - ETA: 3s - loss: 0.3458 - acc: 1.000 - ETA: 3s - loss: 0.3445 - acc: 1.000 - ETA: 3s - loss: 0.3450 - acc: 1.000 - ETA: 3s - loss: 0.3448 - acc: 1.000 - ETA: 3s - loss: 0.3438 - acc: 1.000 - ETA: 2s - loss: 0.3438 - acc: 1.000 - ETA: 2s - loss: 0.3438 - acc: 1.000 - ETA: 2s - loss: 0.3441 - acc: 1.000 - ETA: 2s - loss: 0.3443 - acc: 1.000 - ETA: 2s - loss: 0.3443 - acc: 1.000 - ETA: 2s - loss: 0.3450 - acc: 1.000 - ETA: 2s - loss: 0.3447 - acc: 1.000 - ETA: 2s - loss: 0.3451 - acc: 1.000 - ETA: 2s - loss: 0.3457 - acc: 1.000 - ETA: 2s - loss: 0.3455 - acc: 1.000 - ETA: 2s - loss: 0.3458 - acc: 0.999 - ETA: 2s - loss: 0.3461 - acc: 0.999 - ETA: 2s - loss: 0.3459 - acc: 0.999 - ETA: 2s - loss: 0.3456 - acc: 0.999 - ETA: 2s - loss: 0.3455 - acc: 0.999 - ETA: 2s - loss: 0.3460 - acc: 0.999 - ETA: 2s - loss: 0.3463 - acc: 0.999 - ETA: 2s - loss: 0.3466 - acc: 0.999 - ETA: 2s - loss: 0.3465 - acc: 0.999 - ETA: 1s - loss: 0.3466 - acc: 0.999 - ETA: 1s - loss: 0.3475 - acc: 0.998 - ETA: 1s - loss: 0.3477 - acc: 0.998 - ETA: 1s - loss: 0.3478 - acc: 0.998 - ETA: 1s - loss: 0.3480 - acc: 0.998 - ETA: 1s - loss: 0.3479 - acc: 0.998 - ETA: 1s - loss: 0.3480 - acc: 0.998 - ETA: 1s - loss: 0.3478 - acc: 0.998 - ETA: 1s - loss: 0.3522 - acc: 0.998 - ETA: 1s - loss: 0.3520 - acc: 0.998 - ETA: 1s - loss: 0.3521 - acc: 0.998 - ETA: 1s - loss: 0.3526 - acc: 0.998 - ETA: 1s - loss: 0.3527 - acc: 0.998 - ETA: 1s - loss: 0.3528 - acc: 0.998 - ETA: 1s - loss: 0.3533 - acc: 0.997 - ETA: 1s - loss: 0.3535 - acc: 0.997 - ETA: 1s - loss: 0.3530 - acc: 0.997 - ETA: 0s - loss: 0.3533 - acc: 0.997 - ETA: 0s - loss: 0.3530 - acc: 0.997 - ETA: 0s - loss: 0.3529 - acc: 0.997 - ETA: 0s - loss: 0.3531 - acc: 0.997 - ETA: 0s - loss: 0.3536 - acc: 0.997 - ETA: 0s - loss: 0.3537 - acc: 0.997 - ETA: 0s - loss: 0.3539 - acc: 0.997 - ETA: 0s - loss: 0.3546 - acc: 0.997 - ETA: 0s - loss: 0.3547 - acc: 0.997 - ETA: 0s - loss: 0.3548 - acc: 0.997 - ETA: 0s - loss: 0.3547 - acc: 0.997 - ETA: 0s - loss: 0.3545 - acc: 0.997 - ETA: 0s - loss: 0.3545 - acc: 0.997 - ETA: 0s - loss: 0.3546 - acc: 0.997 - ETA: 0s - loss: 0.3546 - acc: 0.997 - ETA: 0s - loss: 0.3545 - acc: 0.997 - ETA: 0s - loss: 0.3553 - acc: 0.996 - ETA: 0s - loss: 0.3561 - acc: 0.996 - ETA: 0s - loss: 0.3560 - acc: 0.9964Epoch 00012: val_loss improved from 1.13651 to 1.09837, saving model to saved_models/weights.best.VGG19.hdf5\n",
      "6680/6680 [==============================] - 4s - loss: 0.3560 - acc: 0.9963 - val_loss: 1.0984 - val_acc: 0.7545\n",
      "Epoch 14/30\n",
      "6608/6680 [============================>.] - ETA: 5s - loss: 0.3376 - acc: 1.000 - ETA: 4s - loss: 0.3276 - acc: 1.000 - ETA: 4s - loss: 0.3332 - acc: 1.000 - ETA: 4s - loss: 0.3399 - acc: 0.996 - ETA: 3s - loss: 0.3391 - acc: 0.997 - ETA: 3s - loss: 0.3382 - acc: 0.995 - ETA: 3s - loss: 0.3368 - acc: 0.996 - ETA: 3s - loss: 0.3359 - acc: 0.996 - ETA: 4s - loss: 0.3349 - acc: 0.997 - ETA: 4s - loss: 0.3340 - acc: 0.997 - ETA: 4s - loss: 0.3332 - acc: 0.997 - ETA: 4s - loss: 0.3330 - acc: 0.997 - ETA: 4s - loss: 0.3324 - acc: 0.997 - ETA: 4s - loss: 0.3325 - acc: 0.998 - ETA: 4s - loss: 0.3342 - acc: 0.998 - ETA: 4s - loss: 0.3328 - acc: 0.998 - ETA: 4s - loss: 0.3325 - acc: 0.998 - ETA: 3s - loss: 0.3308 - acc: 0.998 - ETA: 3s - loss: 0.3300 - acc: 0.998 - ETA: 3s - loss: 0.3287 - acc: 0.998 - ETA: 3s - loss: 0.3282 - acc: 0.998 - ETA: 3s - loss: 0.3275 - acc: 0.998 - ETA: 3s - loss: 0.3271 - acc: 0.998 - ETA: 3s - loss: 0.3267 - acc: 0.998 - ETA: 3s - loss: 0.3269 - acc: 0.999 - ETA: 3s - loss: 0.3268 - acc: 0.999 - ETA: 3s - loss: 0.3274 - acc: 0.999 - ETA: 3s - loss: 0.3272 - acc: 0.999 - ETA: 3s - loss: 0.3273 - acc: 0.999 - ETA: 3s - loss: 0.3277 - acc: 0.998 - ETA: 3s - loss: 0.3278 - acc: 0.998 - ETA: 2s - loss: 0.3281 - acc: 0.998 - ETA: 2s - loss: 0.3288 - acc: 0.997 - ETA: 2s - loss: 0.3288 - acc: 0.997 - ETA: 2s - loss: 0.3291 - acc: 0.997 - ETA: 2s - loss: 0.3292 - acc: 0.997 - ETA: 2s - loss: 0.3288 - acc: 0.997 - ETA: 2s - loss: 0.3290 - acc: 0.997 - ETA: 2s - loss: 0.3286 - acc: 0.997 - ETA: 2s - loss: 0.3295 - acc: 0.997 - ETA: 2s - loss: 0.3347 - acc: 0.997 - ETA: 2s - loss: 0.3345 - acc: 0.997 - ETA: 2s - loss: 0.3342 - acc: 0.997 - ETA: 2s - loss: 0.3341 - acc: 0.997 - ETA: 2s - loss: 0.3338 - acc: 0.997 - ETA: 2s - loss: 0.3336 - acc: 0.997 - ETA: 2s - loss: 0.3333 - acc: 0.997 - ETA: 2s - loss: 0.3331 - acc: 0.997 - ETA: 2s - loss: 0.3331 - acc: 0.997 - ETA: 1s - loss: 0.3337 - acc: 0.997 - ETA: 1s - loss: 0.3333 - acc: 0.997 - ETA: 1s - loss: 0.3335 - acc: 0.997 - ETA: 1s - loss: 0.3334 - acc: 0.997 - ETA: 1s - loss: 0.3333 - acc: 0.997 - ETA: 1s - loss: 0.3331 - acc: 0.997 - ETA: 1s - loss: 0.3331 - acc: 0.997 - ETA: 1s - loss: 0.3332 - acc: 0.997 - ETA: 1s - loss: 0.3332 - acc: 0.997 - ETA: 1s - loss: 0.3327 - acc: 0.997 - ETA: 1s - loss: 0.3324 - acc: 0.997 - ETA: 1s - loss: 0.3323 - acc: 0.997 - ETA: 1s - loss: 0.3325 - acc: 0.997 - ETA: 1s - loss: 0.3322 - acc: 0.997 - ETA: 1s - loss: 0.3324 - acc: 0.997 - ETA: 1s - loss: 0.3323 - acc: 0.997 - ETA: 1s - loss: 0.3319 - acc: 0.997 - ETA: 1s - loss: 0.3319 - acc: 0.997 - ETA: 1s - loss: 0.3322 - acc: 0.997 - ETA: 0s - loss: 0.3331 - acc: 0.997 - ETA: 0s - loss: 0.3342 - acc: 0.996 - ETA: 0s - loss: 0.3341 - acc: 0.996 - ETA: 0s - loss: 0.3340 - acc: 0.996 - ETA: 0s - loss: 0.3336 - acc: 0.996 - ETA: 0s - loss: 0.3335 - acc: 0.996 - ETA: 0s - loss: 0.3334 - acc: 0.996 - ETA: 0s - loss: 0.3337 - acc: 0.996 - ETA: 0s - loss: 0.3340 - acc: 0.996 - ETA: 0s - loss: 0.3340 - acc: 0.996 - ETA: 0s - loss: 0.3348 - acc: 0.996 - ETA: 0s - loss: 0.3346 - acc: 0.996 - ETA: 0s - loss: 0.3345 - acc: 0.996 - ETA: 0s - loss: 0.3350 - acc: 0.996 - ETA: 0s - loss: 0.3350 - acc: 0.996 - ETA: 0s - loss: 0.3350 - acc: 0.996 - ETA: 0s - loss: 0.3353 - acc: 0.9968Epoch 00013: val_loss improved from 1.09837 to 1.04480, saving model to saved_models/weights.best.VGG19.hdf5\n",
      "6680/6680 [==============================] - 4s - loss: 0.3352 - acc: 0.9969 - val_loss: 1.0448 - val_acc: 0.7581\n",
      "Epoch 15/30\n",
      "6608/6680 [============================>.] - ETA: 4s - loss: 0.2764 - acc: 1.000 - ETA: 5s - loss: 0.2910 - acc: 1.000 - ETA: 5s - loss: 0.3011 - acc: 1.000 - ETA: 5s - loss: 0.3083 - acc: 1.000 - ETA: 4s - loss: 0.3116 - acc: 1.000 - ETA: 4s - loss: 0.3120 - acc: 1.000 - ETA: 4s - loss: 0.3132 - acc: 1.000 - ETA: 4s - loss: 0.3148 - acc: 1.000 - ETA: 4s - loss: 0.3159 - acc: 1.000 - ETA: 4s - loss: 0.3141 - acc: 1.000 - ETA: 4s - loss: 0.3128 - acc: 1.000 - ETA: 4s - loss: 0.3125 - acc: 1.000 - ETA: 4s - loss: 0.3130 - acc: 1.000 - ETA: 4s - loss: 0.3125 - acc: 0.998 - ETA: 4s - loss: 0.3150 - acc: 0.998 - ETA: 4s - loss: 0.3146 - acc: 0.998 - ETA: 4s - loss: 0.3145 - acc: 0.998 - ETA: 4s - loss: 0.3126 - acc: 0.998 - ETA: 4s - loss: 0.3133 - acc: 0.998 - ETA: 3s - loss: 0.3121 - acc: 0.998 - ETA: 3s - loss: 0.3114 - acc: 0.998 - ETA: 3s - loss: 0.3132 - acc: 0.998 - ETA: 3s - loss: 0.3132 - acc: 0.997 - ETA: 3s - loss: 0.3127 - acc: 0.997 - ETA: 3s - loss: 0.3118 - acc: 0.997 - ETA: 3s - loss: 0.3115 - acc: 0.998 - ETA: 3s - loss: 0.3115 - acc: 0.998 - ETA: 3s - loss: 0.3133 - acc: 0.997 - ETA: 3s - loss: 0.3137 - acc: 0.996 - ETA: 3s - loss: 0.3133 - acc: 0.996 - ETA: 3s - loss: 0.3128 - acc: 0.997 - ETA: 3s - loss: 0.3128 - acc: 0.997 - ETA: 2s - loss: 0.3124 - acc: 0.997 - ETA: 2s - loss: 0.3118 - acc: 0.997 - ETA: 2s - loss: 0.3115 - acc: 0.997 - ETA: 2s - loss: 0.3117 - acc: 0.997 - ETA: 2s - loss: 0.3115 - acc: 0.997 - ETA: 2s - loss: 0.3122 - acc: 0.997 - ETA: 2s - loss: 0.3126 - acc: 0.997 - ETA: 2s - loss: 0.3133 - acc: 0.996 - ETA: 2s - loss: 0.3131 - acc: 0.996 - ETA: 2s - loss: 0.3131 - acc: 0.996 - ETA: 2s - loss: 0.3132 - acc: 0.997 - ETA: 2s - loss: 0.3135 - acc: 0.997 - ETA: 2s - loss: 0.3132 - acc: 0.997 - ETA: 2s - loss: 0.3131 - acc: 0.997 - ETA: 2s - loss: 0.3125 - acc: 0.997 - ETA: 2s - loss: 0.3124 - acc: 0.997 - ETA: 2s - loss: 0.3122 - acc: 0.997 - ETA: 1s - loss: 0.3129 - acc: 0.997 - ETA: 1s - loss: 0.3127 - acc: 0.997 - ETA: 1s - loss: 0.3125 - acc: 0.997 - ETA: 1s - loss: 0.3129 - acc: 0.997 - ETA: 1s - loss: 0.3131 - acc: 0.997 - ETA: 1s - loss: 0.3134 - acc: 0.997 - ETA: 1s - loss: 0.3133 - acc: 0.997 - ETA: 1s - loss: 0.3138 - acc: 0.997 - ETA: 1s - loss: 0.3138 - acc: 0.997 - ETA: 1s - loss: 0.3135 - acc: 0.997 - ETA: 1s - loss: 0.3135 - acc: 0.997 - ETA: 1s - loss: 0.3134 - acc: 0.997 - ETA: 1s - loss: 0.3134 - acc: 0.997 - ETA: 1s - loss: 0.3138 - acc: 0.997 - ETA: 1s - loss: 0.3137 - acc: 0.997 - ETA: 1s - loss: 0.3141 - acc: 0.997 - ETA: 0s - loss: 0.3142 - acc: 0.997 - ETA: 0s - loss: 0.3142 - acc: 0.997 - ETA: 0s - loss: 0.3142 - acc: 0.996 - ETA: 0s - loss: 0.3142 - acc: 0.996 - ETA: 0s - loss: 0.3141 - acc: 0.997 - ETA: 0s - loss: 0.3142 - acc: 0.997 - ETA: 0s - loss: 0.3142 - acc: 0.996 - ETA: 0s - loss: 0.3140 - acc: 0.996 - ETA: 0s - loss: 0.3138 - acc: 0.997 - ETA: 0s - loss: 0.3142 - acc: 0.997 - ETA: 0s - loss: 0.3142 - acc: 0.997 - ETA: 0s - loss: 0.3139 - acc: 0.997 - ETA: 0s - loss: 0.3140 - acc: 0.997 - ETA: 0s - loss: 0.3140 - acc: 0.997 - ETA: 0s - loss: 0.3137 - acc: 0.997 - ETA: 0s - loss: 0.3159 - acc: 0.997 - ETA: 0s - loss: 0.3160 - acc: 0.997 - ETA: 0s - loss: 0.3161 - acc: 0.9971Epoch 00014: val_loss improved from 1.04480 to 1.03121, saving model to saved_models/weights.best.VGG19.hdf5\n",
      "6680/6680 [==============================] - 4s - loss: 0.3161 - acc: 0.9972 - val_loss: 1.0312 - val_acc: 0.7641\n",
      "Epoch 16/30\n",
      "6640/6680 [============================>.] - ETA: 5s - loss: 0.2809 - acc: 1.000 - ETA: 4s - loss: 0.2797 - acc: 1.000 - ETA: 5s - loss: 0.2860 - acc: 1.000 - ETA: 4s - loss: 0.2860 - acc: 1.000 - ETA: 4s - loss: 0.2893 - acc: 0.997 - ETA: 4s - loss: 0.2923 - acc: 0.997 - ETA: 4s - loss: 0.2907 - acc: 0.998 - ETA: 4s - loss: 0.2899 - acc: 0.998 - ETA: 4s - loss: 0.2886 - acc: 0.998 - ETA: 4s - loss: 0.2864 - acc: 0.998 - ETA: 4s - loss: 0.2867 - acc: 0.998 - ETA: 4s - loss: 0.2870 - acc: 0.998 - ETA: 4s - loss: 0.2869 - acc: 0.998 - ETA: 4s - loss: 0.2884 - acc: 0.999 - ETA: 4s - loss: 0.2882 - acc: 0.999 - ETA: 3s - loss: 0.2898 - acc: 0.998 - ETA: 3s - loss: 0.2886 - acc: 0.998 - ETA: 3s - loss: 0.2886 - acc: 0.998 - ETA: 3s - loss: 0.2896 - acc: 0.997 - ETA: 3s - loss: 0.2888 - acc: 0.998 - ETA: 3s - loss: 0.2886 - acc: 0.998 - ETA: 3s - loss: 0.2888 - acc: 0.998 - ETA: 3s - loss: 0.2885 - acc: 0.998 - ETA: 3s - loss: 0.2888 - acc: 0.998 - ETA: 3s - loss: 0.2887 - acc: 0.998 - ETA: 3s - loss: 0.2886 - acc: 0.998 - ETA: 3s - loss: 0.2888 - acc: 0.998 - ETA: 3s - loss: 0.2883 - acc: 0.998 - ETA: 3s - loss: 0.2887 - acc: 0.998 - ETA: 2s - loss: 0.2888 - acc: 0.998 - ETA: 2s - loss: 0.2887 - acc: 0.998 - ETA: 2s - loss: 0.2891 - acc: 0.998 - ETA: 2s - loss: 0.2893 - acc: 0.998 - ETA: 2s - loss: 0.2891 - acc: 0.998 - ETA: 2s - loss: 0.2895 - acc: 0.998 - ETA: 2s - loss: 0.2893 - acc: 0.998 - ETA: 2s - loss: 0.2903 - acc: 0.999 - ETA: 2s - loss: 0.2917 - acc: 0.998 - ETA: 2s - loss: 0.2929 - acc: 0.998 - ETA: 2s - loss: 0.2932 - acc: 0.998 - ETA: 2s - loss: 0.2989 - acc: 0.997 - ETA: 2s - loss: 0.2986 - acc: 0.997 - ETA: 2s - loss: 0.2987 - acc: 0.997 - ETA: 2s - loss: 0.2986 - acc: 0.997 - ETA: 2s - loss: 0.2982 - acc: 0.997 - ETA: 2s - loss: 0.2983 - acc: 0.997 - ETA: 2s - loss: 0.2980 - acc: 0.997 - ETA: 1s - loss: 0.2981 - acc: 0.997 - ETA: 1s - loss: 0.2979 - acc: 0.997 - ETA: 1s - loss: 0.2982 - acc: 0.997 - ETA: 1s - loss: 0.2982 - acc: 0.997 - ETA: 1s - loss: 0.2982 - acc: 0.997 - ETA: 1s - loss: 0.2981 - acc: 0.997 - ETA: 1s - loss: 0.2983 - acc: 0.997 - ETA: 1s - loss: 0.2980 - acc: 0.998 - ETA: 1s - loss: 0.2981 - acc: 0.998 - ETA: 1s - loss: 0.2981 - acc: 0.998 - ETA: 1s - loss: 0.2980 - acc: 0.998 - ETA: 1s - loss: 0.2983 - acc: 0.998 - ETA: 1s - loss: 0.2980 - acc: 0.998 - ETA: 1s - loss: 0.2978 - acc: 0.998 - ETA: 1s - loss: 0.2978 - acc: 0.998 - ETA: 1s - loss: 0.2975 - acc: 0.998 - ETA: 1s - loss: 0.2975 - acc: 0.998 - ETA: 1s - loss: 0.2974 - acc: 0.998 - ETA: 0s - loss: 0.2984 - acc: 0.997 - ETA: 0s - loss: 0.2987 - acc: 0.997 - ETA: 0s - loss: 0.2986 - acc: 0.998 - ETA: 0s - loss: 0.2987 - acc: 0.998 - ETA: 0s - loss: 0.2985 - acc: 0.998 - ETA: 0s - loss: 0.2984 - acc: 0.998 - ETA: 0s - loss: 0.2984 - acc: 0.998 - ETA: 0s - loss: 0.2988 - acc: 0.997 - ETA: 0s - loss: 0.2986 - acc: 0.998 - ETA: 0s - loss: 0.2984 - acc: 0.998 - ETA: 0s - loss: 0.2986 - acc: 0.997 - ETA: 0s - loss: 0.2988 - acc: 0.997 - ETA: 0s - loss: 0.2989 - acc: 0.997 - ETA: 0s - loss: 0.2992 - acc: 0.997 - ETA: 0s - loss: 0.2995 - acc: 0.997 - ETA: 0s - loss: 0.2996 - acc: 0.996 - ETA: 0s - loss: 0.2995 - acc: 0.996 - ETA: 0s - loss: 0.2995 - acc: 0.9968Epoch 00015: val_loss improved from 1.03121 to 1.02127, saving model to saved_models/weights.best.VGG19.hdf5\n",
      "6680/6680 [==============================] - 4s - loss: 0.2999 - acc: 0.9967 - val_loss: 1.0213 - val_acc: 0.7629\n",
      "Epoch 17/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6624/6680 [============================>.] - ETA: 4s - loss: 0.2480 - acc: 1.000 - ETA: 4s - loss: 0.2848 - acc: 1.000 - ETA: 4s - loss: 0.2890 - acc: 0.994 - ETA: 4s - loss: 0.2894 - acc: 0.995 - ETA: 4s - loss: 0.2832 - acc: 0.996 - ETA: 4s - loss: 0.2822 - acc: 0.997 - ETA: 4s - loss: 0.2803 - acc: 0.997 - ETA: 4s - loss: 0.2807 - acc: 0.998 - ETA: 4s - loss: 0.2819 - acc: 0.996 - ETA: 4s - loss: 0.2820 - acc: 0.997 - ETA: 4s - loss: 0.2818 - acc: 0.997 - ETA: 4s - loss: 0.2814 - acc: 0.997 - ETA: 4s - loss: 0.2802 - acc: 0.997 - ETA: 4s - loss: 0.2800 - acc: 0.997 - ETA: 4s - loss: 0.2791 - acc: 0.998 - ETA: 4s - loss: 0.2780 - acc: 0.998 - ETA: 4s - loss: 0.2774 - acc: 0.998 - ETA: 4s - loss: 0.2778 - acc: 0.998 - ETA: 4s - loss: 0.2778 - acc: 0.998 - ETA: 4s - loss: 0.2785 - acc: 0.998 - ETA: 4s - loss: 0.2793 - acc: 0.997 - ETA: 3s - loss: 0.2795 - acc: 0.998 - ETA: 3s - loss: 0.2797 - acc: 0.998 - ETA: 3s - loss: 0.2791 - acc: 0.998 - ETA: 3s - loss: 0.2802 - acc: 0.997 - ETA: 3s - loss: 0.2805 - acc: 0.997 - ETA: 3s - loss: 0.2804 - acc: 0.997 - ETA: 3s - loss: 0.2804 - acc: 0.998 - ETA: 3s - loss: 0.2796 - acc: 0.998 - ETA: 3s - loss: 0.2792 - acc: 0.998 - ETA: 3s - loss: 0.2789 - acc: 0.998 - ETA: 3s - loss: 0.2786 - acc: 0.998 - ETA: 3s - loss: 0.2789 - acc: 0.997 - ETA: 3s - loss: 0.2789 - acc: 0.998 - ETA: 3s - loss: 0.2790 - acc: 0.998 - ETA: 2s - loss: 0.2792 - acc: 0.998 - ETA: 2s - loss: 0.2790 - acc: 0.998 - ETA: 2s - loss: 0.2791 - acc: 0.998 - ETA: 2s - loss: 0.2794 - acc: 0.998 - ETA: 2s - loss: 0.2792 - acc: 0.998 - ETA: 2s - loss: 0.2793 - acc: 0.998 - ETA: 2s - loss: 0.2790 - acc: 0.998 - ETA: 2s - loss: 0.2791 - acc: 0.998 - ETA: 2s - loss: 0.2789 - acc: 0.998 - ETA: 2s - loss: 0.2790 - acc: 0.997 - ETA: 2s - loss: 0.2793 - acc: 0.997 - ETA: 2s - loss: 0.2797 - acc: 0.997 - ETA: 2s - loss: 0.2799 - acc: 0.997 - ETA: 2s - loss: 0.2797 - acc: 0.997 - ETA: 1s - loss: 0.2796 - acc: 0.997 - ETA: 1s - loss: 0.2795 - acc: 0.997 - ETA: 1s - loss: 0.2796 - acc: 0.997 - ETA: 1s - loss: 0.2799 - acc: 0.997 - ETA: 1s - loss: 0.2797 - acc: 0.997 - ETA: 1s - loss: 0.2796 - acc: 0.997 - ETA: 1s - loss: 0.2794 - acc: 0.997 - ETA: 1s - loss: 0.2793 - acc: 0.997 - ETA: 1s - loss: 0.2793 - acc: 0.998 - ETA: 1s - loss: 0.2791 - acc: 0.998 - ETA: 1s - loss: 0.2795 - acc: 0.998 - ETA: 1s - loss: 0.2796 - acc: 0.998 - ETA: 1s - loss: 0.2795 - acc: 0.998 - ETA: 1s - loss: 0.2798 - acc: 0.998 - ETA: 1s - loss: 0.2803 - acc: 0.997 - ETA: 1s - loss: 0.2806 - acc: 0.997 - ETA: 1s - loss: 0.2805 - acc: 0.997 - ETA: 0s - loss: 0.2809 - acc: 0.997 - ETA: 0s - loss: 0.2812 - acc: 0.997 - ETA: 0s - loss: 0.2816 - acc: 0.997 - ETA: 0s - loss: 0.2816 - acc: 0.997 - ETA: 0s - loss: 0.2820 - acc: 0.997 - ETA: 0s - loss: 0.2820 - acc: 0.997 - ETA: 0s - loss: 0.2819 - acc: 0.997 - ETA: 0s - loss: 0.2821 - acc: 0.997 - ETA: 0s - loss: 0.2845 - acc: 0.997 - ETA: 0s - loss: 0.2843 - acc: 0.997 - ETA: 0s - loss: 0.2841 - acc: 0.997 - ETA: 0s - loss: 0.2848 - acc: 0.997 - ETA: 0s - loss: 0.2848 - acc: 0.997 - ETA: 0s - loss: 0.2850 - acc: 0.997 - ETA: 0s - loss: 0.2854 - acc: 0.997 - ETA: 0s - loss: 0.2854 - acc: 0.9971Epoch 00016: val_loss improved from 1.02127 to 0.97935, saving model to saved_models/weights.best.VGG19.hdf5\n",
      "6680/6680 [==============================] - 4s - loss: 0.2856 - acc: 0.9970 - val_loss: 0.9793 - val_acc: 0.7749\n",
      "Epoch 18/30\n",
      "6624/6680 [============================>.] - ETA: 5s - loss: 0.2581 - acc: 1.000 - ETA: 5s - loss: 0.2620 - acc: 1.000 - ETA: 4s - loss: 0.2684 - acc: 1.000 - ETA: 4s - loss: 0.2649 - acc: 1.000 - ETA: 4s - loss: 0.2660 - acc: 0.996 - ETA: 4s - loss: 0.2662 - acc: 0.997 - ETA: 4s - loss: 0.2631 - acc: 0.998 - ETA: 4s - loss: 0.2646 - acc: 0.998 - ETA: 4s - loss: 0.2630 - acc: 0.998 - ETA: 3s - loss: 0.2629 - acc: 0.998 - ETA: 3s - loss: 0.2614 - acc: 0.998 - ETA: 3s - loss: 0.2621 - acc: 0.998 - ETA: 3s - loss: 0.2634 - acc: 0.999 - ETA: 3s - loss: 0.2618 - acc: 0.999 - ETA: 3s - loss: 0.2625 - acc: 0.999 - ETA: 3s - loss: 0.2619 - acc: 0.999 - ETA: 3s - loss: 0.2622 - acc: 0.999 - ETA: 3s - loss: 0.2620 - acc: 0.999 - ETA: 3s - loss: 0.2624 - acc: 0.999 - ETA: 3s - loss: 0.2627 - acc: 0.999 - ETA: 3s - loss: 0.2643 - acc: 0.998 - ETA: 3s - loss: 0.2643 - acc: 0.998 - ETA: 3s - loss: 0.2659 - acc: 0.998 - ETA: 2s - loss: 0.2663 - acc: 0.998 - ETA: 2s - loss: 0.2659 - acc: 0.998 - ETA: 2s - loss: 0.2662 - acc: 0.998 - ETA: 2s - loss: 0.2663 - acc: 0.998 - ETA: 2s - loss: 0.2734 - acc: 0.998 - ETA: 2s - loss: 0.2733 - acc: 0.998 - ETA: 2s - loss: 0.2733 - acc: 0.998 - ETA: 2s - loss: 0.2735 - acc: 0.998 - ETA: 2s - loss: 0.2729 - acc: 0.998 - ETA: 2s - loss: 0.2722 - acc: 0.998 - ETA: 2s - loss: 0.2719 - acc: 0.998 - ETA: 2s - loss: 0.2719 - acc: 0.998 - ETA: 2s - loss: 0.2717 - acc: 0.998 - ETA: 2s - loss: 0.2712 - acc: 0.998 - ETA: 2s - loss: 0.2707 - acc: 0.998 - ETA: 2s - loss: 0.2705 - acc: 0.998 - ETA: 2s - loss: 0.2702 - acc: 0.998 - ETA: 2s - loss: 0.2702 - acc: 0.998 - ETA: 2s - loss: 0.2712 - acc: 0.997 - ETA: 2s - loss: 0.2714 - acc: 0.997 - ETA: 2s - loss: 0.2720 - acc: 0.996 - ETA: 2s - loss: 0.2721 - acc: 0.996 - ETA: 1s - loss: 0.2717 - acc: 0.996 - ETA: 1s - loss: 0.2723 - acc: 0.996 - ETA: 1s - loss: 0.2725 - acc: 0.996 - ETA: 1s - loss: 0.2725 - acc: 0.996 - ETA: 1s - loss: 0.2726 - acc: 0.996 - ETA: 1s - loss: 0.2724 - acc: 0.996 - ETA: 1s - loss: 0.2725 - acc: 0.996 - ETA: 1s - loss: 0.2728 - acc: 0.996 - ETA: 1s - loss: 0.2729 - acc: 0.996 - ETA: 1s - loss: 0.2728 - acc: 0.996 - ETA: 1s - loss: 0.2729 - acc: 0.996 - ETA: 1s - loss: 0.2729 - acc: 0.996 - ETA: 1s - loss: 0.2732 - acc: 0.996 - ETA: 1s - loss: 0.2731 - acc: 0.996 - ETA: 1s - loss: 0.2730 - acc: 0.996 - ETA: 1s - loss: 0.2726 - acc: 0.996 - ETA: 1s - loss: 0.2728 - acc: 0.996 - ETA: 1s - loss: 0.2730 - acc: 0.996 - ETA: 1s - loss: 0.2729 - acc: 0.996 - ETA: 1s - loss: 0.2730 - acc: 0.996 - ETA: 1s - loss: 0.2731 - acc: 0.996 - ETA: 0s - loss: 0.2728 - acc: 0.997 - ETA: 0s - loss: 0.2732 - acc: 0.997 - ETA: 0s - loss: 0.2735 - acc: 0.996 - ETA: 0s - loss: 0.2738 - acc: 0.996 - ETA: 0s - loss: 0.2738 - acc: 0.997 - ETA: 0s - loss: 0.2737 - acc: 0.997 - ETA: 0s - loss: 0.2741 - acc: 0.996 - ETA: 0s - loss: 0.2742 - acc: 0.996 - ETA: 0s - loss: 0.2742 - acc: 0.997 - ETA: 0s - loss: 0.2745 - acc: 0.997 - ETA: 0s - loss: 0.2746 - acc: 0.997 - ETA: 0s - loss: 0.2745 - acc: 0.997 - ETA: 0s - loss: 0.2747 - acc: 0.997 - ETA: 0s - loss: 0.2745 - acc: 0.997 - ETA: 0s - loss: 0.2744 - acc: 0.997 - ETA: 0s - loss: 0.2743 - acc: 0.997 - ETA: 0s - loss: 0.2743 - acc: 0.9971Epoch 00017: val_loss improved from 0.97935 to 0.95612, saving model to saved_models/weights.best.VGG19.hdf5\n",
      "6680/6680 [==============================] - 4s - loss: 0.2743 - acc: 0.9972 - val_loss: 0.9561 - val_acc: 0.7701\n",
      "Epoch 19/30\n",
      "6656/6680 [============================>.] - ETA: 4s - loss: 0.2360 - acc: 1.000 - ETA: 3s - loss: 0.2653 - acc: 0.991 - ETA: 3s - loss: 0.2597 - acc: 0.995 - ETA: 3s - loss: 0.2543 - acc: 0.996 - ETA: 3s - loss: 0.2602 - acc: 0.994 - ETA: 3s - loss: 0.2576 - acc: 0.995 - ETA: 3s - loss: 0.2554 - acc: 0.996 - ETA: 3s - loss: 0.2564 - acc: 0.995 - ETA: 3s - loss: 0.2575 - acc: 0.994 - ETA: 3s - loss: 0.2557 - acc: 0.995 - ETA: 3s - loss: 0.2562 - acc: 0.995 - ETA: 3s - loss: 0.2577 - acc: 0.995 - ETA: 3s - loss: 0.2586 - acc: 0.995 - ETA: 3s - loss: 0.2579 - acc: 0.995 - ETA: 3s - loss: 0.2587 - acc: 0.995 - ETA: 3s - loss: 0.2573 - acc: 0.996 - ETA: 3s - loss: 0.2571 - acc: 0.996 - ETA: 3s - loss: 0.2574 - acc: 0.996 - ETA: 3s - loss: 0.2573 - acc: 0.996 - ETA: 3s - loss: 0.2572 - acc: 0.997 - ETA: 3s - loss: 0.2571 - acc: 0.997 - ETA: 3s - loss: 0.2574 - acc: 0.997 - ETA: 3s - loss: 0.2569 - acc: 0.997 - ETA: 2s - loss: 0.2567 - acc: 0.997 - ETA: 2s - loss: 0.2570 - acc: 0.997 - ETA: 2s - loss: 0.2566 - acc: 0.997 - ETA: 2s - loss: 0.2563 - acc: 0.997 - ETA: 2s - loss: 0.2563 - acc: 0.997 - ETA: 2s - loss: 0.2563 - acc: 0.998 - ETA: 2s - loss: 0.2564 - acc: 0.998 - ETA: 2s - loss: 0.2575 - acc: 0.997 - ETA: 2s - loss: 0.2576 - acc: 0.997 - ETA: 2s - loss: 0.2580 - acc: 0.997 - ETA: 2s - loss: 0.2583 - acc: 0.997 - ETA: 2s - loss: 0.2589 - acc: 0.996 - ETA: 2s - loss: 0.2587 - acc: 0.997 - ETA: 2s - loss: 0.2588 - acc: 0.997 - ETA: 2s - loss: 0.2588 - acc: 0.997 - ETA: 2s - loss: 0.2587 - acc: 0.997 - ETA: 2s - loss: 0.2586 - acc: 0.997 - ETA: 2s - loss: 0.2586 - acc: 0.997 - ETA: 2s - loss: 0.2591 - acc: 0.996 - ETA: 2s - loss: 0.2590 - acc: 0.996 - ETA: 1s - loss: 0.2588 - acc: 0.996 - ETA: 1s - loss: 0.2587 - acc: 0.996 - ETA: 1s - loss: 0.2586 - acc: 0.996 - ETA: 1s - loss: 0.2586 - acc: 0.996 - ETA: 1s - loss: 0.2587 - acc: 0.997 - ETA: 1s - loss: 0.2587 - acc: 0.997 - ETA: 1s - loss: 0.2588 - acc: 0.997 - ETA: 1s - loss: 0.2591 - acc: 0.997 - ETA: 1s - loss: 0.2590 - acc: 0.997 - ETA: 1s - loss: 0.2589 - acc: 0.997 - ETA: 1s - loss: 0.2588 - acc: 0.997 - ETA: 1s - loss: 0.2591 - acc: 0.997 - ETA: 1s - loss: 0.2592 - acc: 0.997 - ETA: 1s - loss: 0.2594 - acc: 0.997 - ETA: 1s - loss: 0.2593 - acc: 0.997 - ETA: 1s - loss: 0.2591 - acc: 0.997 - ETA: 1s - loss: 0.2592 - acc: 0.997 - ETA: 1s - loss: 0.2623 - acc: 0.997 - ETA: 1s - loss: 0.2624 - acc: 0.997 - ETA: 1s - loss: 0.2622 - acc: 0.997 - ETA: 1s - loss: 0.2628 - acc: 0.997 - ETA: 0s - loss: 0.2627 - acc: 0.997 - ETA: 0s - loss: 0.2628 - acc: 0.997 - ETA: 0s - loss: 0.2628 - acc: 0.997 - ETA: 0s - loss: 0.2629 - acc: 0.997 - ETA: 0s - loss: 0.2631 - acc: 0.997 - ETA: 0s - loss: 0.2630 - acc: 0.997 - ETA: 0s - loss: 0.2630 - acc: 0.997 - ETA: 0s - loss: 0.2636 - acc: 0.997 - ETA: 0s - loss: 0.2641 - acc: 0.997 - ETA: 0s - loss: 0.2643 - acc: 0.997 - ETA: 0s - loss: 0.2642 - acc: 0.997 - ETA: 0s - loss: 0.2644 - acc: 0.997 - ETA: 0s - loss: 0.2645 - acc: 0.997 - ETA: 0s - loss: 0.2645 - acc: 0.997 - ETA: 0s - loss: 0.2642 - acc: 0.997 - ETA: 0s - loss: 0.2643 - acc: 0.9971Epoch 00018: val_loss improved from 0.95612 to 0.92655, saving model to saved_models/weights.best.VGG19.hdf5\n",
      "6680/6680 [==============================] - 4s - loss: 0.2643 - acc: 0.9972 - val_loss: 0.9266 - val_acc: 0.7856\n",
      "Epoch 20/30\n",
      "6608/6680 [============================>.] - ETA: 5s - loss: 0.2237 - acc: 1.000 - ETA: 4s - loss: 0.2416 - acc: 1.000 - ETA: 4s - loss: 0.2549 - acc: 1.000 - ETA: 4s - loss: 0.2517 - acc: 1.000 - ETA: 4s - loss: 0.2507 - acc: 1.000 - ETA: 3s - loss: 0.2503 - acc: 0.997 - ETA: 3s - loss: 0.2496 - acc: 0.998 - ETA: 3s - loss: 0.2487 - acc: 0.998 - ETA: 3s - loss: 0.2475 - acc: 0.998 - ETA: 3s - loss: 0.2462 - acc: 0.998 - ETA: 3s - loss: 0.2468 - acc: 0.998 - ETA: 3s - loss: 0.2453 - acc: 0.999 - ETA: 3s - loss: 0.2448 - acc: 0.999 - ETA: 3s - loss: 0.2449 - acc: 0.999 - ETA: 3s - loss: 0.2455 - acc: 0.999 - ETA: 3s - loss: 0.2465 - acc: 0.998 - ETA: 3s - loss: 0.2461 - acc: 0.998 - ETA: 3s - loss: 0.2458 - acc: 0.998 - ETA: 3s - loss: 0.2470 - acc: 0.998 - ETA: 3s - loss: 0.2467 - acc: 0.998 - ETA: 2s - loss: 0.2470 - acc: 0.998 - ETA: 2s - loss: 0.2475 - acc: 0.998 - ETA: 2s - loss: 0.2474 - acc: 0.998 - ETA: 2s - loss: 0.2472 - acc: 0.998 - ETA: 2s - loss: 0.2470 - acc: 0.998 - ETA: 2s - loss: 0.2467 - acc: 0.998 - ETA: 2s - loss: 0.2472 - acc: 0.998 - ETA: 2s - loss: 0.2480 - acc: 0.998 - ETA: 2s - loss: 0.2486 - acc: 0.997 - ETA: 2s - loss: 0.2486 - acc: 0.998 - ETA: 2s - loss: 0.2489 - acc: 0.997 - ETA: 2s - loss: 0.2495 - acc: 0.997 - ETA: 2s - loss: 0.2495 - acc: 0.997 - ETA: 2s - loss: 0.2497 - acc: 0.997 - ETA: 2s - loss: 0.2499 - acc: 0.998 - ETA: 2s - loss: 0.2494 - acc: 0.998 - ETA: 2s - loss: 0.2493 - acc: 0.998 - ETA: 2s - loss: 0.2489 - acc: 0.998 - ETA: 2s - loss: 0.2484 - acc: 0.998 - ETA: 2s - loss: 0.2484 - acc: 0.998 - ETA: 2s - loss: 0.2482 - acc: 0.998 - ETA: 1s - loss: 0.2484 - acc: 0.998 - ETA: 1s - loss: 0.2536 - acc: 0.997 - ETA: 1s - loss: 0.2538 - acc: 0.997 - ETA: 1s - loss: 0.2540 - acc: 0.997 - ETA: 1s - loss: 0.2538 - acc: 0.997 - ETA: 1s - loss: 0.2539 - acc: 0.997 - ETA: 1s - loss: 0.2538 - acc: 0.997 - ETA: 1s - loss: 0.2540 - acc: 0.997 - ETA: 1s - loss: 0.2539 - acc: 0.997 - ETA: 1s - loss: 0.2539 - acc: 0.997 - ETA: 1s - loss: 0.2538 - acc: 0.997 - ETA: 1s - loss: 0.2537 - acc: 0.997 - ETA: 1s - loss: 0.2537 - acc: 0.997 - ETA: 1s - loss: 0.2536 - acc: 0.997 - ETA: 1s - loss: 0.2535 - acc: 0.997 - ETA: 1s - loss: 0.2535 - acc: 0.997 - ETA: 1s - loss: 0.2532 - acc: 0.998 - ETA: 1s - loss: 0.2530 - acc: 0.998 - ETA: 1s - loss: 0.2530 - acc: 0.998 - ETA: 0s - loss: 0.2529 - acc: 0.998 - ETA: 0s - loss: 0.2527 - acc: 0.998 - ETA: 0s - loss: 0.2530 - acc: 0.997 - ETA: 0s - loss: 0.2529 - acc: 0.997 - ETA: 0s - loss: 0.2528 - acc: 0.998 - ETA: 0s - loss: 0.2528 - acc: 0.998 - ETA: 0s - loss: 0.2528 - acc: 0.998 - ETA: 0s - loss: 0.2531 - acc: 0.997 - ETA: 0s - loss: 0.2533 - acc: 0.997 - ETA: 0s - loss: 0.2536 - acc: 0.997 - ETA: 0s - loss: 0.2538 - acc: 0.998 - ETA: 0s - loss: 0.2539 - acc: 0.998 - ETA: 0s - loss: 0.2537 - acc: 0.998 - ETA: 0s - loss: 0.2538 - acc: 0.998 - ETA: 0s - loss: 0.2540 - acc: 0.997 - ETA: 0s - loss: 0.2542 - acc: 0.997 - ETA: 0s - loss: 0.2544 - acc: 0.997 - ETA: 0s - loss: 0.2542 - acc: 0.997 - ETA: 0s - loss: 0.2542 - acc: 0.9977Epoch 00019: val_loss improved from 0.92655 to 0.91873, saving model to saved_models/weights.best.VGG19.hdf5\n",
      "6680/6680 [==============================] - 4s - loss: 0.2543 - acc: 0.9978 - val_loss: 0.9187 - val_acc: 0.7784\n",
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6640/6680 [============================>.] - ETA: 4s - loss: 0.2249 - acc: 1.000 - ETA: 4s - loss: 0.2266 - acc: 1.000 - ETA: 4s - loss: 0.2239 - acc: 1.000 - ETA: 4s - loss: 0.2328 - acc: 1.000 - ETA: 4s - loss: 0.2351 - acc: 1.000 - ETA: 5s - loss: 0.2370 - acc: 1.000 - ETA: 5s - loss: 0.2360 - acc: 1.000 - ETA: 5s - loss: 0.2337 - acc: 1.000 - ETA: 5s - loss: 0.2346 - acc: 1.000 - ETA: 4s - loss: 0.2350 - acc: 1.000 - ETA: 4s - loss: 0.2347 - acc: 1.000 - ETA: 4s - loss: 0.2351 - acc: 1.000 - ETA: 4s - loss: 0.2364 - acc: 0.998 - ETA: 4s - loss: 0.2358 - acc: 0.999 - ETA: 4s - loss: 0.2357 - acc: 0.999 - ETA: 3s - loss: 0.2353 - acc: 0.999 - ETA: 3s - loss: 0.2346 - acc: 0.999 - ETA: 3s - loss: 0.2341 - acc: 0.999 - ETA: 3s - loss: 0.2340 - acc: 0.999 - ETA: 3s - loss: 0.2353 - acc: 0.998 - ETA: 3s - loss: 0.2356 - acc: 0.998 - ETA: 3s - loss: 0.2360 - acc: 0.998 - ETA: 3s - loss: 0.2357 - acc: 0.998 - ETA: 3s - loss: 0.2363 - acc: 0.998 - ETA: 3s - loss: 0.2377 - acc: 0.998 - ETA: 3s - loss: 0.2388 - acc: 0.998 - ETA: 3s - loss: 0.2389 - acc: 0.998 - ETA: 3s - loss: 0.2394 - acc: 0.998 - ETA: 3s - loss: 0.2394 - acc: 0.998 - ETA: 3s - loss: 0.2389 - acc: 0.998 - ETA: 3s - loss: 0.2386 - acc: 0.998 - ETA: 3s - loss: 0.2385 - acc: 0.998 - ETA: 2s - loss: 0.2384 - acc: 0.998 - ETA: 2s - loss: 0.2380 - acc: 0.998 - ETA: 2s - loss: 0.2383 - acc: 0.998 - ETA: 2s - loss: 0.2382 - acc: 0.998 - ETA: 2s - loss: 0.2383 - acc: 0.998 - ETA: 2s - loss: 0.2385 - acc: 0.999 - ETA: 2s - loss: 0.2387 - acc: 0.999 - ETA: 2s - loss: 0.2389 - acc: 0.998 - ETA: 2s - loss: 0.2392 - acc: 0.998 - ETA: 2s - loss: 0.2394 - acc: 0.998 - ETA: 2s - loss: 0.2395 - acc: 0.998 - ETA: 2s - loss: 0.2393 - acc: 0.998 - ETA: 2s - loss: 0.2394 - acc: 0.998 - ETA: 2s - loss: 0.2394 - acc: 0.998 - ETA: 2s - loss: 0.2395 - acc: 0.998 - ETA: 2s - loss: 0.2397 - acc: 0.998 - ETA: 2s - loss: 0.2399 - acc: 0.998 - ETA: 2s - loss: 0.2398 - acc: 0.998 - ETA: 2s - loss: 0.2402 - acc: 0.998 - ETA: 2s - loss: 0.2403 - acc: 0.999 - ETA: 2s - loss: 0.2402 - acc: 0.999 - ETA: 2s - loss: 0.2399 - acc: 0.999 - ETA: 1s - loss: 0.2407 - acc: 0.999 - ETA: 1s - loss: 0.2408 - acc: 0.999 - ETA: 1s - loss: 0.2410 - acc: 0.999 - ETA: 1s - loss: 0.2407 - acc: 0.999 - ETA: 1s - loss: 0.2408 - acc: 0.999 - ETA: 1s - loss: 0.2409 - acc: 0.999 - ETA: 1s - loss: 0.2411 - acc: 0.999 - ETA: 1s - loss: 0.2411 - acc: 0.999 - ETA: 1s - loss: 0.2415 - acc: 0.999 - ETA: 1s - loss: 0.2416 - acc: 0.999 - ETA: 1s - loss: 0.2419 - acc: 0.999 - ETA: 1s - loss: 0.2419 - acc: 0.999 - ETA: 1s - loss: 0.2424 - acc: 0.999 - ETA: 1s - loss: 0.2425 - acc: 0.998 - ETA: 0s - loss: 0.2427 - acc: 0.998 - ETA: 0s - loss: 0.2432 - acc: 0.998 - ETA: 0s - loss: 0.2462 - acc: 0.998 - ETA: 0s - loss: 0.2462 - acc: 0.998 - ETA: 0s - loss: 0.2462 - acc: 0.998 - ETA: 0s - loss: 0.2466 - acc: 0.998 - ETA: 0s - loss: 0.2470 - acc: 0.998 - ETA: 0s - loss: 0.2469 - acc: 0.998 - ETA: 0s - loss: 0.2468 - acc: 0.998 - ETA: 0s - loss: 0.2470 - acc: 0.998 - ETA: 0s - loss: 0.2472 - acc: 0.998 - ETA: 0s - loss: 0.2470 - acc: 0.998 - ETA: 0s - loss: 0.2471 - acc: 0.998 - ETA: 0s - loss: 0.2470 - acc: 0.998 - ETA: 0s - loss: 0.2471 - acc: 0.998 - ETA: 0s - loss: 0.2471 - acc: 0.9980Epoch 00020: val_loss improved from 0.91873 to 0.90720, saving model to saved_models/weights.best.VGG19.hdf5\n",
      "6680/6680 [==============================] - 5s - loss: 0.2472 - acc: 0.9981 - val_loss: 0.9072 - val_acc: 0.7737\n",
      "Epoch 22/30\n",
      "6656/6680 [============================>.] - ETA: 6s - loss: 0.2213 - acc: 1.000 - ETA: 5s - loss: 0.2270 - acc: 1.000 - ETA: 6s - loss: 0.2271 - acc: 1.000 - ETA: 5s - loss: 0.2262 - acc: 1.000 - ETA: 5s - loss: 0.2262 - acc: 1.000 - ETA: 5s - loss: 0.2274 - acc: 1.000 - ETA: 4s - loss: 0.2304 - acc: 1.000 - ETA: 4s - loss: 0.2314 - acc: 1.000 - ETA: 4s - loss: 0.2326 - acc: 1.000 - ETA: 4s - loss: 0.2331 - acc: 1.000 - ETA: 4s - loss: 0.2323 - acc: 1.000 - ETA: 4s - loss: 0.2309 - acc: 1.000 - ETA: 3s - loss: 0.2312 - acc: 1.000 - ETA: 3s - loss: 0.2310 - acc: 1.000 - ETA: 3s - loss: 0.2319 - acc: 1.000 - ETA: 3s - loss: 0.2320 - acc: 0.999 - ETA: 3s - loss: 0.2321 - acc: 0.999 - ETA: 3s - loss: 0.2316 - acc: 0.999 - ETA: 3s - loss: 0.2316 - acc: 0.999 - ETA: 3s - loss: 0.2316 - acc: 0.999 - ETA: 3s - loss: 0.2328 - acc: 0.999 - ETA: 3s - loss: 0.2324 - acc: 0.999 - ETA: 3s - loss: 0.2328 - acc: 0.999 - ETA: 3s - loss: 0.2323 - acc: 0.999 - ETA: 3s - loss: 0.2322 - acc: 0.999 - ETA: 3s - loss: 0.2325 - acc: 0.999 - ETA: 3s - loss: 0.2325 - acc: 0.999 - ETA: 3s - loss: 0.2327 - acc: 0.999 - ETA: 2s - loss: 0.2330 - acc: 0.999 - ETA: 2s - loss: 0.2326 - acc: 0.999 - ETA: 2s - loss: 0.2330 - acc: 0.999 - ETA: 2s - loss: 0.2334 - acc: 0.999 - ETA: 2s - loss: 0.2332 - acc: 0.999 - ETA: 2s - loss: 0.2334 - acc: 0.999 - ETA: 2s - loss: 0.2334 - acc: 0.999 - ETA: 2s - loss: 0.2331 - acc: 0.999 - ETA: 2s - loss: 0.2331 - acc: 0.999 - ETA: 2s - loss: 0.2332 - acc: 0.999 - ETA: 2s - loss: 0.2331 - acc: 0.999 - ETA: 2s - loss: 0.2330 - acc: 0.999 - ETA: 2s - loss: 0.2329 - acc: 0.999 - ETA: 2s - loss: 0.2329 - acc: 0.999 - ETA: 2s - loss: 0.2332 - acc: 0.999 - ETA: 2s - loss: 0.2333 - acc: 0.999 - ETA: 2s - loss: 0.2332 - acc: 0.999 - ETA: 2s - loss: 0.2331 - acc: 0.999 - ETA: 2s - loss: 0.2334 - acc: 0.999 - ETA: 2s - loss: 0.2334 - acc: 0.999 - ETA: 2s - loss: 0.2334 - acc: 0.999 - ETA: 2s - loss: 0.2334 - acc: 0.999 - ETA: 2s - loss: 0.2334 - acc: 0.999 - ETA: 2s - loss: 0.2335 - acc: 0.999 - ETA: 2s - loss: 0.2336 - acc: 0.999 - ETA: 2s - loss: 0.2337 - acc: 0.999 - ETA: 2s - loss: 0.2340 - acc: 0.999 - ETA: 2s - loss: 0.2343 - acc: 0.999 - ETA: 2s - loss: 0.2343 - acc: 0.999 - ETA: 1s - loss: 0.2344 - acc: 0.999 - ETA: 1s - loss: 0.2345 - acc: 0.999 - ETA: 1s - loss: 0.2346 - acc: 0.999 - ETA: 1s - loss: 0.2346 - acc: 0.999 - ETA: 1s - loss: 0.2345 - acc: 0.999 - ETA: 1s - loss: 0.2345 - acc: 0.999 - ETA: 1s - loss: 0.2343 - acc: 0.999 - ETA: 1s - loss: 0.2345 - acc: 0.999 - ETA: 1s - loss: 0.2349 - acc: 0.999 - ETA: 1s - loss: 0.2358 - acc: 0.999 - ETA: 1s - loss: 0.2360 - acc: 0.999 - ETA: 1s - loss: 0.2357 - acc: 0.999 - ETA: 1s - loss: 0.2358 - acc: 0.999 - ETA: 1s - loss: 0.2362 - acc: 0.999 - ETA: 1s - loss: 0.2365 - acc: 0.998 - ETA: 1s - loss: 0.2369 - acc: 0.998 - ETA: 1s - loss: 0.2372 - acc: 0.998 - ETA: 1s - loss: 0.2400 - acc: 0.998 - ETA: 0s - loss: 0.2401 - acc: 0.998 - ETA: 0s - loss: 0.2399 - acc: 0.998 - ETA: 0s - loss: 0.2403 - acc: 0.998 - ETA: 0s - loss: 0.2407 - acc: 0.998 - ETA: 0s - loss: 0.2406 - acc: 0.998 - ETA: 0s - loss: 0.2406 - acc: 0.998 - ETA: 0s - loss: 0.2404 - acc: 0.998 - ETA: 0s - loss: 0.2406 - acc: 0.998 - ETA: 0s - loss: 0.2404 - acc: 0.998 - ETA: 0s - loss: 0.2405 - acc: 0.998 - ETA: 0s - loss: 0.2404 - acc: 0.998 - ETA: 0s - loss: 0.2406 - acc: 0.998 - ETA: 0s - loss: 0.2410 - acc: 0.998 - ETA: 0s - loss: 0.2408 - acc: 0.998 - ETA: 0s - loss: 0.2409 - acc: 0.998 - ETA: 0s - loss: 0.2407 - acc: 0.998 - ETA: 0s - loss: 0.2407 - acc: 0.9986Epoch 00021: val_loss improved from 0.90720 to 0.87845, saving model to saved_models/weights.best.VGG19.hdf5\n",
      "6680/6680 [==============================] - 5s - loss: 0.2408 - acc: 0.9987 - val_loss: 0.8784 - val_acc: 0.7844\n",
      "Epoch 23/30\n",
      "6624/6680 [============================>.] - ETA: 4s - loss: 0.2136 - acc: 1.000 - ETA: 4s - loss: 0.2238 - acc: 1.000 - ETA: 4s - loss: 0.2183 - acc: 1.000 - ETA: 3s - loss: 0.2265 - acc: 1.000 - ETA: 3s - loss: 0.2284 - acc: 1.000 - ETA: 3s - loss: 0.2277 - acc: 1.000 - ETA: 3s - loss: 0.2275 - acc: 1.000 - ETA: 3s - loss: 0.2285 - acc: 0.998 - ETA: 3s - loss: 0.2277 - acc: 0.997 - ETA: 3s - loss: 0.2310 - acc: 0.997 - ETA: 3s - loss: 0.2327 - acc: 0.996 - ETA: 3s - loss: 0.2308 - acc: 0.997 - ETA: 3s - loss: 0.2321 - acc: 0.997 - ETA: 3s - loss: 0.2315 - acc: 0.997 - ETA: 3s - loss: 0.2310 - acc: 0.997 - ETA: 3s - loss: 0.2301 - acc: 0.997 - ETA: 3s - loss: 0.2299 - acc: 0.997 - ETA: 3s - loss: 0.2289 - acc: 0.998 - ETA: 3s - loss: 0.2285 - acc: 0.998 - ETA: 3s - loss: 0.2286 - acc: 0.998 - ETA: 3s - loss: 0.2284 - acc: 0.998 - ETA: 3s - loss: 0.2276 - acc: 0.998 - ETA: 2s - loss: 0.2277 - acc: 0.998 - ETA: 2s - loss: 0.2270 - acc: 0.998 - ETA: 2s - loss: 0.2264 - acc: 0.998 - ETA: 2s - loss: 0.2268 - acc: 0.998 - ETA: 2s - loss: 0.2272 - acc: 0.998 - ETA: 2s - loss: 0.2265 - acc: 0.998 - ETA: 2s - loss: 0.2265 - acc: 0.998 - ETA: 2s - loss: 0.2313 - acc: 0.998 - ETA: 2s - loss: 0.2316 - acc: 0.998 - ETA: 2s - loss: 0.2321 - acc: 0.997 - ETA: 2s - loss: 0.2319 - acc: 0.997 - ETA: 2s - loss: 0.2317 - acc: 0.997 - ETA: 2s - loss: 0.2315 - acc: 0.997 - ETA: 2s - loss: 0.2311 - acc: 0.997 - ETA: 2s - loss: 0.2312 - acc: 0.997 - ETA: 2s - loss: 0.2316 - acc: 0.997 - ETA: 2s - loss: 0.2321 - acc: 0.997 - ETA: 1s - loss: 0.2319 - acc: 0.997 - ETA: 1s - loss: 0.2321 - acc: 0.997 - ETA: 1s - loss: 0.2323 - acc: 0.997 - ETA: 1s - loss: 0.2325 - acc: 0.997 - ETA: 1s - loss: 0.2326 - acc: 0.997 - ETA: 1s - loss: 0.2327 - acc: 0.998 - ETA: 1s - loss: 0.2327 - acc: 0.998 - ETA: 1s - loss: 0.2327 - acc: 0.998 - ETA: 1s - loss: 0.2327 - acc: 0.998 - ETA: 1s - loss: 0.2327 - acc: 0.997 - ETA: 1s - loss: 0.2324 - acc: 0.997 - ETA: 1s - loss: 0.2326 - acc: 0.997 - ETA: 1s - loss: 0.2326 - acc: 0.997 - ETA: 1s - loss: 0.2326 - acc: 0.997 - ETA: 1s - loss: 0.2330 - acc: 0.997 - ETA: 1s - loss: 0.2335 - acc: 0.997 - ETA: 1s - loss: 0.2333 - acc: 0.997 - ETA: 1s - loss: 0.2332 - acc: 0.997 - ETA: 0s - loss: 0.2333 - acc: 0.997 - ETA: 0s - loss: 0.2332 - acc: 0.997 - ETA: 0s - loss: 0.2334 - acc: 0.997 - ETA: 0s - loss: 0.2333 - acc: 0.997 - ETA: 0s - loss: 0.2332 - acc: 0.997 - ETA: 0s - loss: 0.2333 - acc: 0.997 - ETA: 0s - loss: 0.2334 - acc: 0.997 - ETA: 0s - loss: 0.2332 - acc: 0.997 - ETA: 0s - loss: 0.2334 - acc: 0.997 - ETA: 0s - loss: 0.2333 - acc: 0.997 - ETA: 0s - loss: 0.2337 - acc: 0.997 - ETA: 0s - loss: 0.2338 - acc: 0.997 - ETA: 0s - loss: 0.2337 - acc: 0.997 - ETA: 0s - loss: 0.2337 - acc: 0.997 - ETA: 0s - loss: 0.2337 - acc: 0.997 - ETA: 0s - loss: 0.2337 - acc: 0.997 - ETA: 0s - loss: 0.2335 - acc: 0.997 - ETA: 0s - loss: 0.2337 - acc: 0.997 - ETA: 0s - loss: 0.2337 - acc: 0.9977Epoch 00022: val_loss did not improve\n",
      "6680/6680 [==============================] - 4s - loss: 0.2338 - acc: 0.9976 - val_loss: 0.8897 - val_acc: 0.7868\n",
      "Epoch 24/30\n",
      "6640/6680 [============================>.] - ETA: 5s - loss: 0.2004 - acc: 1.000 - ETA: 4s - loss: 0.2256 - acc: 1.000 - ETA: 4s - loss: 0.2241 - acc: 1.000 - ETA: 4s - loss: 0.2245 - acc: 1.000 - ETA: 4s - loss: 0.2200 - acc: 1.000 - ETA: 3s - loss: 0.2279 - acc: 0.997 - ETA: 3s - loss: 0.2280 - acc: 0.998 - ETA: 3s - loss: 0.2263 - acc: 0.998 - ETA: 3s - loss: 0.2245 - acc: 0.998 - ETA: 3s - loss: 0.2250 - acc: 0.997 - ETA: 3s - loss: 0.2238 - acc: 0.997 - ETA: 3s - loss: 0.2229 - acc: 0.997 - ETA: 3s - loss: 0.2223 - acc: 0.998 - ETA: 3s - loss: 0.2239 - acc: 0.997 - ETA: 3s - loss: 0.2236 - acc: 0.997 - ETA: 3s - loss: 0.2246 - acc: 0.997 - ETA: 3s - loss: 0.2241 - acc: 0.997 - ETA: 3s - loss: 0.2236 - acc: 0.998 - ETA: 3s - loss: 0.2227 - acc: 0.998 - ETA: 3s - loss: 0.2237 - acc: 0.997 - ETA: 3s - loss: 0.2237 - acc: 0.997 - ETA: 3s - loss: 0.2235 - acc: 0.997 - ETA: 3s - loss: 0.2238 - acc: 0.997 - ETA: 3s - loss: 0.2237 - acc: 0.998 - ETA: 2s - loss: 0.2229 - acc: 0.998 - ETA: 2s - loss: 0.2227 - acc: 0.998 - ETA: 2s - loss: 0.2229 - acc: 0.998 - ETA: 2s - loss: 0.2235 - acc: 0.997 - ETA: 2s - loss: 0.2232 - acc: 0.997 - ETA: 2s - loss: 0.2232 - acc: 0.997 - ETA: 2s - loss: 0.2233 - acc: 0.998 - ETA: 2s - loss: 0.2239 - acc: 0.998 - ETA: 2s - loss: 0.2235 - acc: 0.998 - ETA: 2s - loss: 0.2233 - acc: 0.998 - ETA: 2s - loss: 0.2231 - acc: 0.998 - ETA: 2s - loss: 0.2234 - acc: 0.998 - ETA: 2s - loss: 0.2237 - acc: 0.998 - ETA: 2s - loss: 0.2234 - acc: 0.998 - ETA: 2s - loss: 0.2235 - acc: 0.998 - ETA: 2s - loss: 0.2238 - acc: 0.998 - ETA: 2s - loss: 0.2238 - acc: 0.998 - ETA: 2s - loss: 0.2235 - acc: 0.998 - ETA: 2s - loss: 0.2234 - acc: 0.998 - ETA: 2s - loss: 0.2234 - acc: 0.998 - ETA: 2s - loss: 0.2235 - acc: 0.998 - ETA: 2s - loss: 0.2240 - acc: 0.998 - ETA: 2s - loss: 0.2237 - acc: 0.998 - ETA: 1s - loss: 0.2238 - acc: 0.998 - ETA: 1s - loss: 0.2238 - acc: 0.998 - ETA: 1s - loss: 0.2237 - acc: 0.998 - ETA: 1s - loss: 0.2234 - acc: 0.998 - ETA: 1s - loss: 0.2232 - acc: 0.998 - ETA: 1s - loss: 0.2236 - acc: 0.998 - ETA: 1s - loss: 0.2235 - acc: 0.998 - ETA: 1s - loss: 0.2235 - acc: 0.998 - ETA: 1s - loss: 0.2236 - acc: 0.998 - ETA: 1s - loss: 0.2238 - acc: 0.998 - ETA: 1s - loss: 0.2239 - acc: 0.998 - ETA: 1s - loss: 0.2241 - acc: 0.998 - ETA: 1s - loss: 0.2240 - acc: 0.998 - ETA: 1s - loss: 0.2240 - acc: 0.998 - ETA: 1s - loss: 0.2240 - acc: 0.998 - ETA: 1s - loss: 0.2243 - acc: 0.998 - ETA: 1s - loss: 0.2245 - acc: 0.998 - ETA: 0s - loss: 0.2244 - acc: 0.998 - ETA: 0s - loss: 0.2245 - acc: 0.998 - ETA: 0s - loss: 0.2243 - acc: 0.998 - ETA: 0s - loss: 0.2245 - acc: 0.998 - ETA: 0s - loss: 0.2245 - acc: 0.998 - ETA: 0s - loss: 0.2246 - acc: 0.998 - ETA: 0s - loss: 0.2251 - acc: 0.999 - ETA: 0s - loss: 0.2255 - acc: 0.998 - ETA: 0s - loss: 0.2255 - acc: 0.998 - ETA: 0s - loss: 0.2256 - acc: 0.998 - ETA: 0s - loss: 0.2274 - acc: 0.998 - ETA: 0s - loss: 0.2277 - acc: 0.998 - ETA: 0s - loss: 0.2279 - acc: 0.998 - ETA: 0s - loss: 0.2279 - acc: 0.998 - ETA: 0s - loss: 0.2283 - acc: 0.998 - ETA: 0s - loss: 0.2284 - acc: 0.998 - ETA: 0s - loss: 0.2283 - acc: 0.998 - ETA: 0s - loss: 0.2283 - acc: 0.998 - ETA: 0s - loss: 0.2285 - acc: 0.9982Epoch 00023: val_loss did not improve\n",
      "6680/6680 [==============================] - 4s - loss: 0.2288 - acc: 0.9982 - val_loss: 0.8788 - val_acc: 0.7832\n",
      "Epoch 25/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6624/6680 [============================>.] - ETA: 4s - loss: 0.2542 - acc: 1.000 - ETA: 4s - loss: 0.2255 - acc: 1.000 - ETA: 4s - loss: 0.2244 - acc: 1.000 - ETA: 4s - loss: 0.2287 - acc: 0.996 - ETA: 4s - loss: 0.2240 - acc: 0.997 - ETA: 3s - loss: 0.2225 - acc: 0.997 - ETA: 4s - loss: 0.2219 - acc: 0.998 - ETA: 4s - loss: 0.2219 - acc: 0.998 - ETA: 4s - loss: 0.2221 - acc: 0.998 - ETA: 4s - loss: 0.2205 - acc: 0.998 - ETA: 4s - loss: 0.2199 - acc: 0.998 - ETA: 4s - loss: 0.2182 - acc: 0.998 - ETA: 4s - loss: 0.2179 - acc: 0.998 - ETA: 4s - loss: 0.2184 - acc: 0.999 - ETA: 4s - loss: 0.2182 - acc: 0.999 - ETA: 3s - loss: 0.2173 - acc: 0.999 - ETA: 3s - loss: 0.2245 - acc: 0.998 - ETA: 3s - loss: 0.2240 - acc: 0.998 - ETA: 3s - loss: 0.2238 - acc: 0.998 - ETA: 3s - loss: 0.2239 - acc: 0.998 - ETA: 3s - loss: 0.2233 - acc: 0.998 - ETA: 3s - loss: 0.2228 - acc: 0.998 - ETA: 3s - loss: 0.2223 - acc: 0.998 - ETA: 3s - loss: 0.2216 - acc: 0.998 - ETA: 3s - loss: 0.2215 - acc: 0.998 - ETA: 3s - loss: 0.2218 - acc: 0.998 - ETA: 3s - loss: 0.2210 - acc: 0.999 - ETA: 3s - loss: 0.2213 - acc: 0.999 - ETA: 3s - loss: 0.2210 - acc: 0.999 - ETA: 3s - loss: 0.2215 - acc: 0.998 - ETA: 3s - loss: 0.2211 - acc: 0.998 - ETA: 3s - loss: 0.2220 - acc: 0.998 - ETA: 3s - loss: 0.2215 - acc: 0.998 - ETA: 2s - loss: 0.2214 - acc: 0.998 - ETA: 2s - loss: 0.2207 - acc: 0.998 - ETA: 2s - loss: 0.2207 - acc: 0.998 - ETA: 2s - loss: 0.2203 - acc: 0.998 - ETA: 2s - loss: 0.2200 - acc: 0.998 - ETA: 2s - loss: 0.2199 - acc: 0.998 - ETA: 2s - loss: 0.2197 - acc: 0.998 - ETA: 2s - loss: 0.2196 - acc: 0.998 - ETA: 2s - loss: 0.2196 - acc: 0.998 - ETA: 2s - loss: 0.2195 - acc: 0.998 - ETA: 2s - loss: 0.2193 - acc: 0.998 - ETA: 2s - loss: 0.2194 - acc: 0.998 - ETA: 2s - loss: 0.2193 - acc: 0.998 - ETA: 2s - loss: 0.2191 - acc: 0.998 - ETA: 2s - loss: 0.2192 - acc: 0.998 - ETA: 1s - loss: 0.2190 - acc: 0.998 - ETA: 1s - loss: 0.2193 - acc: 0.998 - ETA: 1s - loss: 0.2196 - acc: 0.998 - ETA: 1s - loss: 0.2197 - acc: 0.998 - ETA: 1s - loss: 0.2195 - acc: 0.998 - ETA: 1s - loss: 0.2195 - acc: 0.998 - ETA: 1s - loss: 0.2196 - acc: 0.998 - ETA: 1s - loss: 0.2196 - acc: 0.998 - ETA: 1s - loss: 0.2200 - acc: 0.998 - ETA: 1s - loss: 0.2202 - acc: 0.998 - ETA: 1s - loss: 0.2200 - acc: 0.998 - ETA: 1s - loss: 0.2200 - acc: 0.999 - ETA: 1s - loss: 0.2200 - acc: 0.999 - ETA: 1s - loss: 0.2202 - acc: 0.999 - ETA: 1s - loss: 0.2203 - acc: 0.998 - ETA: 1s - loss: 0.2206 - acc: 0.998 - ETA: 1s - loss: 0.2204 - acc: 0.998 - ETA: 0s - loss: 0.2207 - acc: 0.998 - ETA: 0s - loss: 0.2211 - acc: 0.998 - ETA: 0s - loss: 0.2210 - acc: 0.998 - ETA: 0s - loss: 0.2213 - acc: 0.998 - ETA: 0s - loss: 0.2215 - acc: 0.998 - ETA: 0s - loss: 0.2221 - acc: 0.998 - ETA: 0s - loss: 0.2226 - acc: 0.998 - ETA: 0s - loss: 0.2228 - acc: 0.998 - ETA: 0s - loss: 0.2228 - acc: 0.998 - ETA: 0s - loss: 0.2233 - acc: 0.997 - ETA: 0s - loss: 0.2235 - acc: 0.997 - ETA: 0s - loss: 0.2239 - acc: 0.997 - ETA: 0s - loss: 0.2239 - acc: 0.997 - ETA: 0s - loss: 0.2238 - acc: 0.997 - ETA: 0s - loss: 0.2239 - acc: 0.997 - ETA: 0s - loss: 0.2240 - acc: 0.9979Epoch 00024: val_loss improved from 0.87845 to 0.86552, saving model to saved_models/weights.best.VGG19.hdf5\n",
      "6680/6680 [==============================] - 4s - loss: 0.2242 - acc: 0.9979 - val_loss: 0.8655 - val_acc: 0.7749\n",
      "Epoch 26/30\n",
      "6624/6680 [============================>.] - ETA: 4s - loss: 0.1858 - acc: 1.000 - ETA: 4s - loss: 0.2073 - acc: 1.000 - ETA: 4s - loss: 0.2105 - acc: 1.000 - ETA: 4s - loss: 0.2063 - acc: 1.000 - ETA: 3s - loss: 0.2300 - acc: 0.997 - ETA: 3s - loss: 0.2280 - acc: 0.997 - ETA: 3s - loss: 0.2239 - acc: 0.998 - ETA: 3s - loss: 0.2210 - acc: 0.998 - ETA: 3s - loss: 0.2200 - acc: 0.998 - ETA: 3s - loss: 0.2184 - acc: 0.998 - ETA: 3s - loss: 0.2188 - acc: 0.998 - ETA: 3s - loss: 0.2183 - acc: 0.999 - ETA: 3s - loss: 0.2168 - acc: 0.999 - ETA: 3s - loss: 0.2166 - acc: 0.999 - ETA: 3s - loss: 0.2165 - acc: 0.999 - ETA: 3s - loss: 0.2155 - acc: 0.999 - ETA: 3s - loss: 0.2153 - acc: 0.999 - ETA: 3s - loss: 0.2169 - acc: 0.999 - ETA: 3s - loss: 0.2166 - acc: 0.999 - ETA: 3s - loss: 0.2163 - acc: 0.999 - ETA: 2s - loss: 0.2167 - acc: 0.999 - ETA: 2s - loss: 0.2162 - acc: 0.999 - ETA: 2s - loss: 0.2160 - acc: 0.999 - ETA: 2s - loss: 0.2160 - acc: 0.999 - ETA: 2s - loss: 0.2161 - acc: 0.999 - ETA: 2s - loss: 0.2156 - acc: 0.999 - ETA: 2s - loss: 0.2157 - acc: 0.999 - ETA: 2s - loss: 0.2156 - acc: 0.999 - ETA: 2s - loss: 0.2151 - acc: 0.999 - ETA: 2s - loss: 0.2153 - acc: 0.999 - ETA: 2s - loss: 0.2150 - acc: 0.999 - ETA: 2s - loss: 0.2152 - acc: 0.999 - ETA: 2s - loss: 0.2154 - acc: 0.999 - ETA: 2s - loss: 0.2153 - acc: 0.999 - ETA: 2s - loss: 0.2153 - acc: 0.999 - ETA: 2s - loss: 0.2154 - acc: 0.999 - ETA: 2s - loss: 0.2150 - acc: 0.999 - ETA: 2s - loss: 0.2149 - acc: 0.999 - ETA: 2s - loss: 0.2150 - acc: 0.999 - ETA: 2s - loss: 0.2154 - acc: 0.999 - ETA: 2s - loss: 0.2152 - acc: 0.999 - ETA: 1s - loss: 0.2153 - acc: 0.999 - ETA: 1s - loss: 0.2154 - acc: 0.999 - ETA: 1s - loss: 0.2154 - acc: 0.999 - ETA: 1s - loss: 0.2154 - acc: 0.999 - ETA: 1s - loss: 0.2155 - acc: 0.999 - ETA: 1s - loss: 0.2159 - acc: 0.999 - ETA: 1s - loss: 0.2156 - acc: 0.999 - ETA: 1s - loss: 0.2157 - acc: 0.999 - ETA: 1s - loss: 0.2154 - acc: 0.999 - ETA: 1s - loss: 0.2156 - acc: 0.999 - ETA: 1s - loss: 0.2156 - acc: 0.999 - ETA: 1s - loss: 0.2154 - acc: 0.999 - ETA: 1s - loss: 0.2155 - acc: 0.999 - ETA: 1s - loss: 0.2154 - acc: 0.999 - ETA: 1s - loss: 0.2154 - acc: 0.999 - ETA: 1s - loss: 0.2156 - acc: 0.999 - ETA: 1s - loss: 0.2159 - acc: 0.999 - ETA: 1s - loss: 0.2160 - acc: 0.999 - ETA: 0s - loss: 0.2160 - acc: 0.999 - ETA: 0s - loss: 0.2159 - acc: 0.999 - ETA: 0s - loss: 0.2167 - acc: 0.998 - ETA: 0s - loss: 0.2167 - acc: 0.998 - ETA: 0s - loss: 0.2166 - acc: 0.998 - ETA: 0s - loss: 0.2168 - acc: 0.998 - ETA: 0s - loss: 0.2171 - acc: 0.998 - ETA: 0s - loss: 0.2174 - acc: 0.998 - ETA: 0s - loss: 0.2175 - acc: 0.998 - ETA: 0s - loss: 0.2179 - acc: 0.998 - ETA: 0s - loss: 0.2181 - acc: 0.998 - ETA: 0s - loss: 0.2182 - acc: 0.998 - ETA: 0s - loss: 0.2182 - acc: 0.998 - ETA: 0s - loss: 0.2182 - acc: 0.998 - ETA: 0s - loss: 0.2181 - acc: 0.998 - ETA: 0s - loss: 0.2183 - acc: 0.998 - ETA: 0s - loss: 0.2182 - acc: 0.998 - ETA: 0s - loss: 0.2183 - acc: 0.9986Epoch 00025: val_loss improved from 0.86552 to 0.85236, saving model to saved_models/weights.best.VGG19.hdf5\n",
      "6680/6680 [==============================] - 4s - loss: 0.2186 - acc: 0.9985 - val_loss: 0.8524 - val_acc: 0.7868\n",
      "Epoch 27/30\n",
      "6608/6680 [============================>.] - ETA: 6s - loss: 0.1875 - acc: 1.000 - ETA: 5s - loss: 0.2063 - acc: 1.000 - ETA: 5s - loss: 0.2051 - acc: 1.000 - ETA: 5s - loss: 0.2030 - acc: 1.000 - ETA: 5s - loss: 0.2045 - acc: 1.000 - ETA: 4s - loss: 0.2067 - acc: 1.000 - ETA: 4s - loss: 0.2087 - acc: 1.000 - ETA: 4s - loss: 0.2093 - acc: 1.000 - ETA: 4s - loss: 0.2086 - acc: 1.000 - ETA: 4s - loss: 0.2077 - acc: 1.000 - ETA: 4s - loss: 0.2097 - acc: 1.000 - ETA: 4s - loss: 0.2083 - acc: 1.000 - ETA: 3s - loss: 0.2082 - acc: 1.000 - ETA: 3s - loss: 0.2074 - acc: 1.000 - ETA: 3s - loss: 0.2080 - acc: 1.000 - ETA: 3s - loss: 0.2070 - acc: 1.000 - ETA: 3s - loss: 0.2070 - acc: 1.000 - ETA: 3s - loss: 0.2081 - acc: 1.000 - ETA: 3s - loss: 0.2082 - acc: 1.000 - ETA: 3s - loss: 0.2086 - acc: 1.000 - ETA: 3s - loss: 0.2081 - acc: 1.000 - ETA: 3s - loss: 0.2084 - acc: 1.000 - ETA: 3s - loss: 0.2085 - acc: 1.000 - ETA: 3s - loss: 0.2080 - acc: 1.000 - ETA: 3s - loss: 0.2078 - acc: 1.000 - ETA: 3s - loss: 0.2082 - acc: 1.000 - ETA: 2s - loss: 0.2085 - acc: 1.000 - ETA: 2s - loss: 0.2086 - acc: 1.000 - ETA: 2s - loss: 0.2090 - acc: 1.000 - ETA: 2s - loss: 0.2091 - acc: 1.000 - ETA: 2s - loss: 0.2095 - acc: 1.000 - ETA: 2s - loss: 0.2099 - acc: 0.999 - ETA: 2s - loss: 0.2099 - acc: 0.999 - ETA: 2s - loss: 0.2099 - acc: 0.999 - ETA: 2s - loss: 0.2099 - acc: 0.999 - ETA: 2s - loss: 0.2105 - acc: 0.999 - ETA: 2s - loss: 0.2107 - acc: 0.999 - ETA: 2s - loss: 0.2107 - acc: 0.999 - ETA: 2s - loss: 0.2109 - acc: 0.999 - ETA: 2s - loss: 0.2108 - acc: 0.999 - ETA: 2s - loss: 0.2114 - acc: 0.998 - ETA: 2s - loss: 0.2123 - acc: 0.998 - ETA: 2s - loss: 0.2124 - acc: 0.998 - ETA: 2s - loss: 0.2126 - acc: 0.998 - ETA: 2s - loss: 0.2124 - acc: 0.998 - ETA: 1s - loss: 0.2129 - acc: 0.998 - ETA: 1s - loss: 0.2130 - acc: 0.998 - ETA: 1s - loss: 0.2131 - acc: 0.998 - ETA: 1s - loss: 0.2131 - acc: 0.998 - ETA: 1s - loss: 0.2132 - acc: 0.998 - ETA: 1s - loss: 0.2132 - acc: 0.998 - ETA: 1s - loss: 0.2134 - acc: 0.998 - ETA: 1s - loss: 0.2133 - acc: 0.998 - ETA: 1s - loss: 0.2134 - acc: 0.998 - ETA: 1s - loss: 0.2134 - acc: 0.998 - ETA: 1s - loss: 0.2130 - acc: 0.998 - ETA: 1s - loss: 0.2131 - acc: 0.998 - ETA: 1s - loss: 0.2128 - acc: 0.998 - ETA: 1s - loss: 0.2132 - acc: 0.998 - ETA: 1s - loss: 0.2132 - acc: 0.998 - ETA: 1s - loss: 0.2134 - acc: 0.998 - ETA: 0s - loss: 0.2136 - acc: 0.998 - ETA: 0s - loss: 0.2137 - acc: 0.998 - ETA: 0s - loss: 0.2137 - acc: 0.998 - ETA: 0s - loss: 0.2137 - acc: 0.998 - ETA: 0s - loss: 0.2138 - acc: 0.998 - ETA: 0s - loss: 0.2137 - acc: 0.998 - ETA: 0s - loss: 0.2147 - acc: 0.998 - ETA: 0s - loss: 0.2150 - acc: 0.998 - ETA: 0s - loss: 0.2151 - acc: 0.998 - ETA: 0s - loss: 0.2151 - acc: 0.998 - ETA: 0s - loss: 0.2152 - acc: 0.998 - ETA: 0s - loss: 0.2155 - acc: 0.998 - ETA: 0s - loss: 0.2155 - acc: 0.998 - ETA: 0s - loss: 0.2156 - acc: 0.998 - ETA: 0s - loss: 0.2155 - acc: 0.998 - ETA: 0s - loss: 0.2153 - acc: 0.9988Epoch 00026: val_loss improved from 0.85236 to 0.85037, saving model to saved_models/weights.best.VGG19.hdf5\n",
      "6680/6680 [==============================] - 4s - loss: 0.2155 - acc: 0.9988 - val_loss: 0.8504 - val_acc: 0.7880\n",
      "Epoch 28/30\n",
      "6624/6680 [============================>.] - ETA: 4s - loss: 0.1928 - acc: 1.000 - ETA: 4s - loss: 0.1931 - acc: 1.000 - ETA: 3s - loss: 0.1968 - acc: 1.000 - ETA: 3s - loss: 0.2037 - acc: 0.996 - ETA: 3s - loss: 0.2052 - acc: 0.997 - ETA: 3s - loss: 0.2049 - acc: 0.997 - ETA: 3s - loss: 0.2049 - acc: 0.998 - ETA: 3s - loss: 0.2046 - acc: 0.998 - ETA: 3s - loss: 0.2053 - acc: 0.998 - ETA: 3s - loss: 0.2037 - acc: 0.998 - ETA: 3s - loss: 0.2046 - acc: 0.998 - ETA: 3s - loss: 0.2043 - acc: 0.999 - ETA: 3s - loss: 0.2043 - acc: 0.999 - ETA: 3s - loss: 0.2035 - acc: 0.999 - ETA: 3s - loss: 0.2031 - acc: 0.999 - ETA: 3s - loss: 0.2033 - acc: 0.999 - ETA: 3s - loss: 0.2037 - acc: 0.999 - ETA: 3s - loss: 0.2041 - acc: 0.999 - ETA: 3s - loss: 0.2042 - acc: 0.999 - ETA: 3s - loss: 0.2046 - acc: 0.999 - ETA: 3s - loss: 0.2045 - acc: 0.999 - ETA: 3s - loss: 0.2054 - acc: 0.998 - ETA: 3s - loss: 0.2053 - acc: 0.999 - ETA: 3s - loss: 0.2049 - acc: 0.999 - ETA: 2s - loss: 0.2046 - acc: 0.999 - ETA: 2s - loss: 0.2043 - acc: 0.999 - ETA: 2s - loss: 0.2056 - acc: 0.998 - ETA: 2s - loss: 0.2052 - acc: 0.998 - ETA: 2s - loss: 0.2048 - acc: 0.998 - ETA: 2s - loss: 0.2053 - acc: 0.998 - ETA: 2s - loss: 0.2055 - acc: 0.998 - ETA: 2s - loss: 0.2055 - acc: 0.998 - ETA: 2s - loss: 0.2062 - acc: 0.998 - ETA: 2s - loss: 0.2065 - acc: 0.998 - ETA: 2s - loss: 0.2072 - acc: 0.998 - ETA: 2s - loss: 0.2068 - acc: 0.998 - ETA: 2s - loss: 0.2069 - acc: 0.998 - ETA: 2s - loss: 0.2073 - acc: 0.998 - ETA: 2s - loss: 0.2076 - acc: 0.998 - ETA: 2s - loss: 0.2075 - acc: 0.998 - ETA: 1s - loss: 0.2076 - acc: 0.998 - ETA: 1s - loss: 0.2077 - acc: 0.998 - ETA: 1s - loss: 0.2077 - acc: 0.998 - ETA: 1s - loss: 0.2077 - acc: 0.998 - ETA: 1s - loss: 0.2075 - acc: 0.998 - ETA: 1s - loss: 0.2076 - acc: 0.998 - ETA: 1s - loss: 0.2078 - acc: 0.998 - ETA: 1s - loss: 0.2076 - acc: 0.998 - ETA: 1s - loss: 0.2078 - acc: 0.998 - ETA: 1s - loss: 0.2081 - acc: 0.998 - ETA: 1s - loss: 0.2097 - acc: 0.998 - ETA: 1s - loss: 0.2095 - acc: 0.998 - ETA: 1s - loss: 0.2094 - acc: 0.998 - ETA: 1s - loss: 0.2094 - acc: 0.998 - ETA: 1s - loss: 0.2095 - acc: 0.998 - ETA: 1s - loss: 0.2096 - acc: 0.998 - ETA: 1s - loss: 0.2101 - acc: 0.998 - ETA: 1s - loss: 0.2101 - acc: 0.998 - ETA: 1s - loss: 0.2105 - acc: 0.998 - ETA: 0s - loss: 0.2103 - acc: 0.998 - ETA: 0s - loss: 0.2108 - acc: 0.998 - ETA: 0s - loss: 0.2110 - acc: 0.998 - ETA: 0s - loss: 0.2110 - acc: 0.998 - ETA: 0s - loss: 0.2113 - acc: 0.998 - ETA: 0s - loss: 0.2113 - acc: 0.998 - ETA: 0s - loss: 0.2113 - acc: 0.998 - ETA: 0s - loss: 0.2113 - acc: 0.998 - ETA: 0s - loss: 0.2112 - acc: 0.998 - ETA: 0s - loss: 0.2111 - acc: 0.998 - ETA: 0s - loss: 0.2109 - acc: 0.998 - ETA: 0s - loss: 0.2108 - acc: 0.998 - ETA: 0s - loss: 0.2108 - acc: 0.998 - ETA: 0s - loss: 0.2108 - acc: 0.998 - ETA: 0s - loss: 0.2112 - acc: 0.998 - ETA: 0s - loss: 0.2112 - acc: 0.998 - ETA: 0s - loss: 0.2114 - acc: 0.998 - ETA: 0s - loss: 0.2114 - acc: 0.9983Epoch 00027: val_loss improved from 0.85037 to 0.83965, saving model to saved_models/weights.best.VGG19.hdf5\n",
      "6680/6680 [==============================] - 4s - loss: 0.2113 - acc: 0.9984 - val_loss: 0.8397 - val_acc: 0.7880\n",
      "Epoch 29/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6656/6680 [============================>.] - ETA: 4s - loss: 0.1851 - acc: 1.000 - ETA: 3s - loss: 0.2034 - acc: 1.000 - ETA: 3s - loss: 0.2070 - acc: 1.000 - ETA: 3s - loss: 0.2023 - acc: 1.000 - ETA: 3s - loss: 0.2011 - acc: 1.000 - ETA: 3s - loss: 0.2005 - acc: 1.000 - ETA: 3s - loss: 0.2029 - acc: 1.000 - ETA: 3s - loss: 0.2027 - acc: 1.000 - ETA: 3s - loss: 0.2028 - acc: 1.000 - ETA: 3s - loss: 0.2018 - acc: 1.000 - ETA: 3s - loss: 0.2016 - acc: 1.000 - ETA: 3s - loss: 0.2018 - acc: 1.000 - ETA: 3s - loss: 0.2014 - acc: 1.000 - ETA: 3s - loss: 0.2024 - acc: 1.000 - ETA: 3s - loss: 0.2020 - acc: 1.000 - ETA: 3s - loss: 0.2024 - acc: 1.000 - ETA: 3s - loss: 0.2018 - acc: 1.000 - ETA: 3s - loss: 0.2026 - acc: 0.999 - ETA: 3s - loss: 0.2024 - acc: 0.999 - ETA: 3s - loss: 0.2019 - acc: 0.999 - ETA: 3s - loss: 0.2021 - acc: 0.999 - ETA: 2s - loss: 0.2025 - acc: 0.999 - ETA: 2s - loss: 0.2023 - acc: 0.999 - ETA: 2s - loss: 0.2028 - acc: 0.999 - ETA: 2s - loss: 0.2029 - acc: 0.999 - ETA: 2s - loss: 0.2029 - acc: 0.999 - ETA: 2s - loss: 0.2028 - acc: 0.999 - ETA: 2s - loss: 0.2030 - acc: 0.999 - ETA: 2s - loss: 0.2025 - acc: 0.999 - ETA: 2s - loss: 0.2024 - acc: 0.999 - ETA: 2s - loss: 0.2024 - acc: 0.999 - ETA: 2s - loss: 0.2025 - acc: 0.999 - ETA: 2s - loss: 0.2030 - acc: 0.999 - ETA: 2s - loss: 0.2026 - acc: 0.999 - ETA: 2s - loss: 0.2027 - acc: 0.999 - ETA: 2s - loss: 0.2035 - acc: 0.998 - ETA: 2s - loss: 0.2034 - acc: 0.998 - ETA: 2s - loss: 0.2034 - acc: 0.998 - ETA: 1s - loss: 0.2033 - acc: 0.998 - ETA: 1s - loss: 0.2034 - acc: 0.998 - ETA: 1s - loss: 0.2039 - acc: 0.998 - ETA: 1s - loss: 0.2038 - acc: 0.998 - ETA: 1s - loss: 0.2040 - acc: 0.998 - ETA: 1s - loss: 0.2044 - acc: 0.999 - ETA: 1s - loss: 0.2058 - acc: 0.998 - ETA: 1s - loss: 0.2061 - acc: 0.998 - ETA: 1s - loss: 0.2066 - acc: 0.998 - ETA: 1s - loss: 0.2068 - acc: 0.998 - ETA: 1s - loss: 0.2069 - acc: 0.998 - ETA: 1s - loss: 0.2073 - acc: 0.998 - ETA: 1s - loss: 0.2073 - acc: 0.998 - ETA: 1s - loss: 0.2072 - acc: 0.998 - ETA: 1s - loss: 0.2076 - acc: 0.998 - ETA: 1s - loss: 0.2073 - acc: 0.998 - ETA: 1s - loss: 0.2074 - acc: 0.998 - ETA: 1s - loss: 0.2071 - acc: 0.998 - ETA: 0s - loss: 0.2071 - acc: 0.998 - ETA: 0s - loss: 0.2069 - acc: 0.998 - ETA: 0s - loss: 0.2071 - acc: 0.998 - ETA: 0s - loss: 0.2072 - acc: 0.998 - ETA: 0s - loss: 0.2072 - acc: 0.998 - ETA: 0s - loss: 0.2073 - acc: 0.998 - ETA: 0s - loss: 0.2073 - acc: 0.998 - ETA: 0s - loss: 0.2076 - acc: 0.998 - ETA: 0s - loss: 0.2081 - acc: 0.998 - ETA: 0s - loss: 0.2081 - acc: 0.998 - ETA: 0s - loss: 0.2082 - acc: 0.998 - ETA: 0s - loss: 0.2088 - acc: 0.998 - ETA: 0s - loss: 0.2087 - acc: 0.998 - ETA: 0s - loss: 0.2090 - acc: 0.998 - ETA: 0s - loss: 0.2090 - acc: 0.998 - ETA: 0s - loss: 0.2093 - acc: 0.998 - ETA: 0s - loss: 0.2092 - acc: 0.998 - ETA: 0s - loss: 0.2092 - acc: 0.9983Epoch 00028: val_loss did not improve\n",
      "6680/6680 [==============================] - 4s - loss: 0.2092 - acc: 0.9984 - val_loss: 0.8435 - val_acc: 0.7772\n",
      "Epoch 30/30\n",
      "6656/6680 [============================>.] - ETA: 4s - loss: 0.2640 - acc: 0.937 - ETA: 4s - loss: 0.2184 - acc: 0.989 - ETA: 4s - loss: 0.2110 - acc: 0.994 - ETA: 4s - loss: 0.2106 - acc: 0.996 - ETA: 3s - loss: 0.2081 - acc: 0.997 - ETA: 3s - loss: 0.2057 - acc: 0.997 - ETA: 3s - loss: 0.2041 - acc: 0.998 - ETA: 3s - loss: 0.2036 - acc: 0.998 - ETA: 3s - loss: 0.2028 - acc: 0.998 - ETA: 3s - loss: 0.2032 - acc: 0.998 - ETA: 3s - loss: 0.2020 - acc: 0.998 - ETA: 3s - loss: 0.2011 - acc: 0.999 - ETA: 3s - loss: 0.2014 - acc: 0.999 - ETA: 3s - loss: 0.2022 - acc: 0.999 - ETA: 3s - loss: 0.2016 - acc: 0.999 - ETA: 3s - loss: 0.2015 - acc: 0.999 - ETA: 3s - loss: 0.2016 - acc: 0.999 - ETA: 3s - loss: 0.2013 - acc: 0.999 - ETA: 3s - loss: 0.2024 - acc: 0.998 - ETA: 3s - loss: 0.2019 - acc: 0.998 - ETA: 3s - loss: 0.2021 - acc: 0.998 - ETA: 2s - loss: 0.2026 - acc: 0.998 - ETA: 2s - loss: 0.2020 - acc: 0.999 - ETA: 2s - loss: 0.2016 - acc: 0.999 - ETA: 2s - loss: 0.2014 - acc: 0.999 - ETA: 2s - loss: 0.2021 - acc: 0.998 - ETA: 2s - loss: 0.2020 - acc: 0.998 - ETA: 2s - loss: 0.2019 - acc: 0.998 - ETA: 2s - loss: 0.2018 - acc: 0.998 - ETA: 2s - loss: 0.2016 - acc: 0.998 - ETA: 2s - loss: 0.2016 - acc: 0.998 - ETA: 2s - loss: 0.2013 - acc: 0.998 - ETA: 2s - loss: 0.2013 - acc: 0.999 - ETA: 2s - loss: 0.2010 - acc: 0.999 - ETA: 2s - loss: 0.2008 - acc: 0.999 - ETA: 2s - loss: 0.2008 - acc: 0.999 - ETA: 2s - loss: 0.2008 - acc: 0.999 - ETA: 2s - loss: 0.2007 - acc: 0.999 - ETA: 1s - loss: 0.2006 - acc: 0.999 - ETA: 1s - loss: 0.2006 - acc: 0.999 - ETA: 1s - loss: 0.2005 - acc: 0.999 - ETA: 1s - loss: 0.2006 - acc: 0.999 - ETA: 1s - loss: 0.2009 - acc: 0.999 - ETA: 1s - loss: 0.2012 - acc: 0.999 - ETA: 1s - loss: 0.2014 - acc: 0.999 - ETA: 1s - loss: 0.2016 - acc: 0.999 - ETA: 1s - loss: 0.2016 - acc: 0.999 - ETA: 1s - loss: 0.2016 - acc: 0.998 - ETA: 1s - loss: 0.2018 - acc: 0.998 - ETA: 1s - loss: 0.2022 - acc: 0.998 - ETA: 1s - loss: 0.2022 - acc: 0.998 - ETA: 1s - loss: 0.2024 - acc: 0.998 - ETA: 1s - loss: 0.2035 - acc: 0.998 - ETA: 1s - loss: 0.2038 - acc: 0.998 - ETA: 1s - loss: 0.2039 - acc: 0.998 - ETA: 1s - loss: 0.2043 - acc: 0.998 - ETA: 1s - loss: 0.2040 - acc: 0.998 - ETA: 0s - loss: 0.2042 - acc: 0.998 - ETA: 0s - loss: 0.2039 - acc: 0.998 - ETA: 0s - loss: 0.2044 - acc: 0.998 - ETA: 0s - loss: 0.2044 - acc: 0.998 - ETA: 0s - loss: 0.2046 - acc: 0.998 - ETA: 0s - loss: 0.2047 - acc: 0.998 - ETA: 0s - loss: 0.2045 - acc: 0.998 - ETA: 0s - loss: 0.2045 - acc: 0.998 - ETA: 0s - loss: 0.2048 - acc: 0.998 - ETA: 0s - loss: 0.2053 - acc: 0.998 - ETA: 0s - loss: 0.2055 - acc: 0.998 - ETA: 0s - loss: 0.2056 - acc: 0.998 - ETA: 0s - loss: 0.2057 - acc: 0.998 - ETA: 0s - loss: 0.2056 - acc: 0.998 - ETA: 0s - loss: 0.2058 - acc: 0.998 - ETA: 0s - loss: 0.2060 - acc: 0.998 - ETA: 0s - loss: 0.2061 - acc: 0.998 - ETA: 0s - loss: 0.2061 - acc: 0.998 - ETA: 0s - loss: 0.2061 - acc: 0.9983Epoch 00029: val_loss did not improve\n",
      "6680/6680 [==============================] - 4s - loss: 0.2060 - acc: 0.9984 - val_loss: 0.8414 - val_acc: 0.7844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x241b6ed59e8>"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TODO: Train the model.\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.VGG19.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "VGG19_model.fit(train_VGG19, train_targets, \n",
    "          validation_data=(valid_VGG19, valid_targets),\n",
    "          epochs=30, batch_size=16, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Load the Model with the Best Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Load the model weights with the best validation loss.\n",
    "VGG19_model.load_weights('saved_models/weights.best.VGG19.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Test the Model\n",
    "\n",
    "Try out your model on the test dataset of dog images. Ensure that your test accuracy is greater than 60%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 78.5885%\n"
     ]
    }
   ],
   "source": [
    "### TODO: Calculate classification accuracy on the test dataset.\n",
    "VGG19_predictions = [np.argmax(VGG19_model.predict(np.expand_dims(feature, axis=0))) for feature in test_VGG19]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(VGG19_predictions)==np.argmax(test_targets, axis=1))/len(VGG19_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Predict Dog Breed with the Model\n",
    "\n",
    "Write a function that takes an image path as input and returns the dog breed (`Affenpinscher`, `Afghan_hound`, etc) that is predicted by your model.  \n",
    "\n",
    "Similar to the analogous function in Step 5, your function should have three steps:\n",
    "1. Extract the bottleneck features corresponding to the chosen CNN model.\n",
    "2. Supply the bottleneck features as input to the model to return the predicted vector.  Note that the argmax of this prediction vector gives the index of the predicted dog breed.\n",
    "3. Use the `dog_names` array defined in Step 0 of this notebook to return the corresponding breed.\n",
    "\n",
    "The functions to extract the bottleneck features can be found in `extract_bottleneck_features.py`, and they have been imported in an earlier code cell.  To obtain the bottleneck features corresponding to your chosen CNN architecture, you need to use the function\n",
    "\n",
    "    extract_{network}\n",
    "    \n",
    "where `{network}`, in the above filename, should be one of `VGG19`, `Resnet50`, `InceptionV3`, or `Xception`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Write a function that takes a path to an image as input\n",
    "### and returns the dog breed that is predicted by the model.\n",
    "from extract_bottleneck_features import *\n",
    "def VGG19_predict_breed(img_path):\n",
    "    # extract bottleneck features\n",
    "    bottleneck_feature = extract_VGG19(path_to_tensor(img_path))\n",
    "    # obtain predicted vector\n",
    "    predicted_vector = VGG19_model.predict(bottleneck_feature)\n",
    "    # return dog breed that is predicted by the model\n",
    "    return dog_names[np.argmax(predicted_vector)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step6'></a>\n",
    "## Step 6: Write your Algorithm\n",
    "\n",
    "Write an algorithm that accepts a file path to an image and first determines whether the image contains a human, dog, or neither.  Then,\n",
    "- if a __dog__ is detected in the image, return the predicted breed.\n",
    "- if a __human__ is detected in the image, return the resembling dog breed.\n",
    "- if __neither__ is detected in the image, provide output that indicates an error.\n",
    "\n",
    "You are welcome to write your own functions for detecting humans and dogs in images, but feel free to use the `face_detector` and `dog_detector` functions developed above.  You are __required__ to use your CNN from Step 5 to predict dog breed.  \n",
    "\n",
    "Some sample output for our algorithm is provided below, but feel free to design your own user experience!\n",
    "\n",
    "![Sample Human Output](images/sample_human_output.png)\n",
    "\n",
    "\n",
    "### (IMPLEMENTATION) Write your Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset/dogImages/test\\057.Dalmatian\\Dalmatian_04056.jpg\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "URL fetch failure on https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5: None -- [WinError 10054] An existing connection was forcibly closed by the remote host",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mD:\\AppData\\Anaconda\\envs\\dog-project-master\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mdo_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1253\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1254\u001b[1;33m                 \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselector\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1255\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# timeout error\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AppData\\Anaconda\\envs\\dog-project-master\\lib\\http\\client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, body, headers)\u001b[0m\n\u001b[0;32m   1106\u001b[0m         \u001b[1;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1107\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AppData\\Anaconda\\envs\\dog-project-master\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_request\u001b[1;34m(self, method, url, body, headers)\u001b[0m\n\u001b[0;32m   1151\u001b[0m             \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'body'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1152\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AppData\\Anaconda\\envs\\dog-project-master\\lib\\http\\client.py\u001b[0m in \u001b[0;36mendheaders\u001b[1;34m(self, message_body)\u001b[0m\n\u001b[0;32m   1102\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1103\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AppData\\Anaconda\\envs\\dog-project-master\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_output\u001b[1;34m(self, message_body)\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 934\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    935\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmessage_body\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AppData\\Anaconda\\envs\\dog-project-master\\lib\\http\\client.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    876\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 877\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    878\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AppData\\Anaconda\\envs\\dog-project-master\\lib\\http\\client.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1260\u001b[0m             self.sock = self._context.wrap_socket(self.sock,\n\u001b[1;32m-> 1261\u001b[1;33m                                                   server_hostname=server_hostname)\n\u001b[0m\u001b[0;32m   1262\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_hostname\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_hostname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AppData\\Anaconda\\envs\\dog-project-master\\lib\\ssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname)\u001b[0m\n\u001b[0;32m    384\u001b[0m                          \u001b[0mserver_hostname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m                          _context=self)\n\u001b[0m\u001b[0;32m    386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AppData\\Anaconda\\envs\\dog-project-master\\lib\\ssl.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, sock, keyfile, certfile, server_side, cert_reqs, ssl_version, ca_certs, do_handshake_on_connect, family, type, proto, fileno, suppress_ragged_eofs, npn_protocols, ciphers, server_hostname, _context)\u001b[0m\n\u001b[0;32m    759\u001b[0m                         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"do_handshake_on_connect should not be specified for non-blocking sockets\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 760\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AppData\\Anaconda\\envs\\dog-project-master\\lib\\ssl.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m    995\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 996\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    997\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AppData\\Anaconda\\envs\\dog-project-master\\lib\\ssl.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    640\u001b[0m         \u001b[1;34m\"\"\"Start the SSL/TLS handshake.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 641\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    642\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_hostname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionResetError\u001b[0m: [WinError 10054] An existing connection was forcibly closed by the remote host",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mD:\\AppData\\Anaconda\\envs\\dog-project-master\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget_file\u001b[1;34m(fname, origin, untar, md5_hash, cache_subdir)\u001b[0m\n\u001b[0;32m    112\u001b[0m                 urlretrieve(origin, fpath,\n\u001b[1;32m--> 113\u001b[1;33m                             functools.partial(dl_progress, progbar=progbar))\n\u001b[0m\u001b[0;32m    114\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mURLError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AppData\\Anaconda\\envs\\dog-project-master\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AppData\\Anaconda\\envs\\dog-project-master\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AppData\\Anaconda\\envs\\dog-project-master\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    467\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AppData\\Anaconda\\envs\\dog-project-master\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    483\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[1;32m--> 484\u001b[1;33m                                   '_open', req)\n\u001b[0m\u001b[0;32m    485\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AppData\\Anaconda\\envs\\dog-project-master\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    443\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 444\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    445\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AppData\\Anaconda\\envs\\dog-project-master\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1296\u001b[0m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[1;32m-> 1297\u001b[1;33m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[0m\u001b[0;32m   1298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AppData\\Anaconda\\envs\\dog-project-master\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mdo_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1255\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# timeout error\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1256\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1257\u001b[0m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mURLError\u001b[0m: <urlopen error [WinError 10054] An existing connection was forcibly closed by the remote host>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-02bd1dc6c2c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_files\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdog_detector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Dog is Detected and its breed is\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVGG19_predict_breed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mface_detector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Human is detected/n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-41-1c7595978eb1>\u001b[0m in \u001b[0;36mVGG19_predict_breed\u001b[1;34m(img_path)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mVGG19_predict_breed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# extract bottleneck features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mbottleneck_feature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_VGG19\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;31m# obtain predicted vector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mpredicted_vector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVGG19_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbottleneck_feature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Developement\\Udacity_Project\\dog-project-master\\extract_bottleneck_features.py\u001b[0m in \u001b[0;36mextract_VGG19\u001b[1;34m(tensor)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mextract_VGG19\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvgg19\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVGG19\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mVGG19\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'imagenet'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocess_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mextract_Resnet50\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AppData\\Anaconda\\envs\\dog-project-master\\lib\\site-packages\\keras\\applications\\vgg19.py\u001b[0m in \u001b[0;36mVGG19\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes)\u001b[0m\n\u001b[0;32m    169\u001b[0m             weights_path = get_file('vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5',\n\u001b[0;32m    170\u001b[0m                                     \u001b[0mWEIGHTS_PATH_NO_TOP\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m                                     cache_subdir='models')\n\u001b[0m\u001b[0;32m    172\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'theano'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AppData\\Anaconda\\envs\\dog-project-master\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget_file\u001b[1;34m(fname, origin, untar, md5_hash, cache_subdir)\u001b[0m\n\u001b[0;32m    113\u001b[0m                             functools.partial(dl_progress, progbar=progbar))\n\u001b[0;32m    114\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mURLError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrno\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: URL fetch failure on https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5: None -- [WinError 10054] An existing connection was forcibly closed by the remote host"
     ]
    }
   ],
   "source": [
    "### TODO: Write your algorithm.\n",
    "### Feel free to use as many code cells as needed.\n",
    "print(test_files[0])\n",
    "img_path = test_files[0]\n",
    "if dog_detector(img_path):\n",
    "    print(\"Dog is Detected and its breed is\"+str(VGG19_predict_breed(img_path)))\n",
    "if face_detector(img_path):\n",
    "    print(\"Human is detected/n\")\n",
    "    print(\"Image Looks like-\"+str(VGG19_predict_breed(img_path)))\n",
    "    \n",
    "    #priVGG19_predict_breed(img_path)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'Dog-Breed-Classifier'...\n",
      "fatal: unable to access 'https://github.com/saurabh-1991/Dog-Breed-Classifier/': OpenSSL SSL_connect: SSL_ERROR_SYSCALL in connection to github.com:443 \n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step7'></a>\n",
    "## Step 7: Test Your Algorithm\n",
    "\n",
    "In this section, you will take your new algorithm for a spin!  What kind of dog does the algorithm think that __you__ look like?  If you have a dog, does it predict your dog's breed accurately?  If you have a cat, does it mistakenly think that your cat is a dog?\n",
    "\n",
    "### (IMPLEMENTATION) Test Your Algorithm on Sample Images!\n",
    "\n",
    "Test your algorithm at least six images on your computer.  Feel free to use any images you like.  Use at least two human and two dog images.  \n",
    "\n",
    "__Question 6:__ Is the output better than you expected :) ?  Or worse :( ?  Provide at least three possible points of improvement for your algorithm.\n",
    "\n",
    "__Answer:__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TODO: Execute your algorithm from Step 6 on\n",
    "## at least 6 images on your computer.\n",
    "## Feel free to use as many code cells as needed."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
